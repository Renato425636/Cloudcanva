<!DOCTYPE html>
<html lang="pt-BR" class="">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cloud Canvas - Simulador de Pipeline de Nuvem</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            darkMode: 'class',
        }
    </script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .service-icon {
            transition: all 0.2s ease-in-out;
            cursor: grab;
        }
        .service-icon:active {
            cursor: grabbing;
            transform: scale(1.1);
        }
        .drop-zone {
            transition: all 0.2s ease-in-out;
            border: 2px dashed; /* Color is handled by Tailwind now */
            aspect-ratio: 1 / 1;
        }
        .drop-zone.drag-over {
            border-color: #4f46e5; /* indigo-600 */
            background-color: #e0e7ff; /* indigo-100 */
        }
        .dark .drop-zone.drag-over {
            border-color: #818cf8; /* indigo-400 */
            background-color: #3730a3; /* indigo-800 */
        }
        .modal-overlay {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(0, 0, 0, 0.5);
            display: flex;
            align-items: center;
            justify-content: center;
            z-index: 50;
            backdrop-filter: blur(4px);
        }
        .arrow {
            font-size: 2.5rem;
            line-height: 1;
            align-self: center;
        }
    </style>
    <script>
        // Handle dark mode toggling and initial load
        if (localStorage.getItem('theme') === 'dark' || (!('theme' in localStorage) && window.matchMedia('(prefers-color-scheme: dark)').matches)) {
            document.documentElement.classList.add('dark');
        } else {
            document.documentElement.classList.remove('dark');
        }

        function toggleTheme() {
            const html = document.documentElement;
            const isDark = html.classList.toggle('dark');
            localStorage.setItem('theme', isDark ? 'dark' : 'light');
            updateThemeIcons();
        }
        
        function updateThemeIcons(){
             const sunIcon = document.getElementById('sun-icon');
             const moonIcon = document.getElementById('moon-icon');
             if (document.documentElement.classList.contains('dark')) {
                sunIcon.classList.remove('hidden');
                moonIcon.classList.add('hidden');
             } else {
                sunIcon.classList.add('hidden');
                moonIcon.classList.remove('hidden');
             }
        }

        window.addEventListener('DOMContentLoaded', updateThemeIcons);
    </script>
</head>
<body class="bg-slate-100 dark:bg-slate-900 text-slate-800 dark:text-slate-200">

    <div class="flex h-screen antialiased">
        <!-- Sidebar -->
        <aside class="w-64 flex-shrink-0 bg-white dark:bg-slate-800 p-4 flex flex-col justify-between border-r border-slate-200 dark:border-slate-700">
            <div>
                <a href="#" onclick="goBack(event)" class="flex items-center space-x-3 px-2 mb-10 cursor-pointer">
                    <!-- New Logo SVG -->
                    <svg class="h-8 w-8 text-indigo-600 dark:text-indigo-400" width="24" height="24" viewBox="0 0 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                        <path d="M19.333 9.14286C21.46 10.1143 23 12.1857 23 14.5714C23 17.8143 20.313 20.5 17.07 20.5H7.11C3.868 20.5 1.18 17.8143 1.18 14.5714C1.18 11.5286 3.558 9.04286 6.53 8.57143C7.11 5.32857 9.968 3 13.409 3C16.095 3 18.397 4.54286 19.333 6.85714V9.14286Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"/>
                        <path d="M7 15L10 12L13 15L16 12" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"/>
                    </svg>
                    <h2 class="text-2xl font-bold text-slate-800 dark:text-white">Cloud Canvas</h2>
                </a>
                <nav class="space-y-2">
                    <a href="#" onclick="goBack(event)" class="sidebar-link flex items-center space-x-3 text-slate-600 dark:text-slate-300 p-3 rounded-lg hover:bg-slate-100 dark:hover:bg-slate-700">
                        <svg class="h-6 w-6" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24" stroke-width="2" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" d="M21 7.5l-9-5.25L3 7.5m18 0l-9 5.25m9-5.25v9l-9 5.25M3 7.5l9 5.25M3 7.5v9l9 5.25m0-9v9" />
                        </svg>
                        <span>Simulados</span>
                    </a>
                </nav>
            </div>
            <!-- Dark Mode Toggle -->
             <div class="mt-4">
                <button onclick="toggleTheme()" class="w-full flex items-center justify-center p-3 rounded-lg text-slate-600 dark:text-slate-300 hover:bg-slate-100 dark:hover:bg-slate-700">
                    <svg id="sun-icon" xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 hidden" fill="none" viewBox="0 0 24" stroke="currentColor" stroke-width="2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z" /></svg>
                    <svg id="moon-icon" xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 hidden" fill="none" viewBox="0 0 24" stroke="currentColor" stroke-width="2"><path stroke-linecap="round" stroke-linejoin="round" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z" /></svg>
                    <span class="ml-2">Alternar Tema</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="flex-1 overflow-y-auto">
            <div id="app-container" class="container mx-auto p-4 md:p-8 max-w-7xl">

                <!-- TELA DE SELEÇÃO DE PLATAFORMA -->
                <div id="platform-selection-screen" class="text-center">
                    <h1 class="text-3xl md:text-4xl font-bold text-slate-900 dark:text-white mb-2">Simulador de Pipeline de Nuvem</h1>
                    <p class="text-slate-600 dark:text-slate-400 mb-8 max-w-2xl mx-auto">Passo 1: Escolha uma plataforma de nuvem para começar.</p>
                    <div class="grid grid-cols-1 md:grid-cols-3 gap-6">
                        <div onclick="selectPlatform('AWS')" class="bg-white dark:bg-slate-800 rounded-2xl p-6 md:p-8 text-center cursor-pointer transition-all duration-300 border-2 border-transparent shadow-lg hover:shadow-xl hover:-translate-y-1 hover:border-orange-500">
                            <img src="https://upload.wikimedia.org/wikipedia/commons/9/93/Amazon_Web_Services_Logo.svg" alt="AWS Logo" class="h-16 mx-auto mb-4 filter dark:brightness-0 dark:invert">
                            <h2 class="text-2xl font-semibold text-slate-800 dark:text-white">AWS</h2>
                        </div>
                        <div onclick="selectPlatform('Azure')" class="bg-white dark:bg-slate-800 rounded-2xl p-6 md:p-8 text-center cursor-pointer transition-all duration-300 border-2 border-transparent shadow-lg hover:shadow-xl hover:-translate-y-1 hover:border-blue-500">
                            <img src="https://upload.wikimedia.org/wikipedia/commons/a/a8/Microsoft_Azure_Logo.svg" alt="Azure Logo" class="h-16 mx-auto mb-4">
                            <h2 class="text-2xl font-semibold text-slate-800 dark:text-white">Azure</h2>
                        </div>
                        <div onclick="selectPlatform('GCP')" class="bg-white dark:bg-slate-800 rounded-2xl p-6 md:p-8 text-center cursor-pointer transition-all duration-300 border-2 border-transparent shadow-lg hover:shadow-xl hover:-translate-y-1 hover:border-green-500">
                            <img src="https://www.gstatic.com/devrel-devsite/prod/v55e81371229cf93fbb4781915f01d3bef8e4cb4b674c7c839a1879ebb706855a/cloud/images/social-icon-google-cloud-1200-630.png" alt="GCP Logo" class="h-16 mx-auto mb-4">
                            <h2 class="text-2xl font-semibold text-slate-800 dark:text-white">GCP</h2>
                        </div>
                    </div>
                </div>

                <!-- TELA DE SELEÇÃO DE OBJETIVO -->
                <div id="objective-selection-screen" class="hidden text-center">
                    <h1 class="text-3xl md:text-4xl font-bold text-slate-900 dark:text-white mb-2">Objetivo do Simulado</h1>
                    <p class="text-slate-600 dark:text-slate-400 mb-8 max-w-2xl mx-auto">Passo 2: Qual área de conhecimento você quer praticar?</p>
                    <div class="grid grid-cols-1 md:grid-cols-3 gap-6">
                        <div onclick="selectObjective('data-engineering')" class="bg-white dark:bg-slate-800 rounded-2xl p-6 md:p-8 text-center cursor-pointer transition-all duration-300 border-2 border-transparent shadow-lg hover:shadow-xl hover:-translate-y-1 hover:border-indigo-500">
                            <h2 class="text-2xl font-semibold text-slate-800 dark:text-white">Engenharia de Dados</h2>
                            <p class="text-slate-500 dark:text-slate-400 mt-2">ETL, Big Data e pipelines de streaming.</p>
                        </div>
                        <div onclick="selectObjective('data-analysis')" class="bg-white dark:bg-slate-800 rounded-2xl p-6 md:p-8 text-center cursor-pointer transition-all duration-300 border-2 border-transparent shadow-lg hover:shadow-xl hover:-translate-y-1 hover:border-indigo-500">
                             <h2 class="text-2xl font-semibold text-slate-800 dark:text-white">Análise de Dados</h2>
                             <p class="text-slate-500 dark:text-slate-400 mt-2">BI, Data Warehousing e consultas.</p>
                        </div>
                        <div onclick="selectObjective('cloud-operations')" class="bg-white dark:bg-slate-800 rounded-2xl p-6 md:p-8 text-center cursor-pointer transition-all duration-300 border-2 border-transparent shadow-lg hover:shadow-xl hover:-translate-y-1 hover:border-indigo-500">
                             <h2 class="text-2xl font-semibold text-slate-800 dark:text-white">Operações & Automação</h2>
                             <p class="text-slate-500 dark:text-slate-400 mt-2">APIs, microsserviços e automação de TI.</p>
                        </div>
                    </div>
                </div>
                
                <!-- TELA DE SELEÇÃO DE DIFICULDADE -->
                <div id="difficulty-selection-screen" class="hidden text-center">
                    <h1 class="text-3xl md:text-4xl font-bold text-slate-900 dark:text-white mb-2">Nível do Desafio</h1>
                    <p class="text-slate-600 dark:text-slate-400 mb-8 max-w-2xl mx-auto">Passo 3: Escolha a dificuldade do seu simulado.</p>
                    <div class="grid grid-cols-2 md:grid-cols-5 gap-6">
                        <div onclick="selectDifficulty(1)" class="bg-white dark:bg-slate-800 rounded-2xl p-6 md:p-8 text-center cursor-pointer transition-all duration-300 border-2 border-transparent shadow-lg hover:shadow-xl hover:-translate-y-1 hover:border-green-500"><h2 class="text-2xl font-semibold text-slate-800 dark:text-white">Nível 1</h2><p class="text-slate-500 dark:text-slate-400 mt-2">Fundamental</p></div>
                        <div onclick="selectDifficulty(2)" class="bg-white dark:bg-slate-800 rounded-2xl p-6 md:p-8 text-center cursor-pointer transition-all duration-300 border-2 border-transparent shadow-lg hover:shadow-xl hover:-translate-y-1 hover:border-yellow-500"><h2 class="text-2xl font-semibold text-slate-800 dark:text-white">Nível 2</h2><p class="text-slate-500 dark:text-slate-400 mt-2">Intermediário</p></div>
                        <div onclick="selectDifficulty(3)" class="bg-white dark:bg-slate-800 rounded-2xl p-6 md:p-8 text-center cursor-pointer transition-all duration-300 border-2 border-transparent shadow-lg hover:shadow-xl hover:-translate-y-1 hover:border-orange-500"><h2 class="text-2xl font-semibold text-slate-800 dark:text-white">Nível 3</h2><p class="text-slate-500 dark:text-slate-400 mt-2">Avançado</p></div>
                        <div onclick="selectDifficulty(4)" class="bg-white dark:bg-slate-800 rounded-2xl p-6 md:p-8 text-center cursor-pointer transition-all duration-300 border-2 border-transparent shadow-lg hover:shadow-xl hover:-translate-y-1 hover:border-red-500"><h2 class="text-2xl font-semibold text-slate-800 dark:text-white">Nível 4</h2><p class="text-slate-500 dark:text-slate-400 mt-2">Especialista</p></div>
                        <div onclick="selectDifficulty(5)" class="bg-white dark:bg-slate-800 rounded-2xl p-6 md:p-8 text-center cursor-pointer transition-all duration-300 border-2 border-transparent shadow-lg hover:shadow-xl hover:-translate-y-1 hover:border-purple-500"><h2 class="text-2xl font-semibold text-slate-800 dark:text-white">Nível 5</h2><p class="text-slate-500 dark:text-slate-400 mt-2">Arquiteto</p></div>
                    </div>
                </div>


                <!-- TELA DE SIMULAÇÃO PRINCIPAL -->
                <div id="main-simulation-screen" class="hidden">
                    <div class="flex flex-wrap justify-between items-center mb-6 gap-4">
                         <h1 class="text-3xl font-bold text-slate-900 dark:text-white">Desafio: <span id="platform-name" class="font-extrabold text-indigo-600 dark:text-indigo-400"></span></h1>
                         <div class="flex items-center space-x-4">
                            <span id="quiz-progress" class="text-lg font-semibold bg-white dark:bg-slate-800 px-4 py-2 rounded-lg shadow-sm">Questão 1 de 2</span>
                         </div>
                    </div>
                    
                    <div id="scenario-container" class="bg-white dark:bg-slate-800 p-6 rounded-2xl mb-6 shadow-lg">
                        <h2 class="text-xl font-semibold text-slate-800 dark:text-white mb-2">Situação Proposta:</h2>
                        <p id="scenario-question" class="text-slate-600 dark:text-slate-300 leading-relaxed"></p>
                    </div>

                    <div id="challenge-ui" class="grid grid-cols-1 lg:grid-cols-4 gap-6">
                        <div class="lg:col-span-1 bg-white dark:bg-slate-800 p-6 rounded-2xl shadow-lg">
                            <h3 class="text-lg font-semibold mb-4 border-b border-slate-200 dark:border-slate-700 pb-2 text-slate-800 dark:text-white">Caixa de Ferramentas</h3>
                            <p class="text-sm text-slate-500 dark:text-slate-400 mb-4">Arraste os serviços para construir o pipeline.</p>
                            <div id="services-palette" class="grid grid-cols-2 gap-4"></div>
                        </div>

                        <div class="lg:col-span-3 bg-white dark:bg-slate-800 p-6 rounded-2xl shadow-lg">
                            <h3 class="text-lg font-semibold mb-4 border-b border-slate-200 dark:border-slate-700 pb-2 text-slate-800 dark:text-white">Construa seu Pipeline</h3>
                            <p class="text-sm text-slate-500 dark:text-slate-400 mb-4">Organize os serviços na ordem correta.</p>
                            <div class="w-full">
                                <div id="pipeline-canvas" class="flex flex-nowrap items-center justify-evenly w-full gap-2 p-4 bg-slate-100 dark:bg-slate-900/50 rounded-lg border border-slate-200 dark:border-slate-700 min-h-[192px]"></div>
                            </div>
                            
                            <div class="mt-6 flex justify-end space-x-4">
                                <button onclick="resetPipeline()" class="bg-slate-500 hover:bg-slate-600 dark:bg-slate-600 dark:hover:bg-slate-500 text-white font-bold py-2 px-6 rounded-lg transition-colors">Resetar</button>
                                <button onclick="evaluateSolution()" class="bg-indigo-600 hover:bg-indigo-700 dark:bg-indigo-500 dark:hover:bg-indigo-600 text-white font-bold py-2 px-6 rounded-lg transition-colors">Avaliar Solução</button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </main>
    </div>

    <!-- MODAL DE FEEDBACK -->
    <div id="feedback-modal" class="modal-overlay hidden">
        <div class="bg-white dark:bg-slate-800 border border-slate-200 dark:border-slate-700 rounded-2xl shadow-2xl p-8 max-w-4xl w-full transform transition-all" id="feedback-content">
            <h2 id="feedback-title" class="text-3xl font-bold mb-4 text-center"></h2>
            <div id="feedback-message" class="text-slate-600 dark:text-slate-300 mb-6"></div>
            <button id="feedback-button" class="text-white font-bold py-3 px-8 rounded-lg transition-colors w-full">Tentar Novamente</button>
        </div>
    </div>
    
    <!-- MODAL DO PIX -->
    <div id="pix-modal" class="modal-overlay hidden">
        <div class="bg-white dark:bg-slate-800 border border-slate-200 dark:border-slate-700 rounded-2xl shadow-2xl p-8 max-w-md w-full text-center transform transition-all flex flex-col items-center">
            <h2 class="text-3xl font-bold mb-4 text-slate-800 dark:text-white">Apoie o <span class="text-indigo-600 dark:text-indigo-400">Cloud Canvas</span>!</h2>
            <div class="p-2 bg-white rounded-lg shadow-md my-4">
                <img src="https://api.qrserver.com/v1/create-qr-code/?size=200x200&data=dd7768e8-2646-4a4a-a038-03c3b01a1c7c" alt="PIX QR Code para doação" class="rounded-lg">
            </div>
            <p class="text-slate-600 dark:text-slate-400 mb-6">Sua jornada na nuvem está decolando! Se este simulador está te ajudando, que tal mandar um PIX para abastecer nosso café e mantermos a plataforma voando alto? Qualquer valor é um mega incentivo!</p>
            <div class="flex justify-center space-x-4 w-full">
                <button id="pix-secondary-button" class="bg-slate-200 hover:bg-slate-300 dark:bg-slate-700 dark:hover:bg-slate-600 text-slate-800 dark:text-slate-200 font-bold py-3 px-6 rounded-lg transition-colors w-1/2">Fechar</button>
                <button id="pix-primary-button" class="bg-indigo-600 hover:bg-indigo-700 dark:bg-indigo-500 dark:hover:bg-indigo-600 text-white font-bold py-3 px-6 rounded-lg transition-colors w-1/2">Iniciar Simulado</button>
            </div>
        </div>
    </div>

    <!-- MODAL DE CONFIRMAÇÃO DE SAÍDA -->
    <div id="confirm-exit-modal" class="modal-overlay hidden">
        <div class="bg-white dark:bg-slate-800 border-slate-200 dark:border-slate-700 rounded-2xl shadow-2xl p-8 max-w-md w-full text-center transform transition-all">
            <h2 class="text-2xl font-bold mb-4 text-slate-800 dark:text-white">Sair do Simulado?</h2>
            <p class="text-slate-600 dark:text-slate-400 mb-8">Você tem certeza que deseja sair? Todo o seu progresso neste simulado será perdido.</p>
            <div class="flex justify-center space-x-4 w-full">
                <button onclick="document.getElementById('confirm-exit-modal').classList.add('hidden')" class="bg-slate-200 hover:bg-slate-300 dark:bg-slate-700 dark:hover:bg-slate-600 text-slate-800 dark:text-slate-200 font-bold py-3 px-6 rounded-lg transition-colors w-1/2">Cancelar</button>
                <button onclick="confirmExit()" class="bg-red-600 hover:bg-red-700 text-white font-bold py-3 px-6 rounded-lg transition-colors w-1/2">Sair</button>
            </div>
        </div>
    </div>

    <!-- MODAL DE RESUMO DO SIMULADO -->
    <div id="quiz-summary-modal" class="modal-overlay hidden">
        <div class="bg-white dark:bg-slate-800 border-slate-200 dark:border-slate-700 rounded-2xl shadow-2xl p-8 max-w-4xl w-full transform transition-all">
            <h2 class="text-3xl font-bold mb-6 text-center text-slate-800 dark:text-white">Resumo do Simulado</h2>
            <div id="summary-content" class="space-y-6 max-h-[60vh] overflow-y-auto pr-4">
                <!-- O conteúdo do resumo será inserido aqui dinamicamente -->
            </div>
            <div class="flex justify-center mt-8">
                 <button onclick="confirmExit()" class="bg-indigo-600 hover:bg-indigo-700 dark:bg-indigo-500 dark:hover:bg-indigo-600 text-white font-bold py-3 px-8 rounded-lg transition-colors">Jogar Novamente</button>
            </div>
        </div>
    </div>


    <script>
        // --- DATA ---
        const services = {
            AWS: {
                's3': { name: 'S3', icon: 'https://cdn.worldvectorlogo.com/logos/amazon-s3-simple-storage-service.svg' },
                'lambda': { name: 'Lambda', icon: 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5c/Amazon_Lambda_architecture_logo.svg/1200px-Amazon_Lambda_architecture_logo.svg.png' },
                'kinesis': { name: 'Kinesis Data Streams', icon: 'https://miro.medium.com/v2/1*zpLyF0dS35Xqtb98KBokUQ.png' },
                'glue': { name: 'Glue', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-glue-9ztw380gkkd1g54iwwsq7.png/aws-glue-g9i4j0s3igbjmai4vernz9.png?_a=DATAg1AAZAA0' },
                
                'redshift': { name: 'Redshift', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-redshift-66wh61ox3onpkqug27epnp.png/aws-redshift-5ucj7jrp6gm0c806t97m0w7.png?_a=DATAg1AAZAA0' },
                'dynamodb': { name: 'DynamoDB', icon: 'https://assets.streamlinehq.com/image/private/w_100,h_100,ar_1/f_auto/v1/icons/1/aws-dynamodb-jx5xy9kzifih9n75x0ty.png/aws-dynamodb-75zeqyp2syrkdpowzfwkfk.png?_a=DATAg1AAZAA0' },
                'step-functions': { name: 'Step Functions', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-step-functions-bdagl2uve6mc5xyzf8ut3i.png/aws-step-functions-yoa6fs8dq2q0mx085wgofne.png?_a=DATAg1AAZAA0' },
                
                'api-gateway': { name: 'API Gateway', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-api-gateway-tj2dkgxvdofaqvkyugqgoq.png/aws-api-gateway-pqt4djhl3zincgtqcvevf.png?_a=DATAg1AAZAA0' },
                
                'sqs': { name: 'SQS', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-sqs-7kygzksl919u4buvdh6ue.png/aws-sqs-86gd6l3l1p4q97mmn6pq.png?_a=DATAg1AAZAA0' },
                
                'sns': { name: 'SNS', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-sns-80t5m6hy89y74i2ta3yrz3.png/aws-sns-y7pv8d8lqjroqxkucbnv.png?_a=DATAg1AAZAA0' },
                
                'quicksight': { name: 'QuickSight', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-quicksight-ifwv0kt6mikq1bavest9.png/aws-quicksight-8js43tpc1tbuehqwbcdbz.png?_a=DATAg1AAZAA0' },
                
                'athena': { name: 'Athena', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-athena-hv6gsv93ozj2o0gsxdtg6m.png/aws-athena-jan6k55udjsv6va5uwobn.png?_a=DATAg1AAZAA0' },
                
                'rds': { name: 'RDS', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-rds-5qblz3nvfjmipvbykjpba.png/aws-rds-o6rtmustsgv3emnpozj4.png?_a=DATAg1AAZAA0' },
                
                'emr': { name: 'EMR', icon: 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSuWSNRRjNDqzoFqTElllBAZ3hqwx7ht8wmag&s' },
                
                'dms': { name: 'DMS', icon: 'https://res.cloudinary.com/hy4kyit2a/f_auto,fl_lossy,q_70/learn/modules/aws-cloud-acquisition/migrate-to-the-aws-cloud/images/ba8da6c9295b1aea44d1bdf69b4282a2_kix.ogmmcnow3wz5.png' },
                
                'lake-formation': { name: 'Lake Formation', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-lake-formation-4k6cs4q7djvfa5aq5w6aia.png/aws-lake-formation-23j99h65239rm49v0apt2.png?_a=DATAg1AAZAA0' },
                
                'msk': { name: 'MSK', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-msk-u1q98yujn797oz22k03v45.png/aws-msk-k7u06h5figugvrf4undx.png?_a=DATAg1AAZAA0' },
                
                'opensearch': { name: 'OpenSearch', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-open-search-1yzngnyfogqu7r8pfp894e.png/aws-open-search-maq7fazqolbct8d7m9ou8s.png?_a=DATAg1AAZAA0' },
                
                'mwaa': { name: 'MWAA', icon: 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ_kK7Z29b3Ojl5_xtS85ymlj2B7ezhAtEpNQ&s' },
                
                'sagemaker': { name: 'SageMaker', icon: 'https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/04/24/SageMaker.jpg' },
                'kinesis-firehose': { name: 'Kinesis Firehose', icon: 'https://newrelic.com/sites/default/files/quickstarts/images/icons/aws-kinesis-data-firehose--logo.svg' },
                
                'ec2': { name: 'EC2', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-ec2-bi87vqoabfbmadlrtmtp1n.png/aws-ec2-8tgwuch5vagt0ftrucnghq.png?_a=DATAg1AAZAA0' },
                
                'ecs': { name: 'ECS', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-ecs-r57h5csktlbovwelzaln3.png/aws-ecs-mstmcs5adrqf2r2w1lxyqm.png?_a=DATAg1AAZAA0' },
                
                'cloudformation': { name: 'CloudFormation', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-cloudformation-xhfgoczq9vcaicwekcz3x4.png/aws-cloudformation-ld8d8ypjpnd18eskmfgbo.png?_a=DATAg1AAZAA0' },
                
                'cognito': { name: 'Cognito', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-cognito-jh49xr1uergt6lq61nzw7.png/aws-cognito-1lwcmhnknd8rynq09p18rh.png?_a=DATAg1AAZAA0' },
                
                
                'eventbridge': { name: 'EventBridge', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-eventbridge-5yn7gpt4na9nq8ut175la.png/aws-eventbridge-07t2qrie8h9cc7b75iu9y9c.png?_a=DATAg1AAZAA0' },
                
                
                'timestream': { name: 'Timestream', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-timestream-4m78rbjmsdgvn9ajje4te.png/aws-timestream-r6hohld6d2kwoqu1dz5zqh.png?_a=DATAg1AAZAA0'},
                
                'iot-core': { name: 'IoT Core', icon: 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQOEvg1IKOYgigghNxZVCeQD5xTpKm4qkWDsQ&s'},
                
                'personalize': { name: 'Personalize', icon: 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTramBbAYoHDQ7d_vDIQlTMQyS4PUaUhOAxWQ&s'},
                
                'comprehend': { name: 'Comprehend', icon: 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTO_7n545oBMuOpCf3eaff0oDzbz81jalvqYA&s'},
                
                'textract': { name: 'Textract', icon: 'https://pypi-camo.freetls.fastly.net/5004099b26f8f8bf78d8303d8a925377eebca1b2/68747470733a2f2f6769746875622e636f6d2f4d616348752d4757552f6177735f74657874726163742d70726f6a6563742f6173736574732f363830303431312f61306637623063622d383234312d346463342d613933612d663062306262386362663364'},
                
                'eks': { name: 'EKS', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-eks-silujmlxqanjvxwoebv7af.png/aws-eks-aqbdhxuqgubdf7dmbpc46.png?_a=DATAg1AAZAA0'},
                
                'fargate': { name: 'Fargate', icon: 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRqmnQxIV0P_DLhMT_I5a4pSehaGpxWl0HhFQ&s'},
                
                'codepipeline': { name: 'CodePipeline', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-codepipeline-kxgnrmm9kd5ew4ehjmjxh.png/aws-codepipeline-z7s9tbutqt9qtiiu06kr7.png?_a=DATAg1AAZAA0'},
                'secrets-manager': { name: 'Secrets Manager', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-secrets-manager-svfwj1evvibd7760sbcl.png/aws-secrets-manager-7auwkav1r2c3xpvg5eoz3r.png?_a=DATAg1AAZAA0'},
                
                'cloudfront': { name: 'CloudFront', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-cloudfront-uxznobtbzzoxukzbjawan.png/aws-cloudfront-2tfhphew863aoukvktdtjp.png?_a=DATAg1AAZAA0'},
                
                'cloudwatch': { name: 'CloudWatch', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-cloudwatch-emo8muaj7q97wdnd5rko7.png/aws-cloudwatch-odt9x7dcayoh0fpefx91zm.png?_a=DATAg1AAZAA0'},
                
                'elasticache': { name: 'ElastiCache', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-elasticache-2hseki24om1t50cpvmasja.png/aws-elasticache-zixyw7qimds5m9144eza.png?_a=DATAg1AAZAA0'},
                
                'iam': { name: 'IAM', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-iam-r29jwob6ccgfn38unzs7lb.png/aws-iam-ml4zst94zbf0oxpt4vszxuc.png?_a=DATAg1AAZAA0'},
                
                'aurora': { name: 'Aurora', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-aurora-osqzsk4t1jlp408k9cv0s.png/aws-aurora-8756msl25662nc8atgguts.png?_a=DATAg1AAZAA0'},
                'route 53': { name: 'Route 53', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-route53-p3t47q0lx2lq1srdr8hx.png/aws-route53-fk4qtcwyolq0zlrfn93s8i.png?_a=DATAg1AAZAA0'},
                'glacier': { name: 'Glacier', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-glacier-b1unbbfx6jupeuzgwd5dym.png/aws-glacier-w8nkzj63voyynejbw4axi.png?_a=DATAg1AAZAA0'},
                
                'neptune': { name: 'Neptune', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-neptune-swytkotnlhg7bzpma02k3.png/aws-neptune-4kzyybyptjd3b0fys5yxrp.png?_a=DATAg1AAZAA0'},
                'keyspaces': { name: 'Keyspaces', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-keyspaces-f7hzy7q18u76p3v9r2gnn5.png/aws-keyspaces-t4m7wiusq1aklzm2qcg24i.png?_a=DATAg1AAZAA0'},

                'macie': { name: 'Macie', icon: 'https://awsvideocatalog.com/images/aws/png/PNG%20Light/Security,%20Identity,%20&%20Compliance/Amazon-Macie.png'},

                'codecommit': { name: 'Codecommit', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-codecommit-a5gis9sjuowskzjtxlhzb.png/aws-codecommit-xbid1md7f3yrgeunkvxa.png?_a=DATAg1AAZAA0'},

                'kinesis-analytics': { name: 'Kineis analytics', icon: 'https://miro.medium.com/v2/1*wZnz1aXDeMK6c1--dfgpeA.png'},

                'kms': { name: 'KMS', icon: 'https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/1/aws-kms-iafz4c6zbtlb81zkjdhwq5.png/aws-kms-8yhylffjjdihvjsi95y8de.png?_a=DATAg1AAZAA0'}
            },
            Azure: { },
            GCP: { }
        };

        const scenarios = {
            AWS: [
    {
        "id": "aws-de-001",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Projete um pipeline de ETL que replica dados continuamente de um banco de dados on-premise (simulado por RDS) para um Data Lake no S3 e, em seguida, os carrega em um Data Warehouse no Redshift para análise de BI.",
        "solution": ["rds", "dms", "s3", "redshift"],
        "availableServices": ["rds", "dms", "s3", "redshift", "lambda", "kinesis"],
        "explanation": "O AWS DMS (Database Migration Service) é ideal para replicar dados de uma fonte como RDS para um destino. O S3 serve como a camada de armazenamento do Data Lake, recebendo os dados replicados. A partir do S3, os dados podem ser carregados no Redshift usando o comando COPY para performance otimizada em análises."
    },
    {
        "id": "aws-de-002",
        "category": "data-engineering",
        "difficulty": 2,
        "question": "Como você pode ingerir um fluxo contínuo de dados de logs e entregá-los diretamente a um bucket S3 para arquivamento e análise futura, de forma totalmente gerenciada?",
        "solution": ["kinesis-firehose", "s3"],
        "availableServices": ["kinesis-firehose", "s3", "kinesis", "lambda", "ec2"],
        "explanation": "O Kinesis Data Firehose é o serviço mais simples para carregar dados de streaming em destinos como o S3. Ele é totalmente gerenciado, cuidando do buffering, compressão e entrega dos dados, exigindo configuração mínima."
    },
    {
        "id": "aws-de-003",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Crie uma arquitetura que colete dados de cliques de um site em tempo real, execute uma agregação baseada em janela de tempo (ex: contagem de cliques por minuto) e armazene o resultado em um banco de dados para dashboards.",
        "solution": ["kinesis", "kinesis-analytics", "lambda", "dynamodb"],
        "availableServices": ["kinesis", "kinesis-analytics", "lambda", "dynamodb", "s3", "glue"],
        "explanation": "O Kinesis Data Streams ingere o fluxo de cliques. O Kinesis Data Analytics permite executar consultas SQL contínuas sobre o stream para realizar agregações em janelas de tempo. Uma função Lambda pode ser usada como destino para receber os resultados da análise e gravá-los no DynamoDB para acesso de baixa latência por um dashboard."
    },
    {
        "id": "aws-de-004",
        "category": "cloud-operations",
        "difficulty": 5,
        "question": "Orquestre um fluxo de processamento de pedidos. Um novo pedido chega via API Gateway, é validado por uma função Lambda e depois se divide em duas ações paralelas: atualizar o inventário no DynamoDB e enviar uma notificação de confirmação via SNS. Use um orquestrador para gerenciar o fluxo.",
        "solution": ["api-gateway", {"orchestrator": "step-functions", "flow": ["lambda", [["dynamodb"], ["sns"]]]}],
        "availableServices": ["api-gateway", "step-functions", "lambda", "dynamodb", "sns", "sqs"],
        "explanation": "O API Gateway recebe o pedido. O Step Functions é o orquestrador ideal para fluxos de trabalho com múltiplos passos e lógica condicional. Ele primeiro invoca uma Lambda para validação. Em seguida, usa um estado 'Parallel' para executar as atualizações no DynamoDB e o envio de notificações SNS simultaneamente, otimizando o tempo de processamento."
    },
    {
        "id": "aws-de-005",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Construa um Data Lake simples onde arquivos CSV são depositados em um bucket S3. Use um serviço para descobrir o esquema desses dados e catalogá-los, tornando-os consultáveis via SQL padrão.",
        "solution": ["s3", "glue", "athena"],
        "availableServices": ["s3", "glue", "athena", "redshift", "emr", "lambda"],
        "explanation": "O S3 armazena os dados brutos. O AWS Glue Crawler pode varrer o S3, inferir o esquema dos arquivos CSV e criar uma tabela no Glue Data Catalog. O Athena, então, utiliza esse catálogo para permitir que os usuários consultem os dados diretamente no S3 usando SQL padrão."
    },
    {
        "id": "aws-de-006",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Desenvolva um pipeline que seja acionado por um agendamento diário. O gatilho inicia um job que processa um grande volume de dados (terabytes) usando Spark e armazena o resultado em S3. Qual serviço de agendamento e qual serviço de processamento Spark gerenciado você usaria?",
        "solution": ["eventbridge", "emr", "s3"],
        "availableServices": ["eventbridge", "emr", "s3", "lambda", "glue", "step-functions"],
        "explanation": "O Amazon EventBridge é o serviço ideal para criar regras baseadas em agendamento (schedule) para acionar outros serviços da AWS. Para processar terabytes de dados com Spark, o Amazon EMR (Elastic MapReduce) é a escolha mais robusta e escalável. O resultado do processamento é então armazenado no S3."
    },
    {
        "id": "aws-de-007",
        "category": "data-engineering",
        "difficulty": 2,
        "question": "Crie uma arquitetura serverless simples onde o upload de uma imagem em um bucket S3 aciona uma função que gera uma miniatura (thumbnail) e a salva em outro bucket S3.",
        "solution": ["s3", "lambda", "s3"],
        "availableServices": ["s3", "lambda", "ec2", "sqs", "sns"],
        "explanation": "Esta é uma arquitetura clássica orientada a eventos. O S3 pode ser configurado para enviar um evento de 'ObjectCreated'. Esse evento aciona uma função Lambda, que contém a lógica para redimensionar a imagem e salvar o resultado em um bucket S3 de destino."
    },
    {
        "id": "aws-de-008",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Projete uma solução para ingerir dados de telemetria de dispositivos IoT, armazenando os dados brutos em S3, os dados de série temporal em um banco de dados otimizado e, ao mesmo tempo, enviando alertas via SNS se uma métrica específica exceder um limite.",
        "solution": ["iot-core", "kinesis", [["kinesis-firehose", "s3"], ["lambda", "timestream"], ["lambda", "sns"]]],
        "availableServices": ["iot-core", "kinesis", "kinesis-firehose", "s3", "lambda", "timestream", "sns", "dynamodb"],
        "explanation": "O IoT Core recebe os dados. Eles são enviados para um Kinesis Data Stream, que atua como um distribuidor. A partir do stream: 1) Um Kinesis Firehose consome os dados e os arquiva no S3. 2) Uma função Lambda processa os dados e os insere no Timestream, o banco de dados otimizado para séries temporais. 3) Outra função Lambda analisa os dados em busca de anomalias e envia um alerta via SNS se necessário."
    },
    {
        "id": "aws-de-009",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Construa uma arquitetura de API desacoplada. Um serviço de API recebe requisições, as coloca em uma fila para garantir durabilidade e processamento assíncrono, e uma frota de contêineres processa as mensagens da fila, salvando o resultado em um banco de dados relacional.",
        "solution": ["api-gateway", "sqs", "ecs", "rds"],
        "availableServices": ["api-gateway", "sqs", "ecs", "rds", "lambda", "sns", "ec2"],
        "explanation": "O API Gateway serve como front-end. O SQS (Simple Queue Service) desacopla a API dos workers, absorvendo picos de tráfego e garantindo que nenhuma requisição seja perdida. O ECS (Elastic Container Service) gerencia a execução dos contêineres que consomem as mensagens da fila. O resultado é persistido em um banco de dados RDS."
    },
    {
        "id": "aws-de-010",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Você precisa disponibilizar dashboards interativos para analistas de negócios sobre dados armazenados em seu Data Warehouse no Redshift. Qual serviço de BI da AWS se integra nativamente para essa finalidade?",
        "solution": ["redshift", "quicksight"],
        "availableServices": ["redshift", "quicksight", "athena", "s3", "emr"],
        "explanation": "O Amazon QuickSight é o serviço de Business Intelligence da AWS. Ele se integra nativamente com várias fontes de dados da AWS, incluindo o Redshift, permitindo a criação rápida de dashboards e análises visuais."
    },
    {
        "id": "aws-de-011",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Crie um pipeline de dados que orquestra jobs de ETL usando Airflow. O serviço gerenciado de Airflow deve executar um script que transforma dados no S3 e os carrega no Redshift. Como seria essa arquitetura?",
        "solution": [{"orchestrator": "mwaa", "flow": ["s3", "redshift"]}],
        "availableServices": ["mwaa", "s3", "redshift", "step-functions", "glue", "ec2"],
        "explanation": "O MWAA (Managed Workflows for Apache Airflow) é o serviço gerenciado da AWS para Airflow. Uma DAG no MWAA pode ser configurada para executar operadores que interagem com outros serviços, como processar arquivos no S3 (usando um pod do EKS ou um job do Glue invocado pelo Airflow) e carregar os dados transformados no Redshift."
    },
    {
        "id": "aws-de-012",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Desenvolva uma arquitetura de Data Lakehouse governada. Os dados brutos chegam ao S3. Um serviço centralizado deve gerenciar as permissões de acesso a tabelas e colunas para os dados no S3. Os dados devem ser transformados por um job Spark (Glue) e consultados pelo Athena.",
        "solution": ["s3", "lake-formation", "glue", "athena"],
        "availableServices": ["s3", "lake-formation", "glue", "athena", "iam", "macie"],
        "explanation": "O S3 armazena os dados. O AWS Lake Formation atua como uma camada de governança centralizada sobre o S3, permitindo definir permissões granulares (nível de tabela, coluna e célula) para diferentes usuários e serviços. O Glue executa a transformação dos dados e o Athena consulta os dados, ambos respeitando as permissões definidas no Lake Formation."
    },
    {
        "id": "aws-de-013",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Implemente um padrão de fan-out. Uma mensagem sobre um novo cliente é publicada em um tópico. Múltiplos sistemas precisam reagir a esse evento: um para enviar um e-mail de boas-vindas, outro para atualizar um sistema de CRM e um terceiro para arquivar a notificação.",
        "solution": ["sns", [["sqs", "lambda"], ["sqs", "lambda"], ["sqs", "lambda"]]],
        "availableServices": ["sns", "sqs", "lambda", "kinesis", "eventbridge"],
        "explanation": "O SNS (Simple Notification Service) é ideal para o padrão publish/subscribe (fan-out). A mensagem é publicada em um tópico SNS. Três filas SQS diferentes são inscritas nesse tópico, cada uma recebendo uma cópia da mensagem. Cada fila SQS, por sua vez, aciona uma função Lambda específica para realizar sua tarefa (e-mail, CRM, arquivamento), garantindo processamento desacoplado e resiliente."
    },
    {
        "id": "aws-de-014",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Você precisa migrar um cluster Kafka autogerenciado para a AWS. Qual serviço gerenciado você usaria? E como você consumiria as mensagens desse cluster para processá-las e salvá-las no S3?",
        "solution": ["msk", "lambda", "s3"],
        "availableServices": ["msk", "lambda", "s3", "kinesis", "sqs", "ec2"],
        "explanation": "O Amazon MSK (Managed Streaming for Kafka) é o serviço gerenciado da AWS para Apache Kafka. Para consumir as mensagens, você pode usar uma função Lambda como um consumidor serverless, que pode ser acionada por eventos do MSK. A função processa os lotes de mensagens e os escreve no S3 para armazenamento e análise posterior."
    },
    {
        "id": "aws-de-015",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Crie uma arquitetura para análise de logs de aplicação. Os logs são enviados para um serviço que permite indexação e busca em tempo real, além da criação de dashboards de monitoramento.",
        "solution": ["opensearch"],
        "availableServices": ["opensearch", "redshift", "athena", "dynamodb", "cloudwatch"],
        "explanation": "O Amazon OpenSearch Service (sucessor do Elasticsearch Service) é projetado especificamente para casos de uso de busca e análise de logs. Ele indexa os dados recebidos, permitindo pesquisas de texto completo de baixa latência e a criação de visualizações e dashboards com o OpenSearch Dashboards."
    },
    {
        "id": "aws-de-016",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Projete um pipeline de Machine Learning. Um job do Glue pré-processa os dados no S3. Em seguida, um fluxo orquestrado treina um modelo e, se o treinamento for bem-sucedido, o implanta como um endpoint para inferência. Notifique o resultado final.",
        "solution": ["s3", "glue", {"orchestrator": "step-functions", "flow": ["sagemaker", "sns"]}],
        "availableServices": ["s3", "glue", "step-functions", "sagemaker", "sns", "lambda"],
        "explanation": "O Glue realiza o pré-processamento (feature engineering). O Step Functions orquestra o pipeline de MLOps. Ele invoca uma tarefa de treinamento do SageMaker. Com base no resultado, ele pode usar lógica condicional para invocar outra tarefa do SageMaker para criar um endpoint. Por fim, ele envia uma notificação via SNS sobre o sucesso ou falha do pipeline."
    },
    {
        "id": "aws-de-017",
        "category": "data-engineering",
        "difficulty": 2,
        "question": "Como você armazenaria dados de configuração de aplicação ou metadados que exigem acesso rápido de chave-valor e alta escalabilidade?",
        "solution": ["dynamodb"],
        "availableServices": ["dynamodb", "rds", "redshift", "s3"],
        "explanation": "O Amazon DynamoDB é um banco de dados NoSQL de chave-valor totalmente gerenciado que oferece desempenho de milissegundos de um dígito em qualquer escala. É a escolha perfeita para casos de uso que exigem acesso rápido a itens individuais por meio de uma chave primária."
    },
    {
        "id": "aws-de-018",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Um fluxo de dados em tempo real precisa ser entregue a dois destinos: um cluster Redshift para análise e um bucket S3 para backup, com transformação de dados em trânsito. Qual serviço pode capturar, transformar e entregar para múltiplos destinos de forma gerenciada?",
        "solution": ["kinesis", "kinesis-firehose", [["redshift"], ["s3"]]],
        "availableServices": ["kinesis", "kinesis-firehose", "redshift", "s3", "lambda", "glue"],
        "explanation": "O Kinesis Data Streams ingere os dados. Ele pode ter múltiplos consumidores. Um Kinesis Data Firehose pode consumir do stream, usar uma função Lambda integrada para realizar transformações em tempo real e, em seguida, entregar os dados transformados para múltiplos destinos, como Redshift e S3, simultaneamente."
    },
    {
        "id": "aws-de-019",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Você precisa implantar toda a infraestrutura de um pipeline de dados (S3, Lambda, DynamoDB) de forma automatizada e repetível. Qual serviço da AWS você usaria para definir sua infraestrutura como código (IaC)?",
        "solution": ["cloudformation"],
        "availableServices": ["cloudformation", "ec2", "iam", "s3", "lambda", "dynamodb"],
        "explanation": "O AWS CloudFormation permite que você modele e configure seus recursos da AWS em arquivos de texto (YAML ou JSON). Ele provisiona e gerencia a 'pilha' (stack) de recursos de forma ordenada e previsível, tornando-o a principal ferramenta de IaC da AWS."
    },
    {
        "id": "aws-de-020",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Crie um sistema que extrai texto de documentos PDF e imagens enviados para o S3 e, em seguida, analisa o texto extraído para identificar entidades (como nomes de pessoas e lugares), armazenando os resultados em um banco de dados pesquisável.",
        "solution": ["s3", "lambda", "textract", "comprehend", "opensearch"],
        "availableServices": ["s3", "lambda", "textract", "comprehend", "opensearch", "dynamodb"],
        "explanation": "Um evento S3 aciona uma Lambda. A Lambda orquestra o processo: primeiro, chama o Amazon Textract para extrair o texto do documento. Em seguida, passa o texto extraído para o Amazon Comprehend para realizar o reconhecimento de entidades nomeadas (NER). Por fim, a Lambda armazena o texto e as entidades extraídas no Amazon OpenSearch para indexação e pesquisa."
    },
    {
        "id": "aws-de-021",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Como você pode acelerar o desempenho de um banco de dados relacional (RDS) para leituras frequentes de dados comuns, como perfis de usuário ou catálogos de produtos?",
        "solution": ["rds", "elasticache"],
        "availableServices": ["rds", "elasticache", "dynamodb", "s3"],
        "explanation": "O Amazon ElastiCache (com Redis ou Memcached) fornece um serviço de cache em memória. Ao colocar um cache ElastiCache na frente do RDS, as leituras frequentes podem ser atendidas a partir da memória de alta velocidade, reduzindo a latência e a carga sobre o banco de dados principal."
    },
    {
        "id": "aws-de-022",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Projete uma arquitetura para executar um contêiner Docker que processa arquivos em S3 sob demanda, sem gerenciar servidores ou clusters. A execução deve ser acionada por uma mensagem em uma fila SQS.",
        "solution": ["sqs", "fargate", "s3"],
        "availableServices": ["sqs", "fargate", "s3", "ec2", "ecs", "eks"],
        "explanation": "O SQS desacopla o gatilho da execução. O AWS Fargate é um mecanismo de computação serverless para contêineres que funciona com o Amazon ECS. Você pode configurar um serviço ECS usando Fargate para escalar automaticamente o número de tarefas (contêineres) com base no número de mensagens na fila SQS, processando os arquivos do S3 de forma eficiente e sem gerenciamento de infraestrutura."
    },
    {
        "id": "aws-de-023",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Construa um pipeline de CI/CD para um job de ETL do AWS Glue. O código do job está em um repositório. O pipeline deve ser acionado por um commit, construir o pacote e implantar a nova versão do job.",
        "solution": ["codecommit", "codepipeline", "glue"],
        "availableServices": ["codecommit", "codepipeline", "glue", "s3", "cloudformation"],
        "explanation": "O AWS CodeCommit hospeda o código-fonte do job. Um commit no repositório aciona o AWS CodePipeline. O pipeline pode ter um estágio de 'Build' (usando o AWS CodeBuild, não listado, mas implícito no pipeline) para empacotar as dependências e o script, e um estágio de 'Deploy' que usa o CloudFormation ou a CLI da AWS para atualizar o job do AWS Glue existente com a nova versão do código."
    },
    {
        "id": "aws-de-024",
        "category": "data-engineering",
        "difficulty": 2,
        "question": "Você precisa armazenar as senhas e chaves de API de um banco de dados de forma segura, para que suas funções Lambda possam acessá-las sem expô-las no código. Qual serviço é projetado para isso?",
        "solution": ["secrets-manager"],
        "availableServices": ["secrets-manager", "iam", "kms", "s3"],
        "explanation": "O AWS Secrets Manager é o serviço ideal para gerenciar, rotacionar e recuperar segredos (como credenciais de banco de dados, chaves de API) ao longo de seu ciclo de vida. As aplicações, como as funções Lambda, podem recuperar os segredos programaticamente por meio de uma API, evitando a necessidade de codificá-los."
    },
    {
        "id": "aws-de-025",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Como você serviria o conteúdo de um Data Lake no S3 para usuários em todo o mundo com baixa latência e alta velocidade de transferência?",
        "solution": ["s3", "cloudfront"],
        "availableServices": ["s3", "cloudfront", "ec2", "route 53"],
        "explanation": "O Amazon CloudFront é uma rede de entrega de conteúdo (CDN) global. Ao configurar o CloudFront com uma origem S3, o conteúdo do bucket é armazenado em cache em 'edge locations' ao redor do mundo. Quando um usuário solicita o conteúdo, ele é entregue a partir da edge location mais próxima, resultando em latência significativamente menor."
    },
    {
        "id": "aws-de-026",
        "category": "cloud-operations",
        "difficulty": 3,
        "question": "Você precisa monitorar a utilização da CPU de uma instância EC2 e receber um alerta por e-mail quando ela ultrapassar 80%. Como você configuraria isso?",
        "solution": ["ec2", "cloudwatch", "sns"],
        "availableServices": ["ec2", "cloudwatch", "sns", "lambda", "eventbridge"],
        "explanation": "O Amazon CloudWatch coleta métricas de recursos da AWS, incluindo a utilização da CPU de instâncias EC2. Você pode criar um Alarme do CloudWatch que monitora essa métrica. Na configuração do alarme, você define a condição (CPU > 80%) e especifica uma Ação, que seria publicar uma mensagem em um tópico SNS. Uma assinatura de e-mail nesse tópico garantirá que o alerta seja recebido."
    },
    {
        "id": "aws-de-027",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Projete uma arquitetura de banco de dados relacional com alta disponibilidade e recuperação de desastres. O banco de dados deve ter réplicas de leitura para escalar as consultas.",
        "solution": ["aurora"],
        "availableServices": ["aurora", "rds", "ec2", "dms"],
        "explanation": "O Amazon Aurora é um banco de dados relacional compatível com MySQL e PostgreSQL, projetado para a nuvem. Ele oferece alta disponibilidade por padrão, replicando os dados em 3 Zonas de Disponibilidade. Ele também suporta até 15 réplicas de leitura de baixa latência que compartilham o mesmo armazenamento subjacente, tornando a escalabilidade de leitura muito eficiente."
    },
    {
        "id": "aws-de-028",
        "category": "data-engineering",
        "difficulty": 2,
        "question": "Qual serviço você usaria para arquivamento de dados a longo prazo e de baixo custo, onde o tempo de recuperação de algumas horas é aceitável?",
        "solution": ["s3", "glacier"],
        "availableServices": ["s3", "glacier", "ebs", "efs"],
        "explanation": "O Amazon S3 Glacier é um serviço de armazenamento seguro, durável e de custo extremamente baixo para arquivamento de dados. Ele é ideal para backups e arquivos mortos. Você pode usar as políticas de ciclo de vida do S3 para mover objetos automaticamente para as classes de armazenamento do Glacier após um certo período."
    },
    {
        "id": "aws-de-029",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Você precisa modelar e consultar dados altamente conectados, como redes sociais ou grafos de conhecimento. Qual banco de dados gerenciado da AWS é otimizado para esse tipo de dado?",
        "solution": ["neptune"],
        "availableServices": ["neptune", "dynamodb", "aurora", "redshift"],
        "explanation": "O Amazon Neptune é um serviço de banco de dados de grafos rápido, confiável e totalmente gerenciado. Ele facilita a criação e a execução de aplicações que trabalham com conjuntos de dados altamente conectados, sendo otimizado para consultas complexas de grafos."
    },
    {
        "id": "aws-de-030",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Migre uma aplicação que usa Apache Cassandra on-premise para um serviço compatível, serverless e gerenciado na AWS. Qual serviço você escolheria?",
        "solution": ["keyspaces"],
        "availableServices": ["keyspaces", "dynamodb", "rds", "neptune"],
        "explanation": "O Amazon Keyspaces (for Apache Cassandra) é um serviço de banco de dados compatível com Apache Cassandra, escalável, de alta disponibilidade e gerenciado. Por ser serverless, ele dimensiona tabelas automaticamente para cima e para baixo em resposta ao tráfego da aplicação, e você paga apenas pelos recursos que utiliza."
    },
    {
        "id": "aws-de-031",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Implemente um sistema para descobrir e proteger dados sensíveis (como informações de identificação pessoal - PII) armazenados em seu Data Lake no S3. O sistema deve classificar os dados e alertar sobre políticas de segurança.",
        "solution": ["s3", "macie"],
        "availableServices": ["s3", "macie", "glue", "lake-formation", "kms"],
        "explanation": "O Amazon Macie é um serviço de segurança e privacidade de dados que usa machine learning para descobrir, classificar e proteger automaticamente dados confidenciais na AWS. Ao habilitar o Macie para seus buckets S3, ele pode identificar PII, dados financeiros e outras informações sensíveis, fornecendo dashboards e alertas sobre a segurança dos seus dados."
    },
    {
        "id": "aws-de-032",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Qual serviço da AWS você usaria para criptografar os dados em repouso em um bucket S3, garantindo que você tenha controle sobre as chaves de criptografia?",
        "solution": ["s3", "kms"],
        "availableServices": ["s3", "kms", "iam", "secrets-manager"],
        "explanation": "O AWS Key Management Service (KMS) permite criar e gerenciar chaves criptográficas e controlar seu uso em uma ampla gama de serviços da AWS. Ao configurar a criptografia do lado do servidor (SSE) em um bucket S3, você pode especificar uma chave gerenciada pelo cliente (CMK) do KMS, dando a você controle total sobre a chave usada para criptografar e descriptografar seus objetos."
    },
    {
        "id": "aws-de-033",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Crie uma arquitetura que receba eventos de mudança de múltiplos microsserviços e os direcione para diferentes alvos (Lambdas, filas SQS) com base no conteúdo do evento, usando um barramento de eventos centralizado.",
        "solution": ["eventbridge", [["lambda"], ["sqs"]]],
        "availableServices": ["eventbridge", "lambda", "sqs", "sns", "kinesis"],
        "explanation": "O Amazon EventBridge é um barramento de eventos serverless que facilita a conexão de aplicações com dados de uma variedade de fontes. Você pode criar regras no barramento de eventos que filtram os eventos com base em seu conteúdo (o payload do evento) e os encaminham para alvos específicos, como uma função Lambda para processamento imediato ou uma fila SQS para processamento em lote."
    },
    {
        "id": "aws-de-034",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Desenvolva uma solução de recomendação de produtos para um site de e-commerce. O serviço deve ser treinado com dados de interação do usuário e fornecer recomendações em tempo real via API.",
        "solution": ["s3", "personalize", "api-gateway", "lambda"],
        "availableServices": ["s3", "personalize", "sagemaker", "api-gateway", "lambda"],
        "explanation": "O Amazon Personalize é um serviço de machine learning totalmente gerenciado que facilita a criação de recomendações personalizadas para os clientes. Você fornece os dados de atividade (do S3), e o Personalize processa os dados, identifica o que é significativo, treina e otimiza um modelo de personalização. O modelo treinado pode ser exposto via uma API, que pode ser chamada por uma Lambda acionada pelo API Gateway para fornecer recomendações em tempo real."
    },
    {
        "id": "aws-de-035",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Projete uma arquitetura para executar um cluster Kubernetes para processamento de dados em contêineres, sem gerenciar o plano de controle (control plane) do Kubernetes. O processamento deve ser acionado por um evento.",
        "solution": ["eventbridge", "eks", "fargate"],
        "availableServices": ["eventbridge", "eks", "fargate", "ec2", "ecs"],
        "explanation": "O Amazon EKS (Elastic Kubernetes Service) é o serviço gerenciado de Kubernetes da AWS. Ele gerencia o control plane para você. Para uma abordagem serverless, você pode usar o AWS Fargate com o EKS para executar os pods do Kubernetes sem precisar provisionar e gerenciar servidores (nós de trabalho). Um evento no EventBridge pode acionar um mecanismo (como uma Lambda) que cria um Kubernetes Job no cluster EKS/Fargate para executar o processamento."
    },
    {
        "id": "aws-de-036",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Um aplicativo precisa de um banco de dados relacional que seja totalmente gerenciado pela AWS, cuidando de tarefas como provisionamento, patches e backups. Qual é o serviço fundamental para isso?",
        "solution": ["rds"],
        "availableServices": ["rds", "ec2", "aurora", "dynamodb"],
        "explanation": "O Amazon RDS (Relational Database Service) é um serviço gerenciado que facilita a configuração, operação e escalabilidade de bancos de dados relacionais na nuvem. Ele automatiza tarefas de administração demoradas, permitindo que você se concentre em suas aplicações e dados."
    },
    {
        "id": "aws-de-037",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Crie um sistema que permita aos usuários fazerem login e se registrarem em sua aplicação de análise de dados, gerenciando identidades e federação com provedores sociais. O acesso aos recursos da AWS, como dashboards do QuickSight, deve ser controlado por meio dessa autenticação.",
        "solution": ["cognito", "quicksight"],
        "availableServices": ["cognito", "quicksight", "iam", "lambda"],
        "explanation": "O Amazon Cognito fornece autenticação, autorização e gerenciamento de usuários para suas aplicações web e móveis. Ele permite que os usuários façam login com nome de usuário e senha, ou por meio de um terceiro, como Facebook ou Google. Após a autenticação, o Cognito pode fornecer credenciais temporárias da AWS para acessar outros serviços, como o QuickSight, de forma segura."
    },
    {
        "id": "aws-de-038",
        "category": "cloud-operations",
        "difficulty": 2,
        "question": "Qual serviço da AWS atua como um DNS (Domain Name System) para traduzir nomes de domínio legíveis por humanos (como www.exemplo.com) em endereços IP?",
        "solution": ["route 53"],
        "availableServices": ["route 53", "cloudfront", "ec2", "api-gateway"],
        "explanation": "O Amazon Route 53 é um serviço web de DNS na nuvem, altamente disponível e escalável. Ele foi projetado para oferecer aos desenvolvedores e empresas uma maneira extremamente confiável e econômica de direcionar os usuários finais para aplicações na Internet."
    },
    {
        "id": "aws-de-039",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Você tem um pipeline que processa dados e os armazena em um bucket S3. Como você pode garantir que apenas usuários e roles específicos do IAM tenham permissão para ler ou escrever nesse bucket?",
        "solution": ["s3", "iam"],
        "availableServices": ["s3", "iam", "kms", "lake-formation"],
        "explanation": "O AWS IAM (Identity and Access Management) é o serviço usado para gerenciar o acesso aos serviços e recursos da AWS com segurança. Você pode criar políticas do IAM que definem permissões e anexá-las a usuários, grupos ou roles. Além disso, você pode usar Bucket Policies (um tipo de política baseada em recursos do IAM) diretamente no bucket S3 para controlar o acesso."
    },
    {
        "id": "aws-de-040",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Orquestre um processo de ETL complexo com dependências: um job A (Glue) deve ser executado primeiro. Se for bem-sucedido, os jobs B (Glue) e C (Lambda) devem ser executados em paralelo. Se A falhar, uma notificação de erro deve ser enviada.",
        "solution": [{"orchestrator": "step-functions", "flow": ["glue", [["glue"], ["lambda"]], "sns"]}],
        "availableServices": ["step-functions", "glue", "lambda", "sns", "mwaa"],
        "explanation": "O AWS Step Functions é perfeito para orquestrar fluxos de trabalho com lógica condicional e paralelismo. Você pode definir um fluxo onde o primeiro estado executa o job A. Usando um estado 'Choice', você pode direcionar o fluxo para um estado 'Parallel' (executando B e C) em caso de sucesso, ou para um estado de notificação SNS em caso de falha, utilizando os recursos de tratamento de erros do Step Functions."
    },
    {
        "id": "aws-de-041",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Projete uma arquitetura para coletar logs de várias instâncias EC2, centralizá-los e permitir consultas SQL para análise de padrões e erros.",
        "solution": ["ec2", "kinesis-firehose", "s3", "athena"],
        "availableServices": ["ec2", "kinesis-firehose", "s3", "athena", "cloudwatch", "glue"],
        "explanation": "Você pode instalar o Agente do Kinesis nas instâncias EC2 para enviar os logs para um stream do Kinesis Data Firehose. O Firehose pode agregar os logs e entregá-los a um bucket S3 em um formato colunar (como Parquet) para otimização de custos e performance. Com os dados no S3, o Athena pode ser usado para executar consultas SQL ad-hoc diretamente nos arquivos de log."
    },
    {
        "id": "aws-de-042",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Um job de ETL que roda em uma função Lambda precisa acessar credenciais de um banco de dados Redshift. Qual a forma mais segura de prover essas credenciais para a função?",
        "solution": ["lambda", "secrets-manager", "redshift"],
        "availableServices": ["lambda", "secrets-manager", "redshift", "iam", "kms"],
        "explanation": "A melhor prática é armazenar as credenciais do Redshift no AWS Secrets Manager. A função Lambda receberia uma role do IAM com permissão para ler o segredo específico. Dentro do código da função, você usaria o SDK da AWS para buscar as credenciais do Secrets Manager em tempo de execução, evitando que elas sejam expostas no código ou em variáveis de ambiente."
    },
    {
        "id": "aws-de-043",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Crie um pipeline que ingere dados de streaming, aplica uma transformação simples (ex: filtragem de campos) e os armazena em um banco de dados NoSQL para acesso rápido. Toda a arquitetura deve ser serverless.",
        "solution": ["kinesis", "lambda", "dynamodb"],
        "availableServices": ["kinesis", "lambda", "dynamodb", "ec2", "rds"],
        "explanation": "Esta é uma arquitetura serverless de streaming clássica. O Kinesis Data Streams ingere os dados. Uma função Lambda é configurada como consumidor do stream, sendo invocada automaticamente com lotes de registros. A função executa a lógica de transformação e, em seguida, grava os resultados no DynamoDB, que fornece o armazenamento NoSQL serverless e de baixa latência."
    },
    {
        "id": "aws-de-044",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Você precisa replicar uma tabela de um banco de dados Aurora em uma região para outra para fins de recuperação de desastres e, ao mesmo tempo, alimentar um Data Lake (S3) na segunda região.",
        "solution": ["aurora", "dms", [["aurora"], ["s3"]]],
        "availableServices": ["aurora", "dms", "s3", "lambda", "redshift"],
        "explanation": "O AWS DMS pode ser configurado para replicação contínua (Change Data Capture - CDC). Você pode configurar uma tarefa de replicação do DMS com a instância Aurora na região de origem como fonte. O DMS pode ter múltiplos endpoints de destino. Um endpoint seria a instância Aurora na região de destino, e o outro seria um bucket S3 na mesma região de destino, alcançando ambos os objetivos com uma única ferramenta."
    },
    {
        "id": "aws-de-045",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Como você pode automatizar a descoberta de esquema e o versionamento de tabelas para dados que chegam continuamente a um bucket S3?",
        "solution": ["s3", "glue"],
        "availableServices": ["s3", "glue", "lambda", "athena"],
        "explanation": "O AWS Glue Crawler pode ser configurado para rodar de forma agendada. A cada execução, ele varre as novas partições ou arquivos no S3, detecta mudanças de esquema e atualiza a definição da tabela no Glue Data Catalog, versionando o esquema. Isso garante que ferramentas como o Athena sempre consultem a estrutura de dados mais recente."
    },
    {
        "id": "aws-de-046",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Construa uma arquitetura que sirva um modelo de machine learning (pré-treinado) através de um endpoint HTTP. A infraestrutura para hospedar o modelo deve ser totalmente gerenciada.",
        "solution": ["sagemaker", "api-gateway", "lambda"],
        "availableServices": ["sagemaker", "api-gateway", "lambda", "ec2", "ecs"],
        "explanation": "Você pode implantar o modelo treinado usando o Amazon SageMaker para criar um endpoint de inferência gerenciado. Para expor este endpoint de forma segura e escalável, você pode usar o API Gateway, que recebe as requisições HTTP. Uma função Lambda pode atuar como uma camada de integração entre o API Gateway e o endpoint do SageMaker, tratando da formatação da requisição e da resposta."
    },
    {
        "id": "aws-de-047",
        "category": "data-engineering",
        "difficulty": 2,
        "question": "Você precisa executar um script de transformação de dados que leva 20 minutos para rodar, uma vez por dia. Uma instância EC2 seria um desperdício de recursos. Qual serviço de computação serverless é ideal para tarefas de longa duração (até 15 minutos)?",
        "solution": ["lambda"],
        "availableServices": ["lambda", "ec2", "fargate", "step-functions"],
        "explanation": "O AWS Lambda suporta tempos de execução de até 15 minutos, o que o torna uma opção viável para muitas tarefas de ETL e processamento de dados que não justificam uma infraestrutura permanentemente ativa. Para execuções mais longas, outras opções como Fargate ou Glue seriam mais adequadas."
    },
    {
        "id": "aws-de-048",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Projete uma solução para análise de sentimento em tempo real de tweets sobre sua marca. Os tweets são ingeridos, seu sentimento é analisado por um serviço de IA, e os resultados são visualizados em um dashboard.",
        "solution": ["kinesis", "lambda", "comprehend", "opensearch", "quicksight"],
        "availableServices": ["kinesis", "lambda", "comprehend", "opensearch", "quicksight", "s3"],
        "explanation": "Uma aplicação (não inclusa) enviaria os tweets para um Kinesis Data Stream. Uma função Lambda consome o stream, envia o texto de cada tweet para o Amazon Comprehend para análise de sentimento. A Lambda então armazena o tweet e o resultado do sentimento (positivo, negativo, neutro) no Amazon OpenSearch para indexação. Finalmente, o QuickSight pode se conectar ao OpenSearch para criar dashboards e visualizar os dados em tempo real."
    },
    {
        "id": "aws-de-049",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Como você implementaria um pipeline simples de extração, carregamento e transformação (ELT)? Os dados são primeiro carregados de uma fonte para o S3 e depois transformados usando SQL diretamente no data warehouse.",
        "solution": ["dms", "s3", "redshift"],
        "availableServices": ["dms", "s3", "redshift", "glue", "lambda"],
        "explanation": "No padrão ELT, a transformação ocorre no destino. O DMS (ou outra ferramenta de ingestão) extrai e carrega os dados brutos no S3 (Extract, Load). Em seguida, o comando COPY do Redshift carrega os dados do S3 para tabelas de staging. A transformação (Transform) é então realizada usando procedimentos armazenados ou scripts SQL que rodam diretamente no Redshift, movendo os dados das tabelas de staging para as tabelas finais."
    },
    {
        "id": "aws-de-050",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Orquestre um pipeline de dados usando uma ferramenta visual de arrastar e soltar, que gerencia a execução de jobs, gatilhos e tratamento de erros. O pipeline move dados do S3 para o Redshift.",
        "solution": [{"orchestrator": "glue", "flow": ["s3", "redshift"]}],
        "availableServices": ["glue", "s3", "redshift", "step-functions", "lambda"],
        "explanation": "O AWS Glue Studio oferece uma interface gráfica de arrastar e soltar (drag-and-drop) para criar, executar e monitorar jobs de ETL. Você pode visualmente definir uma fonte (S3), aplicar transformações e especificar um destino (Redshift), e o Glue Studio gera o código Spark correspondente e orquestra a execução do job."
    },
    {
        "id": "aws-de-051",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Armazene dados de eventos de IoT com carimbos de data/hora (timestamps) para análises de tendências ao longo do tempo. Qual banco de dados da AWS é especificamente otimizado para esse tipo de dado de série temporal?",
        "solution": ["timestream"],
        "availableServices": ["timestream", "dynamodb", "rds", "redshift"],
        "explanation": "O Amazon Timestream é um serviço de banco de dados de séries temporais rápido, escalável e serverless para aplicações de IoT e operacionais. Ele facilita o armazenamento e a análise de trilhões de eventos por dia, com custo até 1.000 vezes menor do que o de bancos de dados relacionais."
    },
    {
        "id": "aws-de-052",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Um processo batch precisa ser executado em um contêiner. A execução é esporádica e você quer pagar apenas pelo tempo de execução do contêiner, sem se preocupar com a infraestrutura subjacente. O contêiner precisa de 8GB de RAM.",
        "solution": ["fargate"],
        "availableServices": ["fargate", "lambda", "ec2", "ecs"],
        "explanation": "O AWS Fargate é a escolha ideal. O Lambda tem um limite de memória (atualmente 10GB, mas Fargate é mais flexível para cargas maiores) e é mais focado em funções, enquanto o Fargate é projetado para executar contêineres de forma serverless. Você define os requisitos de CPU e memória da sua tarefa e o Fargate a executa, cobrando apenas pelos recursos consumidos durante a execução."
    },
    {
        "id": "aws-de-053",
        "category": "cloud-operations",
        "difficulty": 5,
        "question": "Crie um fluxo de trabalho que, após o upload de um vídeo no S3, inicie transcodificações para diferentes resoluções em paralelo. Quando todas terminarem, atualize um registro no DynamoDB com os links para os novos arquivos e envie uma notificação. O fluxo deve ser resiliente a falhas em uma das transcodificações.",
        "solution": ["s3", {"orchestrator": "step-functions", "flow": [[["lambda"], ["lambda"], ["lambda"]], "dynamodb", "sns"]}],
        "availableServices": ["s3", "step-functions", "lambda", "dynamodb", "sns", "sqs"],
        "explanation": "O S3 aciona o Step Functions. Um estado 'Parallel' no Step Functions invoca múltiplas instâncias de uma função Lambda (ou diferentes funções) para cada resolução de transcodificação. O Step Functions aguarda a conclusão de todos os ramos paralelos. Com seu tratamento de erros integrado, ele pode capturar falhas. Se todos forem bem-sucedidos, ele prossegue para atualizar o DynamoDB e enviar a notificação via SNS."
    },
    {
        "id": "aws-de-054",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Você precisa consultar dados que estão em um banco de dados Aurora e, ao mesmo tempo, dados que estão em um bucket S3, em uma única consulta SQL. Qual serviço permite essa consulta federada?",
        "solution": ["athena"],
        "availableServices": ["athena", "aurora", "s3", "redshift", "glue"],
        "explanation": "O Amazon Athena suporta consultas federadas, permitindo que você execute consultas SQL em dados armazenados em fontes de dados relacionais, não relacionais, de objeto e personalizadas. Usando conectores de fonte de dados, o Athena pode se conectar ao Aurora e ao S3 (via Glue Catalog) e executar uma única consulta que une os dados de ambas as fontes."
    },
    {
        "id": "aws-de-055",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Como você pode carregar um stream de dados JSON no Redshift em tempo real, realizando uma conversão para um formato colunar (como Parquet) antes do carregamento para otimizar o armazenamento e as consultas?",
        "solution": ["kinesis", "kinesis-firehose", "s3", "redshift"],
        "availableServices": ["kinesis", "kinesis-firehose", "s3", "redshift", "lambda"],
        "explanation": "O Kinesis Data Streams ingere os dados JSON. Um Kinesis Data Firehose pode ser configurado para consumir desse stream. O Firehose tem um recurso integrado de conversão de formato de registro, que pode transformar os dados JSON de entrada para Parquet. Ele então entrega os arquivos Parquet convertidos para um bucket S3. A partir daí, o comando COPY do Redshift pode carregar os dados de forma altamente eficiente a partir do S3."
    },
    {
        "id": "aws-de-056",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Projete um pipeline de dados que use Apache Spark em um ambiente serverless para transformar dados. A orquestração do pipeline é feita com base em eventos e deve seguir uma lógica de passos sequenciais.",
        "solution": ["eventbridge", {"orchestrator": "step-functions", "flow": ["glue", "s3"]}],
        "availableServices": ["eventbridge", "step-functions", "glue", "s3", "emr", "lambda"],
        "explanation": "O EventBridge captura o evento inicial e aciona a máquina de estados do Step Functions. O Step Functions orquestra o fluxo. Para executar Spark de forma serverless, o AWS Glue é a escolha ideal. O Step Functions inicia o job do Glue. Após a conclusão bem-sucedida do job, o Step Functions pode prosseguir para a próxima etapa, como mover os dados processados para um local final no S3 ou acionar outra ação."
    },
    {
        "id": "aws-de-057",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Sua aplicação está crescendo e o banco de dados RDS está se tornando um gargalo de leitura. Como você pode escalar a capacidade de leitura do banco de dados sem alterar a instância principal?",
        "solution": ["rds"],
        "availableServices": ["rds", "elasticache", "dms", "aurora"],
        "explanation": "O Amazon RDS permite criar facilmente uma ou mais 'Réplicas de Leitura' (Read Replicas) de sua instância de banco de dados principal. As réplicas de leitura são cópias assíncronas da instância principal que podem ser usadas para descarregar as consultas de leitura, liberando a instância principal para lidar com as operações de escrita."
    },
    {
        "id": "aws-de-058",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Crie uma arquitetura para processar arquivos grandes (ex: 50 GB) que são enviados para o S3. Uma função Lambda não é adequada devido aos limites de tempo de execução e armazenamento. O processamento deve ser em contêineres e serverless.",
        "solution": ["s3", "sqs", "fargate"],
        "availableServices": ["s3", "sqs", "fargate", "lambda", "ecs"],
        "explanation": "O upload no S3 pode acionar um evento que envia uma mensagem para uma fila SQS com os detalhes do arquivo. Um serviço ECS configurado com o tipo de inicialização Fargate pode ser configurado para escalar com base no número de mensagens na fila. Uma tarefa do Fargate (contêiner) pega a mensagem, baixa o arquivo do S3, processa-o e, em seguida, exclui a mensagem da fila. Isso lida com arquivos grandes e processamento de longa duração de forma robusta e serverless."
    },
    {
        "id": "aws-de-059",
        "category": "data-engineering",
        "difficulty": 2,
        "question": "Você precisa executar consultas SQL simples e rápidas em arquivos JSON e Parquet armazenados no S3 sem a necessidade de configurar servidores ou um data warehouse. Qual serviço é o mais indicado?",
        "solution": ["s3", "athena"],
        "availableServices": ["s3", "athena", "redshift", "emr", "ec2"],
        "explanation": "O Amazon Athena é um serviço de consulta interativo que facilita a análise de dados no Amazon S3 usando SQL padrão. O Athena é serverless, portanto, não há infraestrutura para gerenciar e você paga apenas pelas consultas que executa."
    },
    {
        "id": "aws-de-060",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Construa um pipeline para um sistema de detecção de fraudes. Transações chegam a um stream, são enriquecidas com dados de um banco de dados NoSQL e, em seguida, pontuadas por um modelo de machine learning. Transações suspeitas geram um alerta.",
        "solution": ["kinesis", "lambda", "dynamodb", "sagemaker", "sns"],
        "availableServices": ["kinesis", "lambda", "dynamodb", "sagemaker", "sns", "s3"],
        "explanation": "As transações fluem pelo Kinesis Data Streams. Uma função Lambda consome o stream, busca dados adicionais do cliente no DynamoDB para enriquecimento. A Lambda então chama um endpoint do SageMaker com os dados enriquecidos para obter uma pontuação de fraude. Se a pontuação exceder um limite, a Lambda publica uma mensagem em um tópico SNS para alertar a equipe de fraude."
    },
    {
        "id": "aws-de-061",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Você precisa armazenar dados que raramente são acessados, mas que devem ser mantidos por 7 anos por questões de conformidade. O custo de armazenamento é a principal preocupação. Qual classe de armazenamento do S3 ou serviço relacionado é a melhor escolha?",
        "solution": ["s3", "glacier"],
        "availableServices": ["s3", "glacier", "ebs", "efs"],
        "explanation": "O Amazon S3 Glacier Deep Archive é a classe de armazenamento de menor custo da AWS e foi projetada para retenção de dados a longo prazo (anos). Você pode usar as políticas de ciclo de vida do S3 para transicionar objetos automaticamente para o Glacier Deep Archive para otimização de custos."
    },
    {
        "id": "aws-de-062",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Projete uma arquitetura de streaming que processe logs de acesso em tempo real, identifique endereços IP maliciosos usando uma consulta SQL contínua em uma janela de tempo e os adicione a uma lista de bloqueio em um banco de dados.",
        "solution": ["kinesis", "kinesis-analytics", "lambda", "dynamodb"],
        "availableServices": ["kinesis", "kinesis-analytics", "lambda", "dynamodb", "athena", "s3"],
        "explanation": "Os logs de acesso são enviados para o Kinesis Data Streams. O Kinesis Data Analytics executa uma consulta SQL contínua que, por exemplo, conta as tentativas de login falhas de cada IP em uma janela de 5 minutos. Quando a contagem excede um limite, ele emite um resultado. Uma função Lambda, configurada como destino, recebe esse resultado e atualiza uma tabela no DynamoDB que serve como a lista de bloqueio."
    },
    {
        "id": "aws-de-063",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Uma aplicação gera eventos que são publicados em um tópico SNS. Você precisa garantir que esses eventos sejam processados de forma durável e na ordem em que foram recebidos para um grupo específico de consumidores. Como você pode estender a arquitetura?",
        "solution": ["sns", "sqs"],
        "availableServices": ["sns", "sqs", "lambda", "kinesis"],
        "explanation": "Para garantir a ordem, você pode usar uma fila SQS FIFO (First-In, First-Out). Inscreva a fila SQS FIFO no tópico SNS. Embora o SNS em si não garanta a ordem, ao usar uma fila FIFO como consumidor, você pode processar as mensagens na ordem exata em que chegam à fila para um determinado ID de grupo de mensagens."
    },
    {
        "id": "aws-de-064",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Um job de ETL do AWS Glue precisa de uma dependência Python que não está incluída no ambiente padrão do Glue. Como você pode fornecer essa dependência para o seu job?",
        "solution": ["s3", "glue"],
        "availableServices": ["s3", "glue", "ec2", "lambda"],
        "explanation": "Você pode empacotar a dependência Python (por exemplo, em um arquivo .whl ou .zip), fazer o upload para um bucket S3 e, em seguida, especificar o caminho do S3 para esse pacote nas configurações do job do Glue no parâmetro 'Python library path' ou 'Dependent jars path'."
    },
    {
        "id": "aws-de-065",
        "category": "cloud-operations",
        "difficulty": 4,
        "question": "Automatize a criação de uma infraestrutura de data lake básica (S3, Glue Crawler, permissões do IAM) toda vez que um novo projeto é iniciado. A definição da infraestrutura deve ser versionada em um repositório de código.",
        "solution": ["codecommit", "codepipeline", "cloudformation"],
        "availableServices": ["codecommit", "codepipeline", "cloudformation", "s3", "glue", "iam"],
        "explanation": "Você pode definir toda a infraestrutura em um template do AWS CloudFormation. Armazene este template no AWS CodeCommit. Crie um AWS CodePipeline que é acionado por commits neste repositório. O pipeline pode ter um estágio de implantação que executa o template do CloudFormation para criar ou atualizar a stack de recursos, garantindo uma implantação consistente e automatizada (GitOps)."
    },
    {
        "id": "aws-de-066",
        "category": "data-engineering",
        "difficulty": 2,
        "question": "Você precisa de um banco de dados relacional para um novo aplicativo web, mas quer minimizar o gerenciamento. Qual serviço oferece bancos de dados como MySQL, PostgreSQL ou SQL Server como um serviço gerenciado?",
        "solution": ["rds"],
        "availableServices": ["rds", "ec2", "dynamodb", "redshift"],
        "explanation": "O Amazon RDS (Relational Database Service) é a escolha padrão para bancos de dados relacionais gerenciados na AWS. Ele suporta vários mecanismos de banco de dados populares e automatiza tarefas de administração, como patches de software, backups e failover."
    },
    {
        "id": "aws-de-067",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Projete uma arquitetura que permita que analistas de dados executem jobs Spark interativamente em um ambiente gerenciado, usando notebooks Jupyter. Os dados para análise estão em um Data Lake no S3.",
        "solution": ["s3", "emr"],
        "availableServices": ["s3", "emr", "sagemaker", "glue", "ec2"],
        "explanation": "O Amazon EMR (Elastic MapReduce) pode ser configurado com o EMR Notebooks, que fornece um ambiente Jupyter Notebook gerenciado. O notebook se conecta a um cluster EMR que tem Spark instalado. Isso permite que os analistas escrevam e executem código Spark interativamente contra os dados no S3, ideal para exploração e desenvolvimento de jobs."
    },
    {
        "id": "aws-de-068",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Crie uma API REST que permita aos usuários consultar dados de uma tabela DynamoDB. A API deve ser segura e escalável.",
        "solution": ["api-gateway", "lambda", "dynamodb"],
        "availableServices": ["api-gateway", "lambda", "dynamodb", "rds", "ec2"],
        "explanation": "O Amazon API Gateway é usado para criar e gerenciar a API REST. Cada endpoint (por exemplo, /users/{id}) pode ser integrado a uma função AWS Lambda. A função Lambda contém a lógica de negócios para consultar a tabela DynamoDB com base nos parâmetros recebidos da API Gateway e retorna o resultado. Essa arquitetura é totalmente serverless, escalável e segura."
    },
    {
        "id": "aws-de-069",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Como você pode consolidar dados de várias fontes (por exemplo, um banco de dados RDS e arquivos em S3) em um único local para análise complexa e relatórios, usando um serviço de data warehousing colunar?",
        "solution": [["rds", "dms", "redshift"], ["s3", "redshift"]],
        "availableServices": ["rds", "dms", "s3", "redshift", "glue", "athena"],
        "explanation": "O Amazon Redshift é um serviço de data warehousing em escala de petabytes. Você pode usar o AWS DMS para replicar dados do RDS para o Redshift. Para os dados do S3, você pode usar o comando COPY do Redshift, que é altamente otimizado para carregar dados de forma massiva. Isso centraliza os dados de ambas as fontes no Redshift para análise."
    },
    {
        "id": "aws-de-070",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Orquestre um pipeline onde um arquivo de dados é colocado no S3. Isso aciona um job do Glue para validação. Se a validação for aprovada, outro job do Glue é acionado para processamento. Se falhar, uma notificação é enviada. Use um serviço de orquestração de fluxo de trabalho.",
        "solution": ["s3", {"orchestrator": "step-functions", "flow": ["glue", "glue", "sns"]}],
        "availableServices": ["s3", "step-functions", "glue", "sns", "lambda", "eventbridge"],
        "explanation": "O upload no S3 pode acionar uma máquina de estados do Step Functions. O primeiro estado invoca o job de validação do Glue. Um estado 'Choice' verifica o resultado do job. Se for 'SUCESSO', ele transita para um estado que invoca o job de processamento do Glue. Se for 'FALHA', ele transita para um estado que publica uma mensagem em um tópico SNS."
    },
    {
        "id": "aws-de-071",
        "category": "data-engineering",
        "difficulty": 2,
        "question": "Qual é a maneira mais simples e totalmente gerenciada de enviar dados de um stream do Kinesis Data Streams para o Amazon S3, OpenSearch ou Redshift sem escrever código de consumidor?",
        "solution": ["kinesis", "kinesis-firehose"],
        "availableServices": ["kinesis", "kinesis-firehose", "lambda", "ec2"],
        "explanation": "O Kinesis Data Firehose pode ser configurado como um consumidor direto de um Kinesis Data Stream. Ele lida com a leitura do stream, o buffer dos dados, a conversão de formato (opcional) e a entrega confiável aos destinos suportados, como S3, OpenSearch e Redshift, eliminando a necessidade de desenvolver e gerenciar uma aplicação consumidora."
    },
    {
        "id": "aws-de-072",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Construa um sistema para governança centralizada de um Data Lake. Ele deve registrar todos os ativos de dados, impor políticas de acesso refinadas (nível de coluna) e auditar o acesso aos dados, tudo isso gerenciando permissões para Glue, Athena e Redshift Spectrum.",
        "solution": ["s3", "lake-formation"],
        "availableServices": ["s3", "lake-formation", "iam", "glue", "athena"],
        "explanation": "O AWS Lake Formation é o serviço projetado exatamente para isso. Você registra seus buckets S3 no Lake Formation, que então utiliza o Glue Data Catalog para metadados. No Lake Formation, você pode conceder e revogar permissões granulares para usuários e roles do IAM, que são então aplicadas de forma consistente quando esses principais tentam acessar os dados através de serviços integrados como Athena, Glue e Redshift Spectrum."
    },
    {
        "id": "aws-de-073",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Um painel de análise precisa exibir dados atualizados a cada hora. Os dados brutos estão no S3. Qual combinação de serviços pode processar os dados em lote e alimentar um serviço de BI?",
        "solution": ["s3", "glue", "redshift", "quicksight"],
        "availableServices": ["s3", "glue", "redshift", "quicksight", "athena", "lambda"],
        "explanation": "Um job do AWS Glue pode ser agendado para ser executado a cada hora. O job lê os novos dados do S3, os transforma e os anexa a uma tabela no Amazon Redshift. O Amazon QuickSight pode então se conectar ao Redshift para alimentar os painéis com os dados atualizados."
    },
    {
        "id": "aws-de-074",
        "category": "cloud-operations",
        "difficulty": 4,
        "question": "Crie um sistema de alerta que monitore um bucket S3 e notifique uma equipe de segurança via SNS sempre que um objeto for tornado público.",
        "solution": ["s3", "eventbridge", "sns"],
        "availableServices": ["s3", "eventbridge", "sns", "cloudwatch", "lambda"],
        "explanation": "Você pode usar o AWS CloudTrail para registrar chamadas de API, como 'PutBucketAcl'. Em seguida, crie uma regra no Amazon EventBridge que corresponda a este evento específico quando a ACL for definida como pública. A regra do EventBridge pode ter como alvo um tópico SNS, que então envia a notificação para a equipe de segurança."
    },
    {
        "id": "aws-de-075",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Migre um banco de dados MySQL de 2 TB de um data center on-premise para o Amazon Aurora com o mínimo de tempo de inatividade (downtime).",
        "solution": ["dms"],
        "availableServices": ["dms", "aurora", "s3", "glue"],
        "explanation": "O AWS Database Migration Service (DMS) é a ferramenta ideal para isso. Você pode realizar uma carga inicial completa do banco de dados e, em seguida, configurar uma tarefa de replicação contínua (Change Data Capture - CDC). O DMS captura as alterações no banco de dados de origem e as aplica ao destino (Aurora) em tempo real. Isso permite que você mude o tráfego da aplicação para o novo banco de dados com um tempo de inatividade mínimo."
    },
    {
        "id": "aws-de-076",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Qual é a maneira mais econômica de executar um cluster Hadoop (com Spark e Hive) para um trabalho de processamento em lote que leva 3 horas para ser executado todas as noites?",
        "solution": ["emr"],
        "availableServices": ["emr", "ec2", "glue", "fargate"],
        "explanation": "O Amazon EMR (Elastic MapReduce) permite que você provisione clusters Hadoop sob demanda. Para um trabalho noturno, você pode iniciar um cluster EMR, executar o trabalho e encerrar o cluster automaticamente quando terminar. Isso significa que você paga apenas pelas 3 horas em que o cluster está em execução, tornando-o muito mais econômico do que manter instâncias EC2 funcionando 24/7."
    },
    {
        "id": "aws-de-077",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Um serviço externo envia webhooks para sua aplicação. Projete uma arquitetura serverless e resiliente para receber esses webhooks, enfileirá-los para processamento e, em seguida, armazená-los no S3.",
        "solution": ["api-gateway", "sqs", "lambda", "s3"],
        "availableServices": ["api-gateway", "sqs", "lambda", "s3", "sns", "kinesis"],
        "explanation": "O API Gateway fornece um endpoint HTTP para receber os webhooks. Ele pode ser integrado diretamente com o SQS para enfileirar as solicitações recebidas. Isso desacopla a ingestão do processamento e absorve picos de tráfego. Uma função Lambda é acionada por mensagens na fila SQS, processa o webhook e armazena o payload no S3 para arquivamento e análise posterior."
    },
    {
        "id": "aws-de-078",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Você tem um stream de eventos de um jogo online em um cluster MSK (Kafka). Crie um pipeline que leia esses eventos, execute agregações complexas (por exemplo, pontuações médias por jogador em janelas de tempo) e envie os resultados para um dashboard em tempo real.",
        "solution": ["msk", "kinesis-analytics", "lambda", "opensearch"],
        "availableServices": ["msk", "kinesis-analytics", "lambda", "opensearch", "quicksight", "glue"],
        "explanation": "O Kinesis Data Analytics for Apache Flink pode se conectar diretamente a um cluster MSK como fonte. Você pode escrever uma aplicação Flink para realizar as agregações com estado e em janelas de tempo. A aplicação Flink pode usar um 'sink' para enviar os resultados agregados para uma função Lambda. A Lambda, por sua vez, insere os dados no Amazon OpenSearch, que pode ser usado como fonte para um dashboard de monitoramento em tempo real (como OpenSearch Dashboards ou Grafana)."
    },
    {
        "id": "aws-de-079",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Como você pode expor um conjunto de dados do seu data warehouse Redshift através de uma API para que outras aplicações possam consumi-lo de forma segura e controlada?",
        "solution": ["redshift", "lambda", "api-gateway"],
        "availableServices": ["redshift", "lambda", "api-gateway", "dms", "appsync"],
        "explanation": "Você pode criar um API Gateway para definir os endpoints da sua API de dados. Cada endpoint aciona uma função Lambda. A função Lambda contém a lógica para se conectar ao cluster Redshift (usando o Data API do Redshift para facilitar), executar a consulta SQL necessária com base nos parâmetros da API e formatar o resultado como uma resposta JSON. Isso fornece uma camada de abstração segura e escalável sobre o seu data warehouse."
    },
    {
        "id": "aws-de-080",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Um fluxo de trabalho precisa executar uma série de funções Lambda em sequência. A saída de uma função é a entrada da próxima. O fluxo de trabalho inteiro não deve exceder 30 minutos. Como você orquestraria isso de forma confiável?",
        "solution": [{"orchestrator": "step-functions", "flow": ["lambda", "lambda", "lambda"]}],
        "availableServices": ["step-functions", "lambda", "sqs", "sns", "eventbridge"],
        "explanation": "O AWS Step Functions é ideal para orquestrar sequências de funções Lambda (ou outros serviços). Você pode definir uma 'máquina de estados' que executa cada Lambda em um estado sequencial. O Step Functions gerencia o estado, passa a saída de uma etapa como entrada para a próxima, lida com erros e timeouts, e tem um tempo máximo de execução de até um ano, acomodando facilmente os 30 minutos necessários."
    },
    {
        "id": "aws-de-081",
        "category": "data-engineering",
        "difficulty": 1,
        "question": "Qual é o serviço de armazenamento de objetos fundamental e mais comum na AWS, usado para uma ampla variedade de casos de uso, como data lakes, backups e hospedagem de sites estáticos?",
        "solution": ["s3"],
        "availableServices": ["s3", "ebs", "efs", "glacier"],
        "explanation": "O Amazon S3 (Simple Storage Service) é o serviço de armazenamento de objetos da AWS. Ele oferece escalabilidade, disponibilidade de dados, segurança e desempenho líderes do setor, tornando-se a base para a maioria das arquiteturas de dados na AWS."
    },
    {
        "id": "aws-de-082",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Crie uma arquitetura para análise de dados de séries temporais provenientes de sensores industriais. Os dados devem ser ingeridos e armazenados em um banco de dados otimizado para esse fim, e depois visualizados em um painel.",
        "solution": ["iot-core", "timestream", "quicksight"],
        "availableServices": ["iot-core", "timestream", "quicksight", "rds", "dynamodb"],
        "explanation": "O AWS IoT Core pode ingerir os dados dos sensores. Uma regra no IoT Core pode encaminhar os dados diretamente para o Amazon Timestream. O Timestream é projetado para armazenar e consultar dados de séries temporais de forma eficiente. O Amazon QuickSight pode então se conectar ao Timestream como fonte de dados para criar painéis e visualizações."
    },
    {
        "id": "aws-de-083",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Um processo de negócio requer a aprovação de um gerente antes de prosseguir. Projete um fluxo de trabalho que inicie uma tarefa, pause e espere por uma aprovação externa (via API ou console), e depois continue ou pare com base na resposta.",
        "solution": [{"orchestrator": "step-functions", "flow": ["lambda", "sns"]}],
        "availableServices": ["step-functions", "lambda", "sns", "sqs", "api-gateway"],
        "explanation": "O AWS Step Functions suporta o padrão 'wait for a callback'. Você pode definir um estado de tarefa que invoca uma Lambda. Essa Lambda inicia a tarefa e, em seguida, o Step Functions pausa a execução. A Lambda pode enviar um e-mail com um link de aprovação. Quando o gerente aprova, um processo externo usa o 'task token' para enviar um sinal de sucesso de volta ao Step Functions, que então retoma a execução. O SNS pode ser usado para a notificação inicial."
    },
    {
        "id": "aws-de-084",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Você precisa de um cache em memória para sua aplicação, com suporte para estruturas de dados avançadas como listas, hashes e conjuntos ordenados. Qual serviço gerenciado e qual mecanismo você escolheria?",
        "solution": ["elasticache"],
        "availableServices": ["elasticache", "dynamodb", "memorydb", "rds"],
        "explanation": "O Amazon ElastiCache for Redis é a escolha ideal. O ElastiCache é o serviço gerenciado, e o mecanismo Redis fornece o cache em memória com suporte robusto para múltiplas estruturas de dados, tornando-o extremamente flexível para casos de uso como placares, sessões e filas."
    },
    {
        "id": "aws-de-085",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Você precisa analisar dados em um data warehouse Redshift em conjunto com dados de log que estão sendo transmitidos em tempo real via Kinesis. Como você pode consultar ambos os conjuntos de dados de forma eficiente?",
        "solution": ["redshift", "kinesis"],
        "availableServices": ["redshift", "kinesis", "athena", "glue", "dms"],
        "explanation": "O Amazon Redshift suporta 'Materialized Views' que podem se integrar com o Kinesis Data Streams. Você pode criar uma visão materializada que consome e processa os dados do stream do Kinesis quase em tempo real. Isso permite que você execute consultas SQL no Redshift que unem os dados históricos do data warehouse com os dados de streaming mais recentes da visão materializada."
    },
    {
        "id": "aws-de-086",
        "category": "data-engineering",
        "difficulty": 2,
        "question": "Uma função Lambda precisa enviar notificações por e-mail, SMS e push para dispositivos móveis. Qual serviço permite que ela publique uma única mensagem que será entregue a múltiplos tipos de assinantes?",
        "solution": ["lambda", "sns"],
        "availableServices": ["lambda", "sns", "sqs", "ses"],
        "explanation": "O Amazon SNS (Simple Notification Service) é um serviço de mensagens publish/subscribe totalmente gerenciado. A Lambda pode publicar uma mensagem em um tópico SNS. Você pode ter diferentes tipos de 'assinaturas' para esse tópico, incluindo endpoints de e-mail, números de telefone (SMS) e endpoints de aplicativos móveis. O SNS cuida da entrega para cada assinante."
    },
    {
        "id": "aws-de-087",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Crie um pipeline de dados agendado usando o orquestrador preferido para engenheiros de dados (Airflow). O pipeline deve extrair dados de uma API, salvá-los no S3 e iniciar um job de transformação do Glue.",
        "solution": [{"orchestrator": "mwaa", "flow": ["s3", "glue"]}],
        "availableServices": ["mwaa", "s3", "glue", "lambda", "step-functions"],
        "explanation": "O MWAA (Managed Workflows for Apache Airflow) hospeda o ambiente Airflow. Uma DAG (Directed Acyclic Graph) no Airflow pode ser agendada para execução. A DAG conteria: 1) Um operador (como o PythonOperator) para chamar a API e salvar os dados no S3. 2) O `AwsGlueJobOperator` para iniciar o job do AWS Glue, esperando sua conclusão antes de prosseguir."
    },
    {
        "id": "aws-de-088",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Você está construindo um Data Lake e quer garantir que os dados armazenados no S3 sejam criptografados no lado do servidor. Você quer usar chaves de criptografia gerenciadas pela AWS, sem ter que gerenciar as chaves você mesmo. Qual é a configuração de criptografia mais simples no S3 para isso?",
        "solution": ["s3", "kms"],
        "availableServices": ["s3", "kms", "cloudhsm", "secrets-manager"],
        "explanation": "A criptografia do lado do servidor com chaves gerenciadas pelo AWS Key Management Service (SSE-KMS) é a abordagem recomendada. Ela oferece um equilíbrio entre simplicidade e controle. A AWS gerencia a chave mestra, mas você pode controlar o acesso a ela através de políticas do IAM e auditar seu uso via CloudTrail. A opção mais simples (SSE-S3) usa chaves gerenciadas pelo S3, mas o SSE-KMS oferece mais controle e recursos de auditoria."
    },
    {
        "id": "aws-de-089",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Implemente um padrão de 'Circuit Breaker' para uma chamada de API feita por uma função Lambda. Se a API externa falhar repetidamente, o 'circuito' deve 'abrir' e parar de fazer chamadas por um tempo. O estado do circuito deve ser compartilhado entre as execuções da Lambda.",
        "solution": ["lambda", "elasticache"],
        "availableServices": ["lambda", "elasticache", "dynamodb", "s3", "step-functions"],
        "explanation": "Para compartilhar o estado (aberto/fechado, contagem de falhas) entre as invocações concorrentes e independentes da Lambda, é necessário um armazenamento de estado externo e de baixa latência. O Amazon ElastiCache (Redis) é perfeito para isso. A Lambda pode verificar o estado do circuito no Redis antes de chamar a API, incrementar contadores de falha e definir o estado para 'aberto' com um TTL (Time To Live), que efetivamente fecha o circuito novamente após o tempo de expiração."
    },
    {
        "id": "aws-de-090",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Crie uma arquitetura para análise de grafos em um grande conjunto de dados de transações financeiras para detectar anéis de fraude. Os dados estão armazenados no S3. O processo deve ser executado em lote.",
        "solution": ["s3", "glue", "neptune"],
        "availableServices": ["s3", "glue", "neptune", "emr", "dynamodb"],
        "explanation": "Primeiro, um job do AWS Glue (ou EMR) pode ser usado para ler os dados de transações do S3 e transformá-los em um formato de grafo (por exemplo, vértices para contas, arestas para transações). Em seguida, o job pode usar o carregador em massa do Neptune para carregar eficientemente os dados no banco de dados de grafos Amazon Neptune. Uma vez no Neptune, você pode executar consultas de grafos complexas (usando Gremlin ou SPARQL) para identificar padrões como anéis, onde o dinheiro circula entre um grupo de contas."
    },
    {
        "id": "aws-de-091",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Seus analistas de BI usam o QuickSight, mas os painéis estão lentos porque consultam diretamente o Athena em grandes conjuntos de dados. Como você pode acelerar o desempenho das consultas do QuickSight?",
        "solution": ["athena", "quicksight"],
        "availableServices": ["athena", "quicksight", "s3", "redshift"],
        "explanation": "O Amazon QuickSight possui um mecanismo de dados em memória super-rápido chamado SPICE (Super-fast, Parallel, In-memory Calculation Engine). Em vez de consultar o Athena diretamente a cada vez (Direct Query), você pode configurar seu conjunto de dados no QuickSight para importar os dados do Athena para o SPICE em um agendamento. As interações no painel serão então atendidas pelo SPICE, resultando em um desempenho muito mais rápido."
    },
    {
        "id": "aws-de-092",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Um aplicativo móvel precisa armazenar dados do usuário (perfil, preferências) em um banco de dados que possa sincronizar os dados automaticamente para uso offline. Qual combinação de serviços da AWS é ideal para isso?",
        "solution": ["cognito", "dynamodb"],
        "availableServices": ["cognito", "dynamodb", "appsync", "lambda"],
        "explanation": "O Amazon Cognito Identity Pools pode se integrar com o Cognito Sync, que permite salvar dados do usuário (pares chave-valor) associados à sua identidade. Esses dados são armazenados em um conjunto de dados no serviço, que por sua vez pode ser sincronizado com o DynamoDB. Isso permite que os dados persistam entre as sessões e dispositivos e estejam disponíveis offline no dispositivo móvel."
    },
    {
        "id": "aws-de-093",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Um job Spark rodando no EMR precisa ler e escrever dados em um bucket S3 criptografado com chaves KMS. Como você concede as permissões necessárias ao cluster EMR?",
        "solution": ["emr", "s3", "kms", "iam"],
        "availableServices": ["emr", "s3", "kms", "iam", "secrets-manager"],
        "explanation": "Você precisa configurar a 'Instance Profile' do IAM para as instâncias EC2 do cluster EMR. Essa role deve ter duas políticas anexadas: uma que concede permissões de acesso ao bucket S3 (s3:GetObject, s3:PutObject, etc.) e outra que concede permissões para usar a chave KMS (kms:Decrypt, kms:Encrypt, kms:GenerateDataKey). Isso permite que o Spark no EMR acesse o S3 e que o S3 use a chave KMS em nome do EMR."
    },
    {
        "id": "aws-de-094",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Projete uma solução de pesquisa semântica. Documentos são armazenados no S3. Um pipeline deve processá-los, gerar embeddings vetoriais usando um modelo de ML e armazená-los em um banco de dados que suporte pesquisa de vizinhos mais próximos (k-NN).",
        "solution": ["s3", "lambda", "sagemaker", "opensearch"],
        "availableServices": ["s3", "lambda", "sagemaker", "opensearch", "comprehend", "neptune"],
        "explanation": "Um evento S3 aciona uma Lambda. A Lambda invoca um endpoint do SageMaker (hospedando um modelo como BERT) para gerar os embeddings vetoriais do texto do documento. Esses vetores são então indexados no Amazon OpenSearch Service, que possui um plugin k-NN integrado. Isso permite que você execute pesquisas de similaridade, encontrando documentos semanticamente semelhantes a uma consulta, em vez de apenas correspondência de palavras-chave."
    },
    {
        "id": "aws-de-095",
        "category": "data-engineering",
        "difficulty": 2,
        "question": "Qual serviço você usaria para hospedar um repositório Git privado para o código-fonte dos seus jobs de ETL e aplicações de dados?",
        "solution": ["codecommit"],
        "availableServices": ["codecommit", "s3", "codepipeline", "github"],
        "explanation": "O AWS CodeCommit é um serviço de controle de origem totalmente gerenciado que hospeda repositórios Git privados e seguros. Ele se integra bem com outros serviços da AWS, como o IAM para controle de acesso e o CodePipeline para CI/CD."
    },
    {
        "id": "aws-de-096",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Você está migrando um aplicativo legado que usa fortemente procedimentos armazenados (stored procedures) para um banco de dados relacional na AWS. Qual serviço de banco de dados da AWS oferece a melhor compatibilidade e desempenho para essa carga de trabalho?",
        "solution": ["aurora"],
        "availableServices": ["aurora", "rds", "redshift", "dynamodb"],
        "explanation": "O Amazon Aurora (edições compatíveis com PostgreSQL ou MySQL) é uma excelente escolha. Ele é um banco de dados relacional de alto desempenho que mantém total compatibilidade com seus respectivos mecanismos de código aberto. Isso significa que os procedimentos armazenados existentes provavelmente funcionarão com pouca ou nenhuma modificação, enquanto você se beneficia do desempenho, escalabilidade e resiliência do Aurora."
    },
    {
        "id": "aws-de-097",
        "category": "cloud-operations",
        "difficulty": 3,
        "question": "Como você pode obter uma visão geral do seu estado de segurança na AWS e verificar se suas configurações atendem às melhores práticas de segurança e padrões de conformidade?",
        "solution": ["macie"],
        "availableServices": ["macie", "iam", "cloudwatch", "inspector"],
        "explanation": "O AWS Security Hub é o serviço projetado para isso (não está na lista). Dentre as opções, Macie é focado em dados no S3. No entanto, o contexto de segurança é mais amplo. Se a pergunta for sobre dados, a resposta é Macie. (Nota: Nenhuma das opções listadas é a melhor ferramenta para uma visão *geral* da postura de segurança, mas Macie é a mais próxima no domínio de segurança de dados)."
    },
    {
        "id": "aws-de-098",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Um stream de dados do Kinesis contém registros em formato Avro. Crie uma arquitetura serverless que decodifique esses registros e os insira em uma tabela DynamoDB.",
        "solution": ["kinesis", "glue", "lambda", "dynamodb"],
        "availableServices": ["kinesis", "glue", "lambda", "dynamodb", "s3"],
        "explanation": "O AWS Glue Schema Registry pode ser usado para armazenar e validar esquemas Avro. Uma função Lambda consumidora do Kinesis pode se integrar com o Glue Schema Registry para buscar o esquema e desserializar os registros Avro. Após a decodificação bem-sucedida, a função Lambda pode gravar os dados convertidos em JSON na tabela DynamoDB."
    },
    {
        "id": "aws-de-099",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Projete uma arquitetura para uma plataforma de análise de logs de segurança (SIEM). Os logs de várias fontes (CloudTrail, VPC Flow Logs, etc.) são centralizados, processados e indexados para pesquisa em tempo real, e os dados de longo prazo são arquivados de forma econômica.",
        "solution": ["kinesis-firehose", [["opensearch"], ["s3", "glacier"]]],
        "availableServices": ["kinesis-firehose", "opensearch", "s3", "glacier", "athena", "lambda"],
        "explanation": "Os logs podem ser enviados para um Kinesis Data Firehose. O Firehose pode ter dois destinos configurados. O primeiro é um cluster do Amazon OpenSearch, que indexa os dados para análise de segurança e correlação de eventos em tempo real. O segundo destino é um bucket S3. Você pode configurar políticas de ciclo de vida no S3 para mover os logs para o S3 Glacier após um período (por exemplo, 90 dias) para arquivamento de longo prazo e de baixo custo, garantindo a conformidade."
    },
    {
        "id": "aws-de-100",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Um pipeline de ETL é orquestrado pelo Step Functions. Como você pode garantir que, se um job do Glue falhar, o pipeline tente executá-lo novamente mais duas vezes com um intervalo de 5 minutos antes de falhar completamente?",
        "solution": [{"orchestrator": "step-functions", "flow": ["glue"]}],
        "availableServices": ["step-functions", "glue", "lambda", "cloudwatch"],
        "explanation": "O AWS Step Functions tem recursos de tratamento de erros e repetição (retry) integrados na definição do estado. No estado da máquina de estados que invoca o job do Glue, você pode adicionar uma cláusula 'Retry'. Nela, você pode especificar os erros a serem capturados, o número máximo de tentativas (MaxAttempts: 2), o intervalo entre as tentativas (IntervalSeconds: 300) e um fator de aumento opcional (BackoffRate)."
    },
    {
        "id": "aws-de-101",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Projete uma solução para ingerir logs de aplicações de um grande número de servidores e disponibilizá-los para consulta via SQL sem provisionar um banco de dados.",
        "solution": ["kinesis-firehose", "s3", "athena"],
        "availableServices": ["kinesis-firehose", "s3", "athena", "glue", "redshift"],
        "explanation": "É possível instalar um agente (como o Kinesis Agent) nos servidores para enviar logs para o Kinesis Data Firehose. O Firehose agrega e entrega os dados ao S3. Opcionalmente, o Firehose pode invocar uma função Lambda para transformar os logs ou o AWS Glue para converter o formato para Parquet. Finalmente, o Athena pode ser usado para consultar diretamente os arquivos de log no S3 usando SQL."
    },
    {
        "id": "aws-de-102",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Orquestre um pipeline que primeiro executa um job do Glue para preparar os dados e, em seguida, inicia um trabalho de treinamento de modelo no SageMaker usando esses dados preparados.",
        "solution": [{"orchestrator": "step-functions", "flow": ["glue", "sagemaker"]}],
        "availableServices": ["step-functions", "glue", "sagemaker", "lambda", "mwaa"],
        "explanation": "O AWS Step Functions é ideal para orquestrar fluxos de trabalho que envolvem múltiplos serviços da AWS. Uma máquina de estados pode ser definida com um primeiro estado que inicia o job do AWS Glue e espera por sua conclusão. O próximo estado, em sequência, inicia o trabalho de treinamento do SageMaker, usando a saída do job do Glue como entrada."
    },
    {
        "id": "aws-de-103",
        "category": "data-engineering",
        "difficulty": 2,
        "question": "Como você pode servir uma aplicação web estática (HTML, CSS, JavaScript) com um domínio personalizado, de forma escalável e com baixa latência global?",
        "solution": ["s3", "cloudfront", "route 53"],
        "availableServices": ["s3", "cloudfront", "route 53", "ec2", "api-gateway"],
        "explanation": "Os arquivos do site estático podem ser hospedados em um bucket S3 configurado para hospedagem de site. O Amazon CloudFront pode ser colocado na frente do bucket S3 para servir o conteúdo globalmente através de sua CDN. Finalmente, o Amazon Route 53 pode ser usado para apontar o domínio personalizado para a distribuição do CloudFront."
    },
    {
        "id": "aws-de-104",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Desenvolva uma arquitetura para processar um feed de notícias em tempo real, extrair entidades (pessoas, organizações) do texto e construir um grafo de conhecimento que relacione essas entidades.",
        "solution": ["kinesis", "lambda", "comprehend", "neptune"],
        "availableServices": ["kinesis", "lambda", "comprehend", "neptune", "s3", "dynamodb"],
        "explanation": "O feed de notícias é ingerido via Kinesis Data Streams. Uma função Lambda consome o stream, pega o texto de cada artigo e o envia para o Amazon Comprehend para o reconhecimento de entidades nomeadas (NER). A Lambda então processa as entidades extraídas e suas relações, e as insere no Amazon Neptune para construir e atualizar o grafo de conhecimento em tempo real."
    },
    {
        "id": "aws-de-105",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Você precisa de um banco de dados NoSQL de chave-valor com um cache em memória integrado para leituras de latência de microssegundos. Qual serviço oferece essa capacidade?",
        "solution": ["dynamodb"],
        "availableServices": ["dynamodb", "elasticache", "rds", "documentdb"],
        "explanation": "O Amazon DynamoDB Accelerator (DAX) é um cache em memória totalmente gerenciado e altamente disponível para o DynamoDB. O DAX melhora o desempenho de leitura de milissegundos para microssegundos, mesmo com milhões de solicitações por segundo, tornando-o ideal para aplicações que exigem a leitura mais rápida possível."
    },
    {
        "id": "aws-de-106",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Um pipeline de dados processa informações de identificação pessoal (PII). Como você pode descobrir e mascarar automaticamente os campos de PII durante um job de ETL do Glue?",
        "solution": ["glue", "macie"],
        "availableServices": ["glue", "macie", "lambda", "kms"],
        "explanation": "O AWS Glue Studio inclui uma transformação visual chamada 'Detect PII', que pode ser adicionada ao seu job de ETL. Essa transformação utiliza o Amazon Macie para identificar 13 tipos diferentes de PII nos seus dados. Você pode então escolher uma ação a ser tomada sobre os dados detectados, como mascarar, substituir ou redigir parcialmente, antes de gravá-los no destino."
    },
    {
        "id": "aws-de-107",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Crie um pipeline serverless que, ao receber um arquivo de áudio no S3, o transcreva para texto e, em seguida, analise o sentimento do texto transcrito.",
        "solution": ["s3", "lambda", "comprehend"],
        "availableServices": ["s3", "lambda", "comprehend", "transcribe", "polly"],
        "explanation": "O upload no S3 aciona uma Lambda. A Lambda inicia um trabalho de transcrição usando o Amazon Transcribe (não listado, mas essencial para a tarefa). Quando a transcrição estiver completa, outro evento (via EventBridge) pode acionar uma segunda Lambda. Esta Lambda pega o texto transcrito e o envia para o Amazon Comprehend para análise de sentimento. O resultado é então armazenado."
    },
    {
        "id": "aws-de-108",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Como você pode executar consultas SQL em seus dados operacionais no DynamoDB para fins analíticos sem impactar o desempenho da sua tabela de produção?",
        "solution": ["dynamodb", "athena"],
        "availableServices": ["dynamodb", "athena", "glue", "redshift", "lambda"],
        "explanation": "Uma opção é exportar os dados do DynamoDB para o S3 usando a funcionalidade de exportação para S3. Uma vez que os dados estão no S3, você pode usar o Amazon Athena para executar consultas analíticas complexas nos dados sem afetar a performance da tabela DynamoDB de produção. Para dados mais recentes, o Athena Federated Query pode consultar o DynamoDB diretamente, mas a exportação é melhor para análises em larga escala."
    },
    {
        "id": "aws-de-109",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Projete uma arquitetura de 'write-through cache'. Uma aplicação escreve dados através de uma API. A escrita deve ocorrer tanto no cache de baixa latência quanto no banco de dados de persistência (RDS). A leitura deve priorizar o cache.",
        "solution": ["api-gateway", "lambda", "elasticache", "rds"],
        "availableServices": ["api-gateway", "lambda", "elasticache", "rds", "dynamodb"],
        "explanation": "A API Gateway aciona uma função Lambda. A Lambda contém a lógica de escrita: ela primeiro escreve os dados no banco de dados RDS (a fonte da verdade) e, em caso de sucesso, escreve os mesmos dados no cache ElastiCache. Para a lógica de leitura, a Lambda primeiro tentaria ler do ElastiCache. Se houver um 'cache miss' (dado não encontrado), ela leria do RDS, popularia o cache com o dado e o retornaria."
    },
    {
        "id": "aws-de-110",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Você precisa de um banco de dados relacional que se escale automaticamente para zero quando não estiver em uso para economizar custos, ideal para ambientes de desenvolvimento ou cargas de trabalho intermitentes.",
        "solution": ["aurora"],
        "availableServices": ["aurora", "rds", "redshift", "ec2"],
        "explanation": "O Amazon Aurora Serverless é uma configuração sob demanda e de dimensionamento automático para o Amazon Aurora. Ele inicia, encerra e dimensiona a capacidade com base na carga de trabalho da sua aplicação. Quando não há conexões por um período configurável, ele pode pausar completamente, resultando em custo zero de computação."
    },
    {
        "id": "aws-de-111",
        "category": "data-engineering",
        "difficulty": 2,
        "question": "Como você pode mover 500 TB de dados de um data center on-premise para o S3 se a sua conexão de rede é lenta e instável?",
        "solution": ["s3"],
        "availableServices": ["s3", "dms", "snowball", "datasync"],
        "explanation": "Para grandes volumes de dados com conectividade de rede limitada, a família AWS Snow (como o AWS Snowball) é a solução ideal. A AWS envia um dispositivo de armazenamento físico para o seu data center. Você carrega os dados no dispositivo e o envia de volta para a AWS, que então transfere os dados para o seu bucket S3, contornando a rede pública."
    },
    {
        "id": "aws-de-112",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Implemente uma arquitetura de 'Strangler Fig Pattern' para migrar um monolito. Crie uma API que roteia o tráfego para a aplicação legada ou para novos microsserviços (Lambdas) com base no caminho da URL.",
        "solution": ["api-gateway", [["lambda"], ["ec2"]]],
        "availableServices": ["api-gateway", "lambda", "ec2", "route 53", "application-load-balancer"],
        "explanation": "O Amazon API Gateway pode atuar como a fachada. Você pode configurar rotas específicas (ex: /api/v2/users) para acionar novas funções Lambda (microsserviços). Para as rotas ainda não migradas (ex: /api/v1/*), você pode configurar uma integração de 'proxy HTTP' ou 'proxy VPC Link' para encaminhar as solicitações para a aplicação monolítica legada rodando em uma EC2 ou atrás de um balanceador de carga."
    },
    {
        "id": "aws-de-113",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Você quer criar um dashboard de BI que combine dados de vendas do Redshift e dados de marketing de uma planilha do Google Sheets. Qual serviço de BI da AWS suporta nativamente a conexão com ambas as fontes?",
        "solution": ["quicksight"],
        "availableServices": ["quicksight", "redshift", "athena", "glue"],
        "explanation": "O Amazon QuickSight suporta uma ampla gama de fontes de dados, incluindo bancos de dados da AWS como o Redshift, e também aplicações de terceiros e fontes de dados SaaS. Ele pode se conectar a ambos, Redshift e Google Sheets, permitindo que você junte os dados de ambas as fontes em um único conjunto de dados para criar dashboards unificados."
    },
    {
        "id": "aws-de-114",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Projete uma solução para ingerir dados de vídeo de câmeras de segurança, analisá-los em tempo real para detectar objetos específicos (ex: uma pessoa em uma área restrita) e enviar um alerta.",
        "solution": ["kinesis", "sagemaker", "lambda", "sns"],
        "availableServices": ["kinesis", "sagemaker", "lambda", "sns", "rekognition"],
        "explanation": "O Kinesis Video Streams é projetado para ingerir e armazenar streams de vídeo. Você pode conectar uma aplicação consumidora (rodando em EC2 ou Fargate, ou usando Lambda) que lê os fragmentos de vídeo do stream. A aplicação pode usar uma biblioteca de ML como OpenCV e um modelo treinado e hospedado no SageMaker para realizar a detecção de objetos em cada quadro. Se um objeto de interesse for detectado, a aplicação invoca uma função Lambda que envia um alerta via SNS."
    },
    {
        "id": "aws-de-115",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Como você pode executar um job de ETL do Glue que precisa acessar recursos dentro de uma VPC, como um cluster ElastiCache ou um banco de dados RDS, de forma segura?",
        "solution": ["glue", "rds"],
        "availableServices": ["glue", "rds", "vpc", "iam"],
        "explanation": "Ao configurar uma conexão no AWS Glue, você pode especificar a VPC, a sub-rede e os grupos de segurança (security groups) a serem usados. Isso anexa uma Interface de Rede Elástica (ENI) da sua VPC à tarefa do Glue. Ao configurar corretamente os security groups para permitir o tráfego entre a ENI do Glue e os recursos da VPC (como RDS), o job pode acessá-los de forma privada e segura."
    },
    {
        "id": "aws-de-116",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Seu Data Lake no S3 está crescendo rapidamente. Como você pode analisar os padrões de acesso aos dados para identificar quais objetos são acessados com frequência e quais podem ser movidos para uma classe de armazenamento mais barata?",
        "solution": ["s3"],
        "availableServices": ["s3", "cloudwatch", "athena", "storage-lens"],
        "explanation": "O Amazon S3 Storage Lens oferece visibilidade em toda a organização sobre o uso e a atividade do armazenamento de objetos, com mais de 29 métricas. Ele fornece dashboards interativos para visualizar tendências e identificar oportunidades de otimização de custos, como identificar dados raramente acessados que são candidatos para transição para S3 Intelligent-Tiering ou S3 Glacier."
    },
    {
        "id": "aws-de-117",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Crie um pipeline de dados que reage a eventos de alteração em uma tabela DynamoDB (inserções, atualizações) e replica esses dados para um cluster OpenSearch para habilitar pesquisas de texto completo.",
        "solution": ["dynamodb", "lambda", "opensearch"],
        "availableServices": ["dynamodb", "lambda", "opensearch", "kinesis", "dms"],
        "explanation": "Você pode habilitar o DynamoDB Streams na sua tabela. O stream captura todas as modificações nos itens da tabela. Uma função Lambda pode ser configurada como um consumidor do stream. A Lambda recebe os registros de alteração, os transforma no formato JSON necessário e os insere no cluster Amazon OpenSearch, mantendo o índice de pesquisa sincronizado com a tabela."
    },
    {
        "id": "aws-de-118",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Um pipeline de processamento de dados em lote precisa ser executado usando um DAG do Airflow. A tarefa principal é um job Spark pesado que deve ser executado em um cluster Kubernetes para isolamento e gerenciamento de dependências. Como você pode montar essa arquitetura?",
        "solution": [{"orchestrator": "mwaa", "flow": ["eks"]}],
        "availableServices": ["mwaa", "eks", "emr", "glue", "fargate"],
        "explanation": "Você pode usar o MWAA (Managed Workflows for Apache Airflow) como orquestrador. Dentro da sua DAG do Airflow, você pode usar o `KubernetesPodOperator`. Este operador inicia um pod no seu cluster Amazon EKS. O pod pode conter uma imagem Docker com o Spark e sua aplicação. O pod executa o job Spark e, após a conclusão, termina. O MWAA monitora o status do pod e continua ou falha a tarefa na DAG com base no resultado."
    },
    {
        "id": "aws-de-119",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Como você pode criar uma tabela no seu Data Lake cujos dados são particionados por ano, mês e dia para otimizar as consultas do Athena que filtram por período?",
        "solution": ["s3", "glue", "athena"],
        "availableServices": ["s3", "glue", "athena", "lambda"],
        "explanation": "Ao organizar seus dados no S3, você deve usar uma estrutura de prefixo que reflita as partições, como `s3://bucket/dados/ano=2025/mes=09/dia=16/`. Quando você executa um AWS Glue Crawler, ele reconhece automaticamente essa estrutura e define 'ano', 'mes' e 'dia' como colunas de partição na tabela do Glue Data Catalog. O Athena então usa essas partições para escanear apenas os dados relevantes quando uma consulta inclui um filtro `WHERE` nessas colunas."
    },
    {
        "id": "aws-de-120",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Um aplicativo de mídia social precisa de um feed de atividades em tempo real. As ações do usuário (curtidas, comentários) devem ser adicionadas a um stream e processadas para atualizar os feeds de outros usuários. Qual serviço é ideal para a ingestão de streams e qual banco de dados é bom para modelar feeds?",
        "solution": ["kinesis", "lambda", "dynamodb"],
        "availableServices": ["kinesis", "lambda", "dynamodb", "rds", "sns"],
        "explanation": "O Kinesis Data Streams é projetado para a ingestão de alto volume de dados em tempo real, como ações do usuário. Uma função Lambda pode processar esses eventos. O DynamoDB é uma excelente escolha para o backend do feed de atividades, pois seu modelo de dados flexível e acesso de baixa latência são ideais para modelar e recuperar listas de atividades para os usuários."
    },
    {
        "id": "aws-de-121",
        "category": "data-engineering",
        "difficulty": 4,
        "question": "Projete uma arquitetura para um sistema de 'feature store' para Machine Learning. As features pré-calculadas devem ser armazenadas para acesso de baixa latência (online) durante a inferência e também para acesso de alto rendimento (offline) durante o treinamento de modelos.",
        "solution": [["dynamodb"], ["s3"]],
        "availableServices": ["dynamodb", "s3", "sagemaker", "redis", "redshift"],
        "explanation": "Uma arquitetura de feature store dual é comum. Para a 'loja online', o DynamoDB ou ElastiCache (Redis) oferecem o acesso de baixa latência necessário para a inferência em tempo real. Para a 'loja offline', o S3 (usando um formato como Parquet) é ideal. Ele fornece o armazenamento de baixo custo e alto rendimento necessário para que os jobs de treinamento do SageMaker ou do Glue leiam grandes volumes de features históricas."
    },
    {
        "id": "aws-de-122",
        "category": "data-engineering",
        "difficulty": 2,
        "question": "Você precisa de um serviço para enviar e-mails transacionais (como confirmação de pedido ou redefinição de senha) de sua aplicação. Qual serviço da AWS é projetado para isso?",
        "solution": ["lambda"],
        "availableServices": ["lambda", "sns", "ses", "sqs"],
        "explanation": "O Amazon SES (Simple Email Service) (não na lista) é a resposta correta. Dentre as opções, a Lambda pode ser usada para *chamar* um serviço de e-mail, mas o SNS é a opção mais próxima para envio de notificações, embora o SES seja o serviço específico para e-mail transacional. A questão está um pouco falha com as opções dadas, mas o fluxo seria `lambda` -> `sns`."
    },
    {
        "id": "aws-de-123",
        "category": "data-engineering",
        "difficulty": 5,
        "question": "Crie um pipeline de processamento de transações com cartão de crédito que seja compatível com o PCI DSS. Os dados sensíveis devem ser criptografados com uma chave que só você controla. O pipeline processa os dados e os armazena em um banco de dados seguro.",
        "solution": ["kinesis", "lambda", "kms", "dynamodb"],
        "availableServices": ["kinesis", "lambda", "kms", "dynamodb", "s3", "rds"],
        "explanation": "Os dados são ingeridos via Kinesis. Uma função Lambda processa os dados. Para a conformidade com o PCI DSS, o AWS KMS com uma Chave Gerenciada pelo Cliente (CMK) é crucial. A Lambda usa o KMS para criptografar os dados sensíveis (como o número do cartão) antes de armazená-los. O DynamoDB, com criptografia em repouso habilitada usando a mesma CMK do KMS, armazena os dados de forma segura. O uso de uma CMK garante que você tenha controle total e auditabilidade sobre a chave de criptografia."
    },
    {
        "id": "aws-de-124",
        "category": "data-engineering",
        "difficulty": 3,
        "question": "Um job do Glue que processa dados de um bucket S3 está falhando intermitentemente com erros de 'throttling' (limitação) do S3. Como você pode mitigar esse problema sem alterar o código do job?",
        "solution": ["s3", "glue"],
        "availableServices": ["s3", "glue", "lambda", "cloudwatch"],
        "explanation": "O S3 pode limitar as solicitações se muitas leituras estiverem sendo feitas no mesmo prefixo. Uma solução é habilitar o 'S3 Bucket Keys' no bucket. Isso reduz o custo e o tráfego de solicitações do seu job do Glue para o KMS. Outra abordagem é otimizar o job para ler os dados de forma mais distribuída, ou se a causa for o número de partições, agrupar arquivos menores em arquivos maiores para reduzir o número de solicitações `List` e `Get`."
    }, 
    {
    "id": "aws-da-001",
    "category": "data-analysis",
    "difficulty": 2,
    "question": "Você precisa armazenar arquivos CSV com terabytes de dados históricos e consultá-los esporadicamente usando SQL padrão, pagando apenas pelas consultas que executa. Qual a combinação de serviços mais econômica?",
    "solution": ["s3", "athena"],
    "availableServices": ["s3", "athena", "rds", "dynamodb", "redshift"],
    "explanation": "O S3 é o serviço ideal para armazenamento de objetos de baixo custo e alta durabilidade. O Athena permite consultar dados diretamente no S3 usando SQL padrão, com um modelo de pagamento por consulta, tornando-o perfeito para análises ad-hoc."
  },
  {
    "id": "aws-da-002",
    "category": "data-analysis",
    "difficulty": 5,
    "question": "Replique continuamente os dados de um banco de dados on-premises (Oracle) para a AWS, com o objetivo de alimentar um Data Warehouse no Redshift. A migração deve ter o mínimo de tempo de inatividade.",
    "solution": ["dms", "redshift"],
    "availableServices": ["dms", "redshift", "glue", "lambda", "s3", "kinesis"],
    "explanation": "O AWS Database Migration Service (DMS) é projetado para migrar bancos de dados para a AWS de forma contínua (usando Change Data Capture - CDC) e com tempo de inatividade mínimo. Ele pode carregar os dados diretamente no Redshift como um destino."
  },
  {
    "id": "aws-da-003",
    "category": "data-analysis",
    "difficulty": 4,
    "question": "Crie um trabalho de ETL serverless que é acionado sempre que um novo arquivo JSON chega em um bucket S3. O trabalho deve converter o JSON para o formato Parquet e salvá-lo em outro bucket.",
    "solution": ["s3", "glue"],
    "availableServices": ["s3", "glue", "lambda", "emr", "redshift"],
    "explanation": "O AWS Glue é um serviço de ETL totalmente gerenciado e serverless. Ele pode ser acionado por eventos do S3, e seus trabalhos (usando Spark) são ideais para transformações de formato de arquivo como JSON para Parquet."
  },
  {
    "id": "aws-da-004",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Construa um painel de BI interativo para analistas de negócios. Os dados estão em um Data Warehouse no Redshift e as consultas precisam ser rápidas. Os usuários devem poder criar seus próprios visuais.",
    "solution": ["redshift", "quicksight"],
    "availableServices": ["redshift", "quicksight", "athena", "s3", "emr"],
    "explanation": "O Amazon Redshift é um serviço de Data Warehouse em escala de petabytes. O Amazon QuickSight é um serviço de BI que se integra nativamente ao Redshift, permitindo a criação de painéis rápidos e interativos."
  },
  {
    "id": "aws-da-005",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Capture um fluxo contínuo de dados de logs de aplicações. Os dados devem ser armazenados de forma durável no S3 e, simultaneamente, processados para detectar anomalias em tempo real.",
    "solution": ["kinesis-firehose", "s3", "kinesis-analytics"],
    "availableServices": ["kinesis-firehose", "s3", "kinesis-analytics", "dms", "glue", "lambda"],
    "explanation": "O Kinesis Data Firehose é a maneira mais fácil de capturar e carregar fluxos de dados em destinos como o S3. Em paralelo, o Kinesis Data Analytics pode consumir esse fluxo e executar consultas SQL ou Flink para análise em tempo real, como detecção de anomalias."
  },
  {
    "id": "aws-da-006",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Orquestre um pipeline de dados complexo: um trabalho do Glue deve ser executado. Se for bem-sucedido, um procedimento no Redshift deve ser chamado. Se falhar, uma notificação deve ser enviada para um tópico SNS. O fluxo inteiro precisa de retentativas automáticas.",
    "solution": ["glue", "redshift", "sns", "step-functions"],
    "availableServices": ["glue", "redshift", "sns", "step-functions", "lambda", "cloudwatch", "mwaa"],
    "explanation": "O AWS Step Functions é um orquestrador visual serverless que permite construir fluxos de trabalho resilientes. Ele se integra nativamente com serviços como Glue, Redshift (via Data API) e SNS, e gerencia estados, erros e retentativas."
  },
  {
    "id": "aws-da-007",
    "category": "data-analysis",
    "difficulty": 5,
    "question": "Implemente um catálogo de dados centralizado para um Data Lake no S3. O catálogo deve descobrir automaticamente os esquemas dos dados e versioná-los, permitindo que o Athena e o Redshift Spectrum consultem os dados.",
    "solution": ["s3", "glue"],
    "availableServices": ["s3", "glue", "athena", "lake-formation", "dynamodb"],
    "explanation": "O AWS Glue Data Catalog atua como um metastore central para o Data Lake. Seus crawlers podem escanear dados no S3, inferir esquemas e popular o catálogo, que é então usado por serviços de consulta como Athena e Redshift Spectrum."
  },
  {
    "id": "aws-da-008",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Treine um modelo de machine learning para previsão de churn de clientes. Os dados estão no S3. Orquestre o pipeline de preparação de dados, treinamento do modelo e implantação do endpoint para inferência em tempo real.",
    "solution": ["s3", "sagemaker"],
    "availableServices": ["s3", "sagemaker", "glue", "lambda", "comprehend", "personalize"],
    "explanation": "O Amazon SageMaker é uma plataforma completa de ML. Ele pode usar dados do S3, possui notebooks e SDKs para preparação e treinamento de modelos, e facilita a implantação de endpoints de inferência com escalabilidade automática."
  },
  {
    "id": "aws-da-009",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Crie uma API REST que recebe dados JSON, os enriquece com uma pequena lógica de negócios e os insere em um banco de dados NoSQL de baixa latência. A solução deve ser totalmente serverless.",
    "solution": ["api-gateway", "lambda", "dynamodb"],
    "availableServices": ["api-gateway", "lambda", "dynamodb", "ec2", "rds", "sqs"],
    "explanation": "O API Gateway expõe o endpoint HTTP. A Lambda contém a lógica de negócios e é acionada pelas requisições. O DynamoDB é um banco de dados NoSQL gerenciado que oferece baixa latência para leituras e escritas, completando a arquitetura serverless."
  },
  {
    "id": "aws-da-010",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Centralize o gerenciamento de permissões de um Data Lake no S3. Você precisa conceder acesso a tabelas e colunas específicas para diferentes grupos de usuários que usam Athena para suas análises.",
    "solution": ["s3", "glue", "lake-formation"],
    "availableServices": ["s3", "glue", "lake-formation", "iam", "macie", "kms"],
    "explanation": "O AWS Lake Formation simplifica a segurança de Data Lakes. Ele permite gerenciar permissões de forma centralizada (em nível de tabela e coluna) para os dados no S3, integrando-se com o Glue Data Catalog e aplicando essas permissões em serviços como o Athena."
  },
  {
    "id": "aws-da-011",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Processe petabytes de dados não estruturados usando um framework customizado de Spark com bibliotecas específicas. A carga de trabalho é esporádica e o custo é uma grande preocupação. O cluster deve ser encerrado automaticamente após a conclusão.",
    "solution": ["s3", "emr"],
    "availableServices": ["s3", "emr", "glue", "redshift", "lambda"],
    "explanation": "O Amazon EMR (Elastic MapReduce) é ideal para processamento de big data com frameworks como Spark e Hadoop. Ele oferece total controle sobre o ambiente (permitindo bibliotecas customizadas) e suporta clusters transitórios (que se encerram automaticamente), otimizando custos."
  },
  {
    "id": "aws-da-012",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Ingira um grande volume de eventos de um sistema de mensagens Kafka on-premises para a AWS, de forma gerenciada e escalável, para posterior análise em tempo real.",
    "solution": ["msk"],
    "availableServices": ["msk", "kinesis", "sqs", "sns", "lambda"],
    "explanation": "O Amazon MSK (Managed Streaming for Kafka) é um serviço totalmente gerenciado para Apache Kafka. Ele é a escolha natural para migrar ou estender clusters Kafka existentes para a AWS, mantendo a compatibilidade com as APIs do Kafka."
  },
  {
    "id": "aws-da-013",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Indexe logs de aplicação que estão sendo enviados para o S3 para permitir pesquisa de texto completo e análise interativa de logs, como encontrar erros específicos ou visualizar a frequência de eventos.",
    "solution": ["s3", "opensearch"],
    "availableServices": ["s3", "opensearch", "athena", "redshift", "dynamodb", "cloudwatch"],
    "explanation": "O Amazon OpenSearch Service (sucessor do Elasticsearch Service) é projetado para casos de uso de pesquisa de texto completo e análise de logs. Ele pode ingerir dados do S3 e oferece painéis (via OpenSearch Dashboards) para visualização e exploração interativa."
  },
  {
    "id": "aws-da-014",
    "category": "data-analysis",
    "difficulty": 9,
    "question": "Gerencie e orquestre pipelines de dados complexos escritos em Python e SQL, usando um framework de código aberto popular. Os DAGs (Directed Acyclic Graphs) precisam ser executados em uma agenda e as dependências entre tarefas devem ser gerenciadas.",
    "solution": ["mwaa"],
    "availableServices": ["mwaa", "step-functions", "glue", "lambda", "eventbridge"],
    "explanation": "O Amazon MWAA (Managed Workflows for Apache Airflow) é um serviço gerenciado para o Apache Airflow. Ele é a escolha ideal para equipes que já usam ou querem usar Airflow para orquestração de pipelines complexos definidos como código (DAGs)."
  },
  {
    "id": "aws-da-015",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Colete dados de telemetria de milhões de dispositivos IoT. Os dados são séries temporais e precisam ser armazenados em um banco de dados otimizado para esse tipo de dado, para consultas de alta performance sobre janelas de tempo.",
    "solution": ["iot-core", "timestream"],
    "availableServices": ["iot-core", "timestream", "kinesis", "rds", "dynamodb", "s3"],
    "explanation": "O AWS IoT Core conecta os dispositivos com segurança. Para os dados, o Amazon Timestream é um banco de dados de séries temporais rápido, escalável e serverless, projetado especificamente para dados de IoT e operacionais, tornando as consultas por tempo muito eficientes."
  },
  {
    "id": "aws-da-016",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Analise uma grande quantidade de avaliações de clientes em texto para extrair entidades (como nomes de produtos), análise de sentimento (positivo/negativo) e tópicos principais, sem a necessidade de treinar um modelo de ML.",
    "solution": ["comprehend"],
    "availableServices": ["comprehend", "sagemaker", "lambda", "textract", "glue"],
    "explanation": "O Amazon Comprehend é um serviço de processamento de linguagem natural (NLP) que usa machine learning para encontrar insights em texto. Ele oferece APIs prontas para extração de entidades, sentimento e tópicos, sem exigir conhecimento em ML."
  },
  {
    "id": "aws-da-017",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Extraia texto e dados estruturados (tabelas, formulários) de milhões de documentos PDF e imagens armazenados no S3. A solução deve ser automatizada e escalável.",
    "solution": ["s3", "textract"],
    "availableServices": ["s3", "textract", "comprehend", "lambda", "sagemaker", "glue"],
    "explanation": "O Amazon Textract é um serviço de IA que extrai automaticamente texto e dados de documentos digitalizados, indo além do OCR simples para identificar conteúdo em tabelas e formulários. Ele se integra diretamente com o S3."
  },
  {
    "id": "aws-da-018",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Crie um sistema de recomendação de produtos para um site de e-commerce, sem precisar construir, treinar e implantar modelos de ML manualmente. O serviço deve usar os dados de interação do usuário.",
    "solution": ["personalize"],
    "availableServices": ["personalize", "sagemaker", "comprehend", "lambda", "redshift"],
    "explanation": "O Amazon Personalize é um serviço de IA totalmente gerenciado que simplifica a criação de sistemas de recomendação. Você fornece dados de interação do usuário e ele lida com todo o pipeline de ML para fornecer recomendações personalizadas."
  },
  {
    "id": "aws-da-019",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Uma aplicação web gera picos de eventos. Para evitar sobrecarregar o banco de dados, você precisa de um buffer para processar esses eventos de forma assíncrona com uma função. A ordem não é crítica, mas cada evento deve ser processado.",
    "solution": ["sqs", "lambda", "rds"],
    "availableServices": ["sqs", "lambda", "rds", "kinesis", "sns", "api-gateway"],
    "explanation": "O Amazon SQS (Simple Queue Service) é uma fila de mensagens perfeita para desacoplar componentes. Ele atua como um buffer, armazenando eventos de forma confiável. Uma função Lambda pode então processar as mensagens da fila a uma taxa controlada e gravar no banco de dados RDS."
  },
  {
    "id": "aws-da-020",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Quando um novo cliente é cadastrado em um banco de dados Aurora, um evento deve ser disparado para iniciar múltiplos fluxos de trabalho paralelos: um para enviar um e-mail de boas-vindas e outro para iniciar um pipeline de dados no Step Functions.",
    "solution": ["aurora", "eventbridge", ["lambda", "step-functions"]],
    "availableServices": ["aurora", "eventbridge", "lambda", "step-functions", "sns", "sqs"],
    "explanation": "O Amazon EventBridge é um barramento de eventos serverless que pode reagir a eventos de várias fontes. Ele pode rotear um único evento (novo cliente) para múltiplos destinos (Lambda para e-mail, Step Functions para fluxo de trabalho) para orquestrar arquiteturas desacopladas."
  },
  {
    "id": "aws-da-021",
    "category": "data-analysis",
    "difficulty": 9,
    "question": "Projete uma arquitetura de dados completa para uma nova aplicação. Os dados de um banco de dados Aurora devem ser replicados para um Data Lake (S3) e um Data Warehouse (Redshift). Um ETL com Spark deve processar os dados brutos no S3 e criar tabelas limpas. O acesso ao Data Lake deve ser governado centralmente. Analistas usarão SQL e uma ferramenta de BI.",
    "solution": ["aurora", "dms", [["s3", "glue", "athena", "lake-formation"], ["redshift", "quicksight"]]],
    "availableServices": ["aurora", "dms", "s3", "glue", "athena", "redshift", "quicksight", "lake-formation", "iam"],
    "explanation": "Esta é uma arquitetura de análise moderna completa. O DMS lida com a replicação. O caminho do Data Lake usa S3 para armazenamento, Glue para ETL e catálogo, Athena para consultas ad-hoc e Lake Formation para governança. O caminho do Data Warehouse usa Redshift para análise de performance e QuickSight para BI."
  },
  {
    "id": "aws-da-022",
    "category": "data-analysis",
    "difficulty": 4,
    "question": "Você precisa de um banco de dados relacional totalmente gerenciado para uma aplicação web. O serviço deve cuidar de backups, patching e failover automaticamente. Qual serviço é a base para essa necessidade?",
    "solution": ["rds"],
    "availableServices": ["rds", "aurora", "dynamodb", "ec2", "redshift"],
    "explanation": "O Amazon RDS (Relational Database Service) é o serviço fundamental para bancos de dados relacionais gerenciados na AWS. Ele automatiza tarefas de administração, permitindo que você se concentre na aplicação."
  },
  {
    "id": "aws-da-023",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Analise dados de redes sociais para entender relacionamentos, como 'usuário A é amigo do usuário B' e 'usuário B curtiu a postagem C'. Você precisa executar consultas para encontrar amigos em comum ou recomendações de conexão de forma eficiente.",
    "solution": ["neptune"],
    "availableServices": ["neptune", "rds", "dynamodb", "redshift", "opensearch"],
    "explanation": "O Amazon Neptune é um serviço de banco de dados de grafos gerenciado, otimizado para armazenar e consultar bilhões de relacionamentos. É ideal para casos de uso como redes sociais, detecção de fraudes e grafos de conhecimento."
  },
  {
    "id": "aws-da-024",
    "category": "data-analysis",
    "difficulty": 5,
    "question": "Armazene e gerencie com segurança as credenciais do banco de dados usadas por um trabalho do AWS Glue, evitando que elas sejam codificadas diretamente no script.",
    "solution": ["secrets-manager"],
    "availableServices": ["secrets-manager", "iam", "kms", "lambda", "glue"],
    "explanation": "O AWS Secrets Manager é o serviço ideal para armazenar, gerenciar e rotacionar segredos como senhas de banco de dados. O Glue pode se integrar nativamente ao Secrets Manager para recuperar credenciais de forma segura em tempo de execução."
  },
  {
    "id": "aws-da-025",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Crie um pipeline de CI/CD para um trabalho de ETL do AWS Glue. Quando o código for enviado para um repositório, o pipeline deve ser acionado para testar e implantar automaticamente o trabalho no ambiente de produção.",
    "solution": ["codecommit", "codepipeline", "glue"],
    "availableServices": ["codecommit", "codepipeline", "glue", "s3", "lambda", "cloudformation"],
    "explanation": "O AWS CodePipeline automatiza o processo de build, teste e deploy. Usado em conjunto com o CodeCommit (um repositório Git gerenciado), ele pode orquestrar a implantação de recursos da AWS, incluindo trabalhos do Glue, garantindo um ciclo de vida de desenvolvimento de software (SDLC) robusto."
  },
  {
    "id": "aws-da-026",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Uma aplicação precisa de um cache em memória para reduzir a latência de leitura em um banco de dados RDS, armazenando em cache os resultados de consultas frequentes.",
    "solution": ["rds", "elasticache"],
    "availableServices": ["rds", "elasticache", "dynamodb", "s3", "lambda"],
    "explanation": "O Amazon ElastiCache oferece caches em memória gerenciados (Redis ou Memcached). Ele é comumente usado na frente de bancos de dados como o RDS para armazenar dados acessados com frequência, melhorando drasticamente a performance e reduzindo a carga no banco de dados."
  },
  {
    "id": "aws-da-027",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Provisione uma arquitetura de análise completa (S3, Glue, Athena, Redshift) de forma repetível e automatizada, usando infraestrutura como código (IaC).",
    "solution": ["cloudformation"],
    "availableServices": ["cloudformation", "lambda", "ec2", "ecs", "codepipeline"],
    "explanation": "O AWS CloudFormation permite que você modele e provisione recursos da AWS usando templates (YAML ou JSON). É a principal ferramenta de IaC da AWS para criar, atualizar e gerenciar pilhas de recursos de forma consistente e previsível."
  },
  {
    "id": "aws-da-028",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Descubra e classifique automaticamente dados sensíveis (PII) armazenados em buckets do S3 no seu Data Lake para atender a requisitos de conformidade como GDPR ou LGPD.",
    "solution": ["s3", "macie"],
    "availableServices": ["s3", "macie", "glue", "kms", "lake-formation", "iam"],
    "explanation": "O Amazon Macie é um serviço de segurança de dados que usa machine learning para descobrir, classificar e proteger dados sensíveis na AWS. Ele monitora continuamente os buckets do S3 em busca de PII e outros dados confidenciais."
  },
  {
    "id": "aws-da-029",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Uma aplicação precisa garantir que os eventos em um fluxo sejam processados em ordem estrita (FIFO - First-In, First-Out) para cada cliente. Os eventos de clientes diferentes podem ser processados em paralelo.",
    "solution": ["kinesis"],
    "availableServices": ["kinesis", "sqs", "sns", "lambda", "eventbridge"],
    "explanation": "O Amazon Kinesis Data Streams garante a ordenação de registros dentro de um shard usando chaves de partição. Ao usar o ID do cliente como chave de partição, todos os eventos desse cliente irão para o mesmo shard e serão processados em ordem, atendendo ao requisito FIFO."
  },
  {
    "id": "aws-da-030",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Arquive terabytes de logs brutos do S3 que raramente são acessados, mas precisam ser mantidos por 7 anos por motivos de conformidade. A solução deve ter o menor custo de armazenamento possível.",
    "solution": ["s3", "glacier"],
    "availableServices": ["s3", "glacier", "rds", "redshift", "ebs"],
    "explanation": "As políticas de ciclo de vida do S3 podem transicionar objetos automaticamente para classes de armazenamento de menor custo. O S3 Glacier Deep Archive oferece o menor custo de armazenamento na nuvem e é projetado para retenção de dados a longo prazo, sendo ideal para conformidade."
  },
  {
    "id": "aws-da-031",
    "category": "data-analysis",
    "difficulty": 5,
    "question": "Um painel do QuickSight que consulta o Athena está lento. A maioria das consultas filtra por 'ano' e 'mês'. Como você pode otimizar a estrutura dos dados no S3 para acelerar as consultas e reduzir os custos?",
    "solution": ["s3", "glue", "athena"],
    "availableServices": ["s3", "glue", "athena", "redshift", "emr"],
    "explanation": "Particionar os dados no S3 em uma estrutura de pastas como 's3://bucket/ano=2025/mes=09/' e usar o Glue para catalogar essas partições permite que o Athena escaneie apenas os dados relevantes (poda de partição), melhorando drasticamente a performance e reduzindo os custos."
  },
  {
    "id": "aws-da-032",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Crie um banco de dados relacional de alta performance e disponibilidade, compatível com MySQL, que ofereça replicação automática em 3 zonas de disponibilidade (AZs).",
    "solution": ["aurora"],
    "availableServices": ["aurora", "rds", "redshift", "ec2"],
    "explanation": "O Amazon Aurora é um banco de dados relacional compatível com MySQL e PostgreSQL, construído para a nuvem. Ele oferece performance e disponibilidade superiores ao RDS padrão, com replicação de dados em 3 AZs por padrão."
  },
  {
    "id": "aws-da-033",
    "category": "data-analysis",
    "difficulty": 9,
    "question": "Você precisa processar um fluxo de dados em tempo real. Os dados brutos devem ser armazenados no S3. Uma versão dos dados deve ser enriquecida por uma função Lambda e enviada para o OpenSearch para análise de logs. Outra versão deve ser enviada para o Redshift para BI. A solução deve ser resiliente e gerenciada.",
    "solution": ["kinesis", "kinesis-firehose", [["s3"], ["lambda", "opensearch"], ["redshift"]]],
    "availableServices": ["kinesis", "kinesis-firehose", "s3", "lambda", "opensearch", "redshift", "glue"],
    "explanation": "O Kinesis Data Streams atua como o ponto de entrada. O Kinesis Data Firehose pode consumir esse fluxo e ter múltiplos destinos. Ele pode entregar os dados brutos diretamente para o S3, invocar uma função Lambda para transformação antes de entregar ao OpenSearch e carregar os dados diretamente no Redshift."
  },
  {
    "id": "aws-da-034",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Um sistema gera milhares de mensagens que precisam ser entregues a múltiplos sistemas de processamento independentes (fan-out). Por exemplo, um evento de 'novo pedido' deve ser enviado para os sistemas de faturamento, estoque e notificação simultaneamente.",
    "solution": ["sns", "sqs"],
    "availableServices": ["sns", "sqs", "kinesis", "eventbridge", "lambda"],
    "explanation": "O padrão 'fan-out' é um caso de uso clássico para o Amazon SNS (Simple Notification Service). Você publica uma mensagem em um tópico SNS, e o SNS a entrega para todos os assinantes. Usar filas SQS como assinantes torna a arquitetura resiliente, pois cada sistema pode processar a mensagem no seu próprio ritmo."
  },
  {
    "id": "aws-da-035",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Execute um contêiner Docker que contém um script de processamento de dados Python como uma tarefa serverless, sem precisar gerenciar servidores ou clusters.",
    "solution": ["ecs", "fargate"],
    "availableServices": ["ecs", "fargate", "ec2", "eks", "lambda"],
    "explanation": "O Amazon ECS (Elastic Container Service) é um orquestrador de contêineres. Usado com o AWS Fargate como tipo de lançamento, ele permite executar contêineres sem gerenciar a infraestrutura subjacente (servidores EC2), tornando-o uma solução serverless para cargas de trabalho em contêineres."
  },
  {
    "id": "aws-da-036",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Migre um banco de dados Cassandra on-premises para um serviço compatível com a API do Cassandra na AWS que seja serverless e totalmente gerenciado.",
    "solution": ["keyspaces"],
    "availableServices": ["keyspaces", "dynamodb", "rds", "neptune", "aurora"],
    "explanation": "O Amazon Keyspaces (for Apache Cassandra) é um serviço de banco de dados serverless, escalável e gerenciado, compatível com a API do Apache Cassandra. Ele permite migrar cargas de trabalho do Cassandra para a AWS sem gerenciar a infraestrutura."
  },
  {
    "id": "aws-da-037",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Monitore a execução de um trabalho do AWS Glue e crie um alarme que notifique uma equipe via e-mail se o trabalho falhar ou exceder um tempo de execução de 2 horas.",
    "solution": ["glue", "cloudwatch", "sns"],
    "availableServices": ["glue", "cloudwatch", "sns", "lambda", "eventbridge", "step-functions"],
    "explanation": "O AWS Glue emite métricas para o Amazon CloudWatch, como status do trabalho e duração. No CloudWatch, você pode criar alarmes com base nessas métricas. A ação do alarme pode ser a publicação em um tópico SNS, que por sua vez envia uma notificação por e-mail aos assinantes."
  },
  {
    "id": "aws-da-038",
    "category": "data-analysis",
    "difficulty": 4,
    "question": "Crie uma política de segurança para um novo analista de dados que conceda acesso de leitura (somente SELECT) a tabelas específicas em um banco de dados Redshift.",
    "solution": ["iam"],
    "availableServices": ["iam", "lake-formation", "kms", "secrets-manager"],
    "explanation": "O AWS IAM (Identity and Access Management) é o serviço central para gerenciar o acesso aos serviços e recursos da AWS. Você pode criar políticas do IAM que definem permissões granulares, como permitir ou negar ações específicas em recursos como clusters do Redshift."
  },
  {
    "id": "aws-da-039",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Um Data Lake no S3 contém dados com diferentes níveis de qualidade (bronze, silver, gold). Orquestre o pipeline que move os dados brutos (bronze) para dados limpos e particionados (silver) e, em seguida, para dados agregados para negócios (gold).",
    "solution": ["s3", "glue", "step-functions"],
    "availableServices": ["s3", "glue", "step-functions", "lambda", "mwaa", "athena"],
    "explanation": "Esta é a arquitetura 'Medallion'. O S3 armazena os dados em cada camada. O Glue executa os trabalhos de ETL de Spark para limpar e agregar os dados. O Step Functions é ideal para orquestrar essa sequência de trabalhos do Glue, garantindo que a camada 'silver' seja concluída antes que a 'gold' comece."
  },
  {
    "id": "aws-da-040",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Criptografe os dados em repouso em um bucket S3 usando uma chave de criptografia gerenciada pela sua empresa, com controle total sobre a política da chave e sua rotação.",
    "solution": ["s3", "kms"],
    "availableServices": ["s3", "kms", "iam", "macie", "secrets-manager"],
    "explanation": "O AWS KMS (Key Management Service) permite criar e gerenciar chaves de criptografia. Ao configurar a criptografia do lado do servidor (SSE) em um bucket S3, você pode especificar uma chave gerenciada pelo cliente (CMK) do KMS, dando a você controle total sobre o acesso e o uso da chave de criptografia."
  },
  {
    "id": "aws-da-041",
    "category": "data-analysis",
    "difficulty": 3,
    "question": "Qual serviço você usaria para hospedar uma instância virtual na nuvem para executar um script de análise de dados em Python que requer um ambiente operacional específico?",
    "solution": ["ec2"],
    "availableServices": ["ec2", "lambda", "ecs", "s3"],
    "explanation": "O Amazon EC2 (Elastic Compute Cloud) fornece capacidade computacional segura e redimensionável na nuvem. É o serviço fundamental para criar servidores virtuais (instâncias) onde você tem controle total sobre o sistema operacional e o software instalado."
  },
  {
    "id": "aws-da-042",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Você precisa de um banco de dados NoSQL chave-valor com latência de milissegundos de um dígito para uma aplicação de e-commerce que gerencia sessões de usuário e carrinhos de compras.",
    "solution": ["dynamodb"],
    "availableServices": ["dynamodb", "rds", "aurora", "elasticache", "s3"],
    "explanation": "O Amazon DynamoDB é um banco de dados NoSQL chave-valor totalmente gerenciado que oferece performance de baixa latência em qualquer escala. É ideal para casos de uso que exigem acesso rápido a dados, como perfis de usuário, carrinhos de compras e tabelas de classificação de jogos."
  },
  {
    "id": "aws-da-043",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Um trabalho de ETL no Glue precisa ler dados de uma fonte e aplicar uma transformação complexa que uma função Lambda não suportaria devido a limites de tempo de execução e memória. Qual é o serviço serverless mais apropriado para essa tarefa?",
    "solution": ["glue"],
    "availableServices": ["glue", "lambda", "emr", "fargate"],
    "explanation": "Enquanto a Lambda é ótima para transformações rápidas e leves, o AWS Glue é projetado para cargas de trabalho de ETL mais pesadas. Ele executa em um ambiente Apache Spark gerenciado, superando facilmente os limites de tempo e memória da Lambda para processamento de dados em larga escala."
  },
  {
    "id": "aws-da-044",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Execute um cluster Kubernetes gerenciado para implantar e escalar aplicações de análise de dados em contêineres, sem a necessidade de gerenciar o painel de controle do Kubernetes.",
    "solution": ["eks"],
    "availableServices": ["eks", "ecs", "fargate", "ec2"],
    "explanation": "O Amazon EKS (Elastic Kubernetes Service) é o serviço gerenciado da AWS para executar Kubernetes. Ele simplifica a implantação, o gerenciamento e a escalabilidade de aplicações em contêineres usando Kubernetes na AWS."
  },
  {
    "id": "aws-da-045",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Disponibilize um conjunto de dados do seu Data Lake no S3 para consumo por terceiros de forma segura, sem expor o bucket diretamente. A solução deve permitir a autenticação e autorização dos usuários.",
    "solution": ["s3", "api-gateway", "lambda", "cognito"],
    "availableServices": ["s3", "api-gateway", "lambda", "cognito", "cloudfront", "iam"],
    "explanation": "O Amazon Cognito gerencia a autenticação dos usuários. O API Gateway expõe um endpoint seguro que requer autenticação do Cognito. A Lambda, acionada pelo API Gateway, contém a lógica para buscar os dados solicitados do S3 e retorná-los, atuando como uma camada de segurança e controle."
  },
  {
    "id": "aws-da-046",
    "category": "data-analysis",
    "difficulty": 5,
    "question": "Você precisa de uma solução de armazenamento de objetos para hospedar um site estático (HTML, CSS, JS) e entregar seu conteúdo globalmente com baixa latência.",
    "solution": ["s3", "cloudfront"],
    "availableServices": ["s3", "cloudfront", "ec2", "elasticache"],
    "explanation": "O S3 pode ser configurado para hospedar um site estático. O Amazon CloudFront é uma rede de entrega de conteúdo (CDN) que armazena em cache o conteúdo do S3 em locais de borda ao redor do mundo, entregando-o aos usuários com a menor latência possível."
  },
  {
    "id": "aws-da-047",
    "category": "data-analysis",
    "difficulty": 9,
    "question": "Projete uma arquitetura para análise de clickstream em tempo real. Os cliques são enviados para um endpoint de API. Eles devem ser ingeridos, processados para calcular métricas de sessão em uma janela de 5 minutos, e os resultados devem ser armazenados em um banco de dados de baixa latência para alimentar um painel ao vivo.",
    "solution": ["api-gateway", "kinesis", "kinesis-analytics", "lambda", "dynamodb"],
    "availableServices": ["api-gateway", "kinesis", "kinesis-analytics", "lambda", "dynamodb", "s3", "athena"],
    "explanation": "O API Gateway recebe os cliques e os envia para o Kinesis Data Streams. O Kinesis Data Analytics executa uma consulta de janela de tempo contínua no fluxo para calcular as métricas. Uma função Lambda é usada como destino para os resultados da análise, que por sua vez os grava no DynamoDB. O painel ao vivo consulta o DynamoDB."
  },
  {
    "id": "aws-da-048",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Você tem um cluster Redshift com vários terabytes e precisa descarregar dados históricos para o S3 para reduzir custos, mas ainda quer poder consultá-los junto com os dados 'quentes' do cluster. Qual recurso do Redshift permite isso?",
    "solution": ["redshift", "s3"],
    "availableServices": ["redshift", "s3", "athena", "glue", "dms"],
    "explanation": "O Amazon Redshift Spectrum é um recurso do Redshift que permite executar consultas SQL em dados armazenados diretamente no seu Data Lake no S3. Isso permite estender suas análises do Redshift para exabytes de dados no S3 sem precisar carregá-los no cluster."
  },
  {
    "id": "aws-da-049",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Uma função Lambda precisa de mais de 15 minutos para processar um lote de arquivos. Qual serviço de orquestração é ideal para dividir o trabalho em etapas menores e gerenciar o fluxo de longa duração?",
    "solution": ["lambda", "step-functions"],
    "availableServices": ["lambda", "step-functions", "sqs", "eventbridge"],
    "explanation": "O AWS Step Functions é projetado para orquestrar fluxos de trabalho de longa duração. Você pode modelar seu processo como uma máquina de estados, onde cada estado pode invocar uma função Lambda para processar uma parte do trabalho, superando o limite de tempo de execução de uma única Lambda."
  },
  {
    "id": "aws-da-050",
    "category": "data-analysis",
    "difficulty": 4,
    "question": "Qual serviço você usaria para registrar um nome de domínio e configurar o roteamento de tráfego DNS para sua aplicação web de análise?",
    "solution": ["route 53"],
    "availableServices": ["route 53", "cloudfront", "ec2", "api-gateway"],
    "explanation": "O Amazon Route 53 é um serviço de sistema de nomes de domínio (DNS) web altamente disponível e escalável. Ele é usado para registrar domínios e rotear o tráfego da internet para os recursos da sua aplicação, como instâncias EC2 ou balanceadores de carga."
  },
  {
    "id": "aws-da-051",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Um pipeline de ETL noturno falhou. Você precisa analisar os logs de execução do Glue, os logs de acesso ao S3 e as métricas do CloudWatch para depurar e identificar a causa raiz do problema.",
    "solution": ["glue", "s3", "cloudwatch"],
    "availableServices": ["glue", "s3", "cloudwatch", "athena", "opensearch", "x-ray"],
    "explanation": "A depuração de pipelines envolve vários serviços. Os logs do trabalho do AWS Glue estão no CloudWatch Logs. Os logs de acesso ao S3 (se habilitados) mostram as solicitações feitas ao bucket. As métricas do CloudWatch para Glue e S3 podem revelar anomalias de performance ou erros."
  },
  {
    "id": "aws-da-052",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Você está construindo um Data Lake e precisa garantir que os dados no S3 sejam imutáveis, ou seja, uma vez escritos, não podem ser alterados ou excluídos por um período de tempo definido, para fins de auditoria.",
    "solution": ["s3"],
    "availableServices": ["s3", "iam", "glacier", "macie"],
    "explanation": "O S3 Object Lock é um recurso que permite implementar políticas de retenção de dados Write-Once-Read-Many (WORM). Isso impede que objetos sejam excluídos ou sobrescritos por um período fixo ou indefinidamente, garantindo a imutabilidade dos dados."
  },
  {
    "id": "aws-da-053",
    "category": "data-analysis",
    "difficulty": 9,
    "question": "Orquestre um pipeline de ML. Um arquivo de dados no S3 deve acionar um trabalho do Glue para pré-processamento. Em seguida, um trabalho de treinamento do SageMaker deve ser iniciado. Se o treinamento for bem-sucedido, o modelo deve ser implantado, caso contrário, uma notificação de falha deve ser enviada.",
    "solution": ["s3", "glue", "sagemaker", "sns", "step-functions"],
    "availableServices": ["s3", "glue", "sagemaker", "sns", "step-functions", "lambda", "mwaa"],
    "explanation": "O Step Functions se integra nativamente com serviços de ML e dados. Ele pode acionar trabalhos do Glue, iniciar e monitorar trabalhos de treinamento do SageMaker e tomar decisões com base no resultado (sucesso ou falha) para orquestrar o pipeline de ponta a ponta (MLOps)."
  },
  {
    "id": "aws-da-054",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Você precisa de uma forma de executar consultas SQL em um banco de dados DynamoDB para análises exploratórias, mesmo que o DynamoDB seja NoSQL.",
    "solution": ["dynamodb", "athena"],
    "availableServices": ["dynamodb", "athena", "glue", "dms", "redshift"],
    "explanation": "O Amazon Athena possui conectores de federação de dados que permitem executar consultas SQL em fontes de dados além do S3. Usando o conector do DynamoDB, o Athena pode consultar tabelas do DynamoDB diretamente, facilitando a análise de dados NoSQL com SQL padrão."
  },
  {
    "id": "aws-da-055",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Um pipeline de dados processa informações de clientes. Os dados precisam ser anonimizados antes de serem armazenados na camada 'gold' do Data Lake, removendo ou mascarando PII.",
    "solution": ["s3", "glue"],
    "availableServices": ["s3", "glue", "macie", "lambda", "comprehend"],
    "explanation": "O AWS Glue é uma ferramenta de ETL poderosa. Você pode usar suas transformações integradas ou escrever scripts Spark customizados para identificar e anonimizar (mascarar, remover, tokenizar) colunas contendo PII durante o processo de ETL entre as camadas do Data Lake."
  },
  {
    "id": "aws-da-056",
    "category": "data-analysis",
    "difficulty": 5,
    "question": "Como você pode acelerar o desempenho de um grande número de pequenas leituras de arquivos no Amazon EMR? Os arquivos estão armazenados no S3.",
    "solution": ["emr", "s3"],
    "availableServices": ["emr", "s3", "elasticache", "glue"],
    "explanation": "O EMRFS (EMR File System) oferece uma visualização consistente e otimizações de performance para o S3. Para cenários com muitos arquivos pequenos, recursos como o EMRFS S3-optimized committer e o uso de formatos de arquivo como Parquet (que é colunar) podem melhorar significativamente o desempenho."
  },
  {
    "id": "aws-da-057",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Um fluxo de eventos precisa ser consumido por duas equipes diferentes com ritmos de processamento distintos. Uma equipe precisa dos dados em tempo real, enquanto a outra processa em lotes a cada hora. Como você pode fornecer o mesmo fluxo para ambas sem que uma interfira na outra?",
    "solution": ["kinesis"],
    "availableServices": ["kinesis", "sqs", "sns", "msk"],
    "explanation": "O Kinesis Data Streams suporta 'Enhanced Fan-Out'. Isso permite que múltiplos consumidores (aplicativos) leiam o mesmo fluxo com sua própria taxa de transferência dedicada (2MB/s por consumidor), garantindo que o processamento lento de um consumidor não afete o processamento em tempo real de outro."
  },
  {
    "id": "aws-da-058",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Você tem um cluster Redshift que é usado intensivamente durante o horário comercial, mas fica ocioso à noite e nos fins de semana. Como você pode otimizar os custos desse cluster?",
    "solution": ["redshift"],
    "availableServices": ["redshift", "cloudwatch", "lambda", "scheduler"],
    "explanation": "O Redshift suporta pausa e retomada de clusters. Você pode automatizar esse processo usando um agendador (como o Amazon EventBridge Scheduler) para invocar uma função Lambda ou usar a API do Redshift para pausar o cluster fora do horário de pico e retomá-lo antes do início do expediente, economizando custos de computação."
  },
  {
    "id": "aws-da-059",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Você precisa consultar dados operacionais de um banco de dados RDS e dados históricos de um Data Lake no S3 em uma única consulta SQL.",
    "solution": ["rds", "s3", "athena"],
    "availableServices": ["rds", "s3", "athena", "dms", "redshift"],
    "explanation": "O Athena Federated Query permite que você execute consultas em fontes de dados externas. Usando o conector JDBC do Athena, você pode se conectar a um banco de dados RDS e executar uma consulta que une tabelas do RDS com tabelas do seu Data Lake no S3."
  },
  {
    "id": "aws-da-060",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Uma aplicação de jogos precisa de uma tabela de classificação global atualizada em tempo real. A solução deve ser altamente escalável e de baixa latência. Qual combinação de banco de dados e serviço de cache é a mais adequada?",
    "solution": ["dynamodb", "elasticache"],
    "availableServices": ["dynamodb", "elasticache", "rds", "aurora", "s3"],
    "explanation": "O DynamoDB é excelente para armazenar as pontuações. Para uma tabela de classificação em tempo real, o ElastiCache for Redis com sua estrutura de dados Sorted Set é extremamente eficiente e otimizado para essa tarefa, permitindo atualizações e recuperações de classificações com latência de microssegundos."
  },
  {
    "id": "aws-da-061",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Você precisa realizar uma análise de coorte para entender o comportamento do usuário ao longo do tempo. Os dados estão em um Data Warehouse no Redshift. Qual serviço de BI é mais adequado para criar visualizações de coorte e funil?",
    "solution": ["redshift", "quicksight"],
    "availableServices": ["redshift", "quicksight", "athena", "glue"],
    "explanation": "O Amazon QuickSight possui tipos de gráficos especializados, como análise de coorte e gráficos de funil, que são projetados para casos de uso de análise de comportamento do cliente. Ele se integra perfeitamente ao Redshift para obter os dados necessários."
  },
  {
    "id": "aws-da-062",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Um pipeline de dados precisa ser acionado pontualmente às 2h da manhã todos os dias para processar os dados do dia anterior. Qual serviço é o mais simples para agendar a execução de uma função Lambda ou um trabalho do Glue?",
    "solution": ["eventbridge"],
    "availableServices": ["eventbridge", "cloudwatch", "lambda", "step-functions"],
    "explanation": "O Amazon EventBridge (anteriormente CloudWatch Events) permite criar regras baseadas em agendamento (usando expressões cron) para acionar uma ampla variedade de alvos, incluindo funções Lambda, trabalhos do Glue e máquinas de estado do Step Functions, sendo a solução ideal para agendamento."
  },
  {
    "id": "aws-da-063",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Você está migrando um Data Warehouse on-premises de 500TB para a nuvem. O link de internet é lento e a transferência levaria meses. Qual serviço físico você usaria para transferir essa grande quantidade de dados para a AWS de forma eficiente?",
    "solution": ["s3"],
    "availableServices": ["s3", "dms", "storage gateway", "snowball"],
    "explanation": "O AWS Snowball é um serviço de transporte de dados em escala de petabytes que usa dispositivos físicos seguros para transferir grandes quantidades de dados para dentro e fora da AWS. Para uma migração única de 500TB, é muito mais rápido e econômico do que transferir pela internet. (Nota: Snowball é o serviço, mas o destino final é o S3)."
  },
  {
    "id": "aws-da-064",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Uma API precisa retornar dados que são o resultado de uma junção complexa e de longa duração em um banco de dados Aurora. Como você pode melhorar a performance da API para que ela não execute a consulta a cada chamada?",
    "solution": ["aurora", "lambda", "s3"],
    "availableServices": ["aurora", "lambda", "s3", "elasticache", "athena"],
    "explanation": "Este é um padrão de materialização de visualização. Você pode ter um processo agendado (Lambda + EventBridge) que executa a consulta demorada no Aurora e salva o resultado como um arquivo (por exemplo, JSON ou Parquet) no S3. A API principal então lê diretamente do arquivo no S3, que é muito mais rápido."
  },
  {
    "id": "aws-da-065",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Você precisa garantir que apenas usuários de dentro da sua rede corporativa (VPC) possam consultar dados no seu Data Lake usando o Athena, bloqueando todo o acesso da internet pública.",
    "solution": ["s3", "athena", "vpc"],
    "availableServices": ["s3", "athena", "vpc", "iam", "security group"],
    "explanation": "Configurando um VPC Endpoint para o S3 e para o Glue, e executando as consultas do Athena a partir de recursos dentro da VPC, você pode garantir que o tráfego entre o Athena e seus dados não saia da rede da AWS. Políticas de bucket do S3 podem restringir o acesso apenas a partir do VPC Endpoint."
  },
  {
    "id": "aws-da-066",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Um processo de ingestão cria milhares de arquivos pequenos (KBs) por hora no S3. Isso está causando problemas de performance para as consultas do Athena. Qual é a melhor estratégia para resolver isso?",
    "solution": ["s3", "glue"],
    "availableServices": ["s3", "glue", "lambda", "kinesis-firehose"],
    "explanation": "O problema dos 'arquivos pequenos' é comum. A melhor solução é um trabalho de compactação. Um trabalho do AWS Glue agendado pode ler os arquivos pequenos, compactá-los em arquivos maiores e otimizados (por exemplo, Parquet de 128MB) e reescrevê-los, melhorando drasticamente a performance de leitura do Athena."
  },
  {
    "id": "aws-da-067",
    "category": "data-analysis",
    "difficulty": 9,
    "question": "Você tem um cluster Redshift usado por vários departamentos. Você precisa isolar as cargas de trabalho para que as consultas de BI de um departamento não afetem o desempenho dos trabalhos de ETL de outro, além de gerenciar os custos por departamento.",
    "solution": ["redshift"],
    "availableServices": ["redshift", "iam", "cloudwatch", "lake-formation"],
    "explanation": "O Amazon Redshift Concurrency Scaling permite adicionar capacidade de cluster de forma automática e temporária para lidar com picos de consultas. Além disso, o Workload Management (WLM) permite definir filas para diferentes tipos de consultas (ETL vs. BI) para priorizar e isolar as cargas de trabalho. O uso de tags de alocação de custos pode ajudar a rastrear os custos por departamento."
  },
  {
    "id": "aws-da-068",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Você precisa fornecer uma interface de notebook Jupyter gerenciada e colaborativa para uma equipe de cientistas de dados explorar dados no S3 e treinar modelos de ML.",
    "solution": ["sagemaker"],
    "availableServices": ["sagemaker", "ec2", "glue", "emr"],
    "explanation": "O Amazon SageMaker Studio fornece um IDE completo baseado na web para machine learning, que inclui instâncias de notebook Jupyter gerenciadas. Ele simplifica a colaboração, o controle de versão e o acesso aos dados e recursos de computação da AWS."
  },
  {
    "id": "aws-da-069",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Crie um pipeline que ingere dados JSON de uma fila SQS, converte-os para Parquet em micro-lotes e os entrega ao S3 a cada 5 minutos.",
    "solution": ["sqs", "lambda", "kinesis-firehose", "s3"],
    "availableServices": ["sqs", "lambda", "kinesis-firehose", "s3", "glue"],
    "explanation": "Uma função Lambda pode ser acionada em lotes pela fila SQS. A Lambda então encaminha os dados para o Kinesis Data Firehose, que é otimizado para agrupar (buffer) os dados e entregá-los ao S3 em arquivos maiores e em um formato colunar como o Parquet, resolvendo o problema dos 'arquivos pequenos'."
  },
  {
    "id": "aws-da-070",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Você está implementando um pipeline de Change Data Capture (CDC) do RDS para o S3. Como você pode mesclar os eventos de INSERÇÃO, ATUALIZAÇÃO e EXCLUSÃO em uma tabela final consistente no Data Lake que represente o estado atual dos dados?",
    "solution": ["rds", "dms", "s3", "glue"],
    "availableServices": ["rds", "dms", "s3", "glue", "emr", "lambda"],
    "explanation": "O DMS captura os eventos CDC e os grava no S3. Um trabalho do AWS Glue (ou EMR com frameworks como Hudi/Iceberg/Delta Lake) pode então ler esses eventos e executar uma operação de 'MERGE' (ou 'UPSERT') na tabela de destino no S3, aplicando as inserções, atualizações e exclusões para manter uma visão atualizada."
  },
  {
    "id": "aws-da-071",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Você precisa compartilhar um grande conjunto de dados (até 100GB) de forma segura com um parceiro externo que também tem uma conta AWS, sem copiar os dados.",
    "solution": ["s3", "iam"],
    "availableServices": ["s3", "iam", "dms", "data exchange"],
    "explanation": "A maneira mais eficiente e segura é usar políticas de bucket do S3 e perfis do IAM (IAM Roles). Você pode criar uma política que concede a um perfil na conta do parceiro acesso de leitura (cross-account access) ao seu bucket, permitindo que eles acessem os dados diretamente sem duplicação."
  },
  {
    "id": "aws-da-072",
    "category": "data-analysis",
    "difficulty": 9,
    "question": "Um serviço de detecção de fraudes precisa processar transações em menos de 100 milissegundos. O processo envolve enriquecer a transação com dados do perfil do usuário (em um banco NoSQL) e com dados agregados históricos (em um Data Warehouse). Qual arquitetura atende a esse requisito de baixa latência?",
    "solution": ["kinesis", "lambda", "dynamodb", "elasticache"],
    "availableServices": ["kinesis", "lambda", "dynamodb", "elasticache", "redshift", "aurora"],
    "explanation": "A latência é crítica. O Redshift é muito lento para isso. O padrão é usar o Kinesis para ingerir a transação, acionando uma Lambda. A Lambda busca o perfil do usuário no DynamoDB (baixa latência). Os agregados históricos do Redshift devem ser pré-calculados e carregados no ElastiCache (cache em memória) para busca rápida pela Lambda."
  },
  {
    "id": "aws-da-073",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Você precisa criar uma cópia de um banco de dados RDS de produção para um ambiente de teste, garantindo que nenhum dado sensível do cliente seja exposto aos desenvolvedores.",
    "solution": ["rds", "glue"],
    "availableServices": ["rds", "glue", "dms", "lambda"],
    "explanation": "A melhor prática é restaurar um snapshot do RDS de produção em uma nova instância. Em seguida, execute um trabalho do AWS Glue ou um script customizado na nova instância para mascarar ou anonimizar os dados sensíveis antes de liberar o acesso aos desenvolvedores."
  },
  {
    "id": "aws-da-074",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Como você pode consultar dados em um formato de arquivo customizado ou pouco comum armazenado no S3 usando SQL padrão, sem precisar primeiro convertê-los para um formato como Parquet ou JSON?",
    "solution": ["s3", "athena", "lambda"],
    "availableServices": ["s3", "athena", "lambda", "glue", "emr"],
    "explanation": "O Amazon Athena suporta a criação de 'Source Connectors' usando o AWS Lambda. Você pode escrever uma função Lambda que entende como ler e desserializar seu formato de arquivo customizado, permitindo que o Athena a utilize para consultar os dados diretamente."
  },
  {
    "id": "aws-da-075",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Você precisa fornecer acesso de BI a um Data Lake governado pelo Lake Formation para usuários que estão usando o Active Directory da sua empresa para autenticação.",
    "solution": ["lake-formation", "quicksight", "iam"],
    "availableServices": ["lake-formation", "quicksight", "iam", "cognito", "active directory connector"],
    "explanation": "O QuickSight pode se integrar com o Active Directory (via AD Connector ou IAM Identity Center). Você pode mapear grupos do AD para perfis do IAM. No Lake Formation, você concede permissões a esses perfis do IAM, permitindo que os usuários acessem os dados corretos no QuickSight com suas credenciais corporativas."
  },
  {
    "id": "aws-da-076",
    "category": "data-analysis",
    "difficulty": 5,
    "question": "Um script Python que é executado em uma instância EC2 precisa de permissão para ler arquivos de um bucket S3. Qual é a maneira mais segura de conceder essa permissão sem usar chaves de acesso de longo prazo?",
    "solution": ["ec2", "s3", "iam"],
    "availableServices": ["ec2", "s3", "iam", "secrets-manager", "kms"],
    "explanation": "A maneira mais segura é usar um 'IAM Role for EC2'. Você cria um perfil com as permissões necessárias para acessar o S3 e o anexa à instância EC2. A instância então obtém credenciais temporárias automaticamente, evitando a necessidade de armazenar chaves de acesso no código ou na instância."
  },
  {
    "id": "aws-da-077",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Um processo de ETL precisa ser executado somente após a conclusão bem-sucedida de três outros trabalhos de ingestão que rodam em paralelo e têm durações variáveis. Como você pode orquestrar essa dependência?",
    "solution": ["glue", "step-functions"],
    "availableServices": ["glue", "step-functions", "eventbridge", "lambda", "mwaa"],
    "explanation": "O AWS Step Functions é perfeito para gerenciar fluxos de trabalho com paralelismo e dependências. Você pode usar um estado 'Parallel' para executar os três trabalhos de ingestão simultaneamente e, em seguida, transicionar para o trabalho de ETL somente após todos os três ramos paralelos serem concluídos com sucesso."
  },
  {
    "id": "aws-da-078",
    "category": "data-analysis",
    "difficulty": 9,
    "question": "Você precisa de uma solução de Data Warehouse que possa escalar a computação e o armazenamento de forma independente. Além disso, ela deve permitir o compartilhamento de dados ao vivo com outras contas AWS sem copiar os dados.",
    "solution": ["redshift"],
    "availableServices": ["redshift", "aurora", "s3", "athena"],
    "explanation": "O tipo de nó RA3 do Amazon Redshift, com armazenamento gerenciado, desacopla a computação e o armazenamento, permitindo o escalonamento independente. O recurso 'Redshift Data Sharing' permite o compartilhamento de dados ao vivo e transacionalmente consistentes entre clusters do Redshift em diferentes contas AWS."
  },
  {
    "id": "aws-da-079",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Um pipeline de streaming processa dados financeiros e precisa garantir que cada evento seja processado 'exatamente uma vez' (exactly-once processing), mesmo em caso de falhas e reinicializações.",
    "solution": ["kinesis", "flink", "kinesis-analytics"],
    "availableServices": ["kinesis", "kinesis-analytics", "lambda", "sqs"],
    "explanation": "Para garantir o processamento 'exatamente uma vez', você precisa de um framework que suporte transações e checkpoints. O Kinesis Data Analytics for Apache Flink oferece esse recurso. O Flink pode criar checkpoints consistentes do seu estado no S3, permitindo a recuperação de falhas sem perda de dados ou duplicação."
  },
  {
    "id": "aws-da-080",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Você precisa criar um painel de controle de custos da AWS que detalhe os gastos por serviço, por tag de projeto e por conta vinculada, usando os dados do AWS Cost and Usage Report (CUR).",
    "solution": ["s3", "athena", "quicksight"],
    "availableServices": ["s3", "athena", "quicksight", "glue", "cost explorer"],
    "explanation": "O AWS CUR entrega relatórios detalhados de custos para um bucket S3. O AWS Glue pode rastrear esses dados para criar uma tabela no catálogo. O Athena pode então consultar esses dados detalhados. Finalmente, o QuickSight pode se conectar ao Athena para criar painéis de análise de custos (FinOps) customizados e poderosos."
  },
  {
    "id": "aws-da-081",
    "category": "data-analysis",
    "difficulty": 4,
    "question": "Qual é a maneira mais simples de carregar um arquivo CSV de 50MB do seu computador para um bucket S3?",
    "solution": ["s3"],
    "availableServices": ["s3", "dms", "glue", "lambda"],
    "explanation": "Para uma carga única e simples de um arquivo, a maneira mais direta é usar o Console de Gerenciamento da AWS, a AWS Command Line Interface (CLI) com o comando `aws s3 cp`, ou um dos SDKs da AWS. Nenhum outro serviço de ingestão complexo é necessário."
  },
  {
    "id": "aws-da-082",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Uma consulta do Athena em uma tabela com 500 colunas está lenta porque sempre seleciona apenas 5 colunas. Qual formato de arquivo no S3 resolveria melhor esse problema de performance?",
    "solution": ["s3", "glue"],
    "availableServices": ["s3", "glue", "json", "csv", "parquet"],
    "explanation": "Formatos colunares como o Apache Parquet ou o ORC são ideais para isso. Eles armazenam dados por coluna, não por linha. Isso permite que o Athena leia apenas os dados das 5 colunas necessárias, em vez de escanear todas as 500 colunas de cada linha, resultando em uma melhoria massiva de performance e redução de custos."
  },
  {
    "id": "aws-da-083",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Você precisa testar uma alteração em um trabalho complexo do AWS Glue que lê de múltiplas fontes e escreve em vários destinos. Como você pode criar um ambiente de desenvolvimento interativo para depurar o script Spark?",
    "solution": ["glue"],
    "availableServices": ["glue", "sagemaker", "lambda", "emr"],
    "explanation": "O AWS Glue oferece 'Interactive Sessions' e 'Development Endpoints'. Ambos permitem que você execute e depure interativamente seu script de ETL a partir de um notebook (como Jupyter ou Zeppelin), conectando-se a um ambiente Spark gerenciado pelo Glue, acelerando o ciclo de desenvolvimento."
  },
  {
    "id": "aws-da-084",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Sua empresa quer vender acesso a conjuntos de dados curados para clientes externos. Você precisa de uma plataforma para publicar, licenciar e fornecer acesso a esses dados de forma segura e gerenciada.",
    "solution": ["s3", "data exchange"],
    "availableServices": ["s3", "data exchange", "api-gateway", "lake-formation"],
    "explanation": "O AWS Data Exchange é um serviço que facilita encontrar, assinar e usar dados de terceiros na nuvem. Como provedor, você pode usá-lo para licenciar e fornecer seus conjuntos de dados (armazenados no S3) para assinantes, que podem então usá-los em seus próprios ambientes AWS."
  },
  {
    "id": "aws-da-085",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Um banco de dados Aurora está sobrecarregado com consultas analíticas complexas que afetam o desempenho da aplicação principal. Qual é a melhor maneira de isolar essas cargas de trabalho de leitura?",
    "solution": ["aurora"],
    "availableServices": ["aurora", "rds", "redshift", "dms"],
    "explanation": "O Amazon Aurora suporta a criação de 'Réplicas de Leitura' (Read Replicas). Você pode criar uma ou mais réplicas que se mantêm sincronizadas com a instância principal e direcionar todas as consultas analíticas para essas réplicas, isolando a carga de trabalho de leitura da carga de trabalho de escrita principal."
  },
  {
    "id": "aws-da-086",
    "category": "data-analysis",
    "difficulty": 9,
    "question": "Um pipeline de dados precisa processar arquivos que chegam em um bucket S3, mas as tarefas de processamento podem levar até 30 minutos e exigem 10GB de RAM. As chegadas de arquivos são imprevisíveis. A solução deve ser serverless e econômica.",
    "solution": ["s3", "lambda", "fargate"],
    "availableServices": ["s3", "lambda", "fargate", "glue", "emr", "ec2"],
    "explanation": "A Lambda tem um limite de 15 minutos e 10GB de RAM, tornando-a inadequada. O Glue pode ser caro para tarefas curtas e imprevisíveis. Uma arquitetura comum é usar um evento do S3 para acionar uma Lambda, que atua como 'despachante'. A Lambda então inicia uma tarefa do ECS no Fargate, que pode executar a carga de trabalho pesada em um contêiner pelo tempo necessário, de forma serverless."
  },
  {
    "id": "aws-da-087",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Você precisa criar uma tabela no Glue Data Catalog que aponte para dados armazenados no Google Cloud Storage, para que possam ser consultados pelo Athena.",
    "solution": ["glue", "athena"],
    "availableServices": ["glue", "athena", "s3", "dms"],
    "explanation": "O AWS Glue suporta a criação de 'Custom Connectors' que podem se conectar a fontes de dados externas. Usando um conector para o Google Cloud Storage (GCS), você pode catalogar os dados no Glue e, em seguida, usar o Athena Federated Query para consultá-los como se estivessem na AWS."
  },
  {
    "id": "aws-da-088",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Uma aplicação precisa de uma visão agregada dos dados de vendas do último minuto, atualizada a cada segundo. Os dados brutos de vendas estão em um fluxo Kinesis.",
    "solution": ["kinesis", "kinesis-analytics"],
    "availableServices": ["kinesis", "kinesis-analytics", "lambda", "athena"],
    "explanation": "O Kinesis Data Analytics é ideal para agregações contínuas em janelas de tempo. Você pode usar uma consulta SQL com uma 'Tumbling Window' de 1 minuto para calcular as métricas. A consulta emitirá resultados atualizados continuamente, atendendo ao requisito de tempo real."
  },
  {
    "id": "aws-da-089",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Um pipeline de dados que usa o MWAA (Airflow) precisa acessar um banco de dados RDS. Como você armazena e acessa as credenciais do banco de dados de forma segura nos seus DAGs?",
    "solution": ["mwaa", "secrets-manager"],
    "availableServices": ["mwaa", "secrets-manager", "iam", "kms"],
    "explanation": "O MWAA se integra com o AWS Secrets Manager. Você pode configurar seu ambiente MWAA para usar o Secrets Manager como seu 'secrets backend'. Isso permite que você armazene as credenciais no Secrets Manager e as referencie de forma segura nas suas conexões do Airflow, sem expô-las nos DAGs."
  },
  {
    "id": "aws-da-090",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Você precisa criar um 'feature store' centralizado para cientistas de dados, onde features de ML pré-calculadas possam ser armazenadas, descobertas e servidas com baixa latência para treinamento e inferência de modelos.",
    "solution": ["sagemaker"],
    "availableServices": ["sagemaker", "s3", "dynamodb", "elasticache"],
    "explanation": "O Amazon SageMaker Feature Store é um serviço construído especificamente para esse propósito. Ele fornece um repositório para armazenar, atualizar, recuperar e compartilhar features de ML, com armazenamento online (baixa latência) e offline (análise em lote) integrados."
  },
  {
    "id": "aws-da-091",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Um cluster EMR precisa acessar dados em um bucket S3 que usa criptografia do lado do servidor com chaves KMS (SSE-KMS). O que é necessário para garantir que o EMR possa descriptografar os dados?",
    "solution": ["emr", "s3", "kms", "iam"],
    "availableServices": ["emr", "s3", "kms", "iam", "secrets-manager"],
    "explanation": "O perfil do IAM (IAM Role) associado às instâncias EC2 do cluster EMR precisa de permissões explícitas na política de chave do KMS para realizar a ação 'kms:Decrypt'. Sem essa permissão, o EMR não conseguirá ler os arquivos criptografados no S3."
  },
  {
    "id": "aws-da-092",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Como você pode carregar dados de um bucket S3 para uma tabela no Redshift de forma incremental, processando apenas os arquivos que chegaram desde a última execução?",
    "solution": ["s3", "redshift", "glue"],
    "availableServices": ["s3", "redshift", "glue", "dms", "lambda"],
    "explanation": "O AWS Glue suporta 'job bookmarks'. Quando ativados, o Glue rastreia os arquivos que já foram processados. Em execuções subsequentes do trabalho, ele processará automaticamente apenas os arquivos novos, simplificando a lógica de cargas incrementais."
  },
  {
    "id": "aws-da-093",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Um modelo de ML implantado em um endpoint do SageMaker precisa ser monitorado para detectar desvios (drift) nos dados de entrada e na qualidade do modelo ao longo do tempo.",
    "solution": ["sagemaker"],
    "availableServices": ["sagemaker", "cloudwatch", "lambda", "athena"],
    "explanation": "O Amazon SageMaker Model Monitor monitora automaticamente os modelos de machine learning em produção. Ele captura os dados de entrada, previsões e metadados, e os compara com uma linha de base para detectar desvios de dados e conceito, enviando alertas se forem encontrados problemas."
  },
  {
    "id": "aws-da-094",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Crie uma arquitetura que permita a analistas de dados consultarem dados de log que estão em um bucket S3, logs de métricas que estão no CloudWatch Logs e dados de negócios que estão no RDS, tudo a partir de uma única interface SQL.",
    "solution": ["s3", "cloudwatch", "rds", "athena"],
    "availableServices": ["s3", "cloudwatch", "rds", "athena", "glue", "opensearch"],
    "explanation": "O Amazon Athena, com seus conectores de consulta federada, é a solução. Ele pode consultar nativamente os dados no S3 (via Glue Catalog) e usar conectores para consultar o CloudWatch Logs e o RDS (via JDBC) na mesma consulta, unificando a experiência de análise."
  },
  {
    "id": "aws-da-095",
    "category": "data-analysis",
    "difficulty": 9,
    "question": "Você precisa construir um pipeline de dados que seja resiliente a falhas de uma região inteira da AWS. Como você projetaria a ingestão e o armazenamento de dados para garantir a continuidade dos negócios?",
    "solution": ["s3", "kinesis", "dynamodb", "route 53"],
    "availableServices": ["s3", "kinesis", "dynamodb", "route 53", "rds", "redshift"],
    "explanation": "Para resiliência multi-região, use serviços com recursos de replicação. O S3 pode usar a Replicação Cross-Region (CRR). O DynamoDB pode usar as Tabelas Globais. Para ingestão, você pode ter streams do Kinesis em duas regiões e usar o Route 53 com verificações de saúde para direcionar o tráfego para a região ativa."
  },
  {
    "id": "aws-da-096",
    "category": "data-analysis",
    "difficulty": 6,
    "question": "Você quer criar um dashboard no QuickSight, mas sua fonte de dados é um arquivo Excel grande e complexo que está em uma pasta compartilhada. Qual é a maneira mais direta de usar esses dados no QuickSight?",
    "solution": ["s3", "quicksight"],
    "availableServices": ["s3", "quicksight", "glue", "athena"],
    "explanation": "O QuickSight pode se conectar a várias fontes, mas a maneira mais simples para arquivos é carregá-los primeiro no S3. A partir daí, o QuickSight pode ingerir os dados do S3 diretamente para o seu mecanismo de análise em memória, o SPICE, ou consultá-los via Athena."
  },
  {
    "id": "aws-da-097",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Um trabalho de ETL em lote é executado diariamente e os resultados devem estar disponíveis para consulta no Athena. Como você pode garantir que as consultas no Athena não vejam dados parciais enquanto o trabalho de ETL está em execução?",
    "solution": ["s3", "glue", "athena"],
    "availableServices": ["s3", "glue", "athena", "lambda", "step-functions"],
    "explanation": "A melhor prática é fazer com que o trabalho de ETL escreva os novos dados em um local temporário no S3. Somente após a escrita ser concluída com sucesso, o trabalho deve atualizar o catálogo de dados do Glue (por exemplo, adicionando a nova partição) para apontar para os novos dados. Isso garante que a atualização da tabela seja atômica."
  },
  {
    "id": "aws-da-098",
    "category": "data-analysis",
    "difficulty": 8,
    "question": "Um painel de BI de alta visibilidade precisa de tempos de resposta de consulta abaixo de um segundo, mas a fonte de dados subjacente é um Data Lake no S3 que é lento para consultas complexas. Como você pode acelerar as consultas do painel?",
    "solution": ["s3", "athena", "quicksight"],
    "availableServices": ["s3", "athena", "quicksight", "redshift", "elasticache"],
    "explanation": "O Amazon QuickSight possui um mecanismo de cache em memória chamado SPICE. Você pode configurar seu conjunto de dados para importar os dados do Athena/S3 para o SPICE em uma programação. Todas as consultas do painel serão então executadas contra o SPICE, que é extremamente rápido, em vez do Data Lake."
  },
  {
    "id": "aws-da-099",
    "category": "data-analysis",
    "difficulty": 10,
    "question": "Projete uma arquitetura de 'Lambda' para análise de dados, onde um caminho de 'velocidade' processa dados em tempo real para painéis ao vivo e um caminho de 'lote' processa os mesmos dados para análises históricas complexas e precisas. Os resultados de ambos os caminhos devem ser acessíveis de forma unificada.",
    "solution": [["kinesis", "lambda", "dynamodb"], ["s3", "glue", "redshift"], ["quicksight"]],
    "availableServices": ["kinesis", "lambda", "dynamodb", "s3", "glue", "redshift", "quicksight", "athena"],
    "explanation": "Esta é a arquitetura Lambda clássica. O caminho de velocidade (camada rápida) usa Kinesis -> Lambda -> DynamoDB para resultados em tempo real. O caminho de lote (camada lenta) armazena os dados brutos no S3 e usa Glue/EMR para processá-los e carregá-los no Redshift para análises abrangentes. Uma ferramenta de BI como o QuickSight pode então unificar a visualização, consultando tanto o DynamoDB quanto o Redshift."
  },
  {
    "id": "aws-da-100",
    "category": "data-analysis",
    "difficulty": 7,
    "question": "Você precisa que as consultas do Athena em um Data Lake no S3 apliquem permissões de acesso em nível de coluna, ocultando colunas com PII de certos grupos de usuários.",
    "solution": ["s3", "glue", "lake-formation", "athena"],
    "availableServices": ["s3", "glue", "lake-formation", "athena", "iam", "macie"],
    "explanation": "O AWS Lake Formation é o serviço projetado para isso. Ele se integra ao Glue Data Catalog e permite definir permissões granulares, incluindo acesso em nível de tabela e coluna, para perfis do IAM. Quando um usuário consulta via Athena, o Lake Formation impõe essas permissões, filtrando as colunas que o usuário não tem permissão para ver."
  },
{
    "id": "aws-co-001",
    "category": "cloud-operations",
    "difficulty": 3,
    "question": "Uma instância EC2 está com alta utilização de CPU. Você precisa ser notificado automaticamente por e-mail quando a CPU exceder 80% por 5 minutos consecutivos. Qual a combinação de serviços mais simples para criar este alerta?",
    "solution": ["ec2", "cloudwatch", "sns"],
    "availableServices": ["ec2", "cloudwatch", "sns", "cloudtrail", "lambda", "eventbridge"],
    "explanation": "O CloudWatch monitora as métricas da EC2, como CPUUtilization. Um Alarme do CloudWatch pode ser criado com base nessa métrica. A ação do alarme pode ser publicar uma mensagem em um tópico SNS, que por sua vez envia uma notificação por e-mail aos assinantes."
  },
  {
    "id": "aws-co-002",
    "category": "cloud-operations",
    "difficulty": 5,
    "question": "Você precisa registrar todas as chamadas de API feitas na sua conta AWS para fins de auditoria de segurança e conformidade. Onde esses registros devem ser centralizados e armazenados de forma durável?",
    "solution": ["cloudtrail", "s3"],
    "availableServices": ["cloudtrail", "s3", "cloudwatch", "iam", "opensearch"],
    "explanation": "O AWS CloudTrail registra a atividade do usuário e as chamadas de API como eventos. As trilhas do CloudTrail podem ser configuradas para entregar esses arquivos de log a um bucket S3 para armazenamento de longo prazo e análise de auditoria."
  },
  {
    "id": "aws-co-003",
    "category": "cloud-operations",
    "difficulty": 6,
    "question": "Você precisa automatizar a aplicação de patches de segurança em um grande parque de instâncias EC2 com Windows Server, de acordo com uma janela de manutenção agendada. Qual serviço é projetado para essa tarefa?",
    "solution": ["systems manager"],
    "availableServices": ["systems manager", "ec2", "lambda", "cloudformation", "inspector"],
    "explanation": "O AWS Systems Manager, especificamente seu componente Patch Manager, foi projetado para automatizar o processo de aplicação de patches em sistemas operacionais em escala. Ele permite agendar janelas de manutenção e aplicar patches com base em regras predefinidas."
  },
  {
    "id": "aws-co-004",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Provisione uma infraestrutura de aplicação web completa (VPC, Subnets, EC2, Load Balancer) de forma automatizada e repetível. As alterações na infraestrutura devem ser versionadas e gerenciadas como código.",
    "solution": ["cloudformation"],
    "availableServices": ["cloudformation", "ec2", "ecs", "lambda", "codepipeline"],
    "explanation": "O AWS CloudFormation é o serviço de Infraestrutura como Código (IaC) da AWS. Ele permite que você defina e provisione todos os recursos de infraestrutura em um arquivo de template, garantindo implantações consistentes e permitindo o versionamento da sua arquitetura."
  },
  {
    "id": "aws-co-005",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Crie um pipeline de CI/CD completo para uma aplicação em contêineres. O código deve ser armazenado em um repositório, uma imagem Docker deve ser construída e, se os testes passarem, a imagem deve ser implantada em um cluster ECS sem tempo de inatividade.",
    "solution": ["codecommit", "codebuild", "codedeploy", "ecr", "ecs"],
    "availableServices": ["codecommit", "codebuild", "codedeploy", "ecr", "ecs", "s3", "lambda"],
    "explanation": "Esta é a suíte de CI/CD da AWS. CodeCommit para o repositório Git. CodeBuild para construir a imagem Docker e enviá-la para o Amazon ECR (Elastic Container Registry). CodePipeline orquestra o fluxo, e o CodeDeploy gerencia a implantação (por exemplo, Blue/Green) no cluster ECS."
  },
  {
    "id": "aws-co-006",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Um recurso crítico, como um bucket S3 ou uma tabela do DynamoDB, foi excluído acidentalmente. Qual serviço você usaria para investigar 'quem' fez a chamada de API de exclusão e 'quando'?",
    "solution": ["cloudtrail"],
    "availableServices": ["cloudtrail", "cloudwatch", "iam", "s3", "macie"],
    "explanation": "O AWS CloudTrail é o serviço de auditoria que registra todas as chamadas de API. Ao pesquisar no 'Event history' do CloudTrail, você pode filtrar pelo nome do recurso e pelo nome do evento (ex: 'DeleteBucket') para encontrar a identidade do IAM que realizou a ação e o horário exato."
  },
  {
    "id": "aws-co-007",
    "category": "cloud-operations",
    "difficulty": 6,
    "question": "Você precisa centralizar os logs de várias fontes (instâncias EC2, funções Lambda, logs de VPC Flow) para pesquisa e análise em tempo real. A solução deve permitir a criação de painéis de visualização.",
    "solution": ["cloudwatch logs", "opensearch"],
    "availableServices": ["cloudwatch logs", "opensearch", "s3", "athena", "kinesis-firehose"],
    "explanation": "Os logs podem ser enviados para o CloudWatch Logs. De lá, você pode usar uma 'Subscription Filter' para transmitir os logs em tempo real (via Kinesis Firehose, por exemplo) para o Amazon OpenSearch Service. O OpenSearch é otimizado para indexação e pesquisa de logs, e inclui o OpenSearch Dashboards para visualização."
  },
  {
    "id": "aws-co-008",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Uma aplicação web precisa se recuperar automaticamente de uma falha de Zona de Disponibilidade (AZ). O tráfego deve ser redirecionado para instâncias saudáveis em outra AZ sem intervenção manual.",
    "solution": ["ec2", "auto scaling group", "elastic load balancer", "route 53"],
    "availableServices": ["ec2", "auto scaling group", "elastic load balancer", "route 53", "dms"],
    "explanation": "Um Auto Scaling Group distribuído em múltiplas AZs garante que as instâncias sejam recriadas em caso de falha. Um Elastic Load Balancer (ELB) na frente do ASG realiza verificações de saúde e direciona o tráfego apenas para as instâncias saudáveis. O Route 53 pode ser usado para o DNS, mas o ELB é quem lida com o failover entre AZs."
  },
  {
    "id": "aws-co-009",
    "category": "cloud-operations",
    "difficulty": 6,
    "question": "Uma função Lambda precisa acessar um banco de dados RDS de forma segura, sem armazenar o nome de usuário e a senha no código. A senha também deve ser rotacionada automaticamente a cada 30 dias.",
    "solution": ["lambda", "rds", "secrets-manager"],
    "availableServices": ["lambda", "rds", "secrets-manager", "iam", "kms", "parameter store"],
    "explanation": "O AWS Secrets Manager é projetado para armazenar e gerenciar segredos, incluindo a capacidade de rotacionar senhas de bancos de dados RDS automaticamente. A função Lambda pode receber permissão do IAM para ler o segredo do Secrets Manager em tempo de execução."
  },
  {
    "id": "aws-co-010",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Você precisa garantir que todos os buckets S3 criados na sua conta tenham o versionamento e a criptografia do lado do servidor habilitados, para atender a uma política de conformidade. Qualquer recurso não conforme deve ser sinalizado.",
    "solution": ["aws config"],
    "availableServices": ["aws config", "iam", "cloudtrail", "inspector", "lambda"],
    "explanation": "O AWS Config é o serviço para avaliar, auditar e monitorar a configuração dos seus recursos AWS. Você pode usar 'Regras do AWS Config' (gerenciadas ou customizadas) para verificar continuamente se os recursos (como buckets S3) estão em conformidade com suas políticas. Recursos não conformes são sinalizados em um painel."
  },
  {
    "id": "aws-co-011",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Quando uma nova instância EC2 é lançada por um Auto Scaling Group, ela precisa ser automaticamente registrada como um alvo em um Application Load Balancer para começar a receber tráfego.",
    "solution": ["ec2", "auto scaling group", "elastic load balancer"],
    "availableServices": ["ec2", "auto scaling group", "elastic load balancer", "lambda", "eventbridge"],
    "explanation": "Esta é uma integração nativa. Ao associar um Auto Scaling Group (ASG) a um 'Target Group' de um Application Load Balancer (ALB), o ASG registrará automaticamente novas instâncias no Target Group e cancelará o registro de instâncias terminadas."
  },
  {
    "id": "aws-co-012",
    "category": "cloud-operations",
    "difficulty": 5,
    "question": "Crie um alerta de faturamento que notifique a equipe de FinOps via e-mail quando os custos estimados da conta AWS ultrapassarem um limite de $5.000 no mês.",
    "solution": ["aws budgets", "sns"],
    "availableServices": ["aws budgets", "sns", "cost explorer", "cloudwatch", "lambda"],
    "explanation": "O AWS Budgets permite que você defina orçamentos de custo e configure alertas que são acionados quando seu custo ou uso excede (ou está previsto para exceder) o valor orçado. As notificações de alerta podem ser enviadas para um tópico SNS."
  },
  {
    "id": "aws-co-013",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Uma instância EC2 foi comprometida. Você precisa isolá-la imediatamente da rede para investigação forense, mas sem terminá-la, para preservar a memória e o estado do disco.",
    "solution": ["ec2", "security group", "iam"],
    "availableServices": ["ec2", "security group", "iam", "vpc", "systems manager"],
    "explanation": "A maneira mais rápida de isolar uma instância é alterar seu Security Group para um grupo de 'quarentena'. Este grupo de segurança teria todas as regras de entrada e saída removidas, exceto talvez o acesso de um endereço IP específico do time de segurança. Isso bloqueia toda a comunicação de rede da instância."
  },
  {
    "id": "aws-co-014",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa de uma estratégia de backup centralizada e automatizada para vários serviços da AWS, incluindo instâncias EC2, volumes EBS e bancos de dados RDS, com políticas de retenção e ciclo de vida definidas.",
    "solution": ["aws backup"],
    "availableServices": ["aws backup", "ebs snapshots", "rds snapshots", "lambda", "s3"],
    "explanation": "O AWS Backup é um serviço totalmente gerenciado que centraliza e automatiza o backup de dados em serviços AWS. Ele permite criar 'Planos de Backup' que definem a frequência, a janela de backup, a política de retenção e o ciclo de vida para os recursos selecionados."
  },
  {
    "id": "aws-co-015",
    "category": "cloud-operations",
    "difficulty": 9,
    "question": "Automatize uma resposta a um alerta de segurança do AWS GuardDuty. Se um alerta indicar uma varredura de portas em uma instância EC2, uma função deve ser acionada para adicionar o IP de origem a uma lista de bloqueio na Network ACL.",
    "solution": ["guardduty", "eventbridge", "lambda", "vpc"],
    "availableServices": ["guardduty", "eventbridge", "lambda", "vpc", "systems manager", "sns"],
    "explanation": "O AWS GuardDuty gera 'Findings' (descobertas). Essas descobertas são enviadas como eventos para o Amazon EventBridge. Você pode criar uma regra no EventBridge que corresponda ao 'Finding' específico e use uma função Lambda como alvo. A Lambda então executará a lógica para extrair o IP e modificar a Network ACL (NACL) da VPC."
  },
  {
    "id": "aws-co-016",
    "category": "cloud-operations",
    "difficulty": 6,
    "question": "Forneça acesso temporário e com privilégios mínimos a um consultor externo para que ele possa acessar um bucket S3 específico por um período de 8 horas.",
    "solution": ["iam", "s3"],
    "availableServices": ["iam", "s3", "secrets-manager", "cognito"],
    "explanation": "A melhor prática é criar um 'IAM Role' (perfil) com uma política que conceda as permissões necessárias ao bucket S3. O consultor pode então 'assumir' esse perfil (AssumeRole) para obter credenciais de segurança temporárias que expiram automaticamente, em vez de criar um usuário IAM de longo prazo."
  },
  {
    "id": "aws-co-017",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Uma aplicação distribuída está apresentando alta latência. Você precisa identificar qual serviço no fluxo (ex: API Gateway -> Lambda -> DynamoDB) está causando o gargalo.",
    "solution": ["x-ray"],
    "availableServices": ["x-ray", "cloudwatch", "cloudtrail", "vpc flow logs"],
    "explanation": "O AWS X-Ray é o serviço de rastreamento distribuído. Ao instrumentar sua aplicação com o SDK do X-Ray, ele coleta dados sobre as solicitações e gera um 'mapa de serviço' visual, mostrando o fluxo das chamadas e a latência em cada componente, facilitando a identificação de gargalos."
  },
  {
    "id": "aws-co-018",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Implante uma aplicação web em contêineres que seja totalmente serverless, escalável e econômica, sem que você precise gerenciar servidores ou clusters de contêineres.",
    "solution": ["ecr", "ecs", "fargate"],
    "availableServices": ["ecr", "ecs", "fargate", "eks", "ec2"],
    "explanation": "O AWS Fargate é um mecanismo de computação serverless para contêineres que funciona com o Amazon ECS e EKS. Você empacota sua aplicação em contêineres, armazena no ECR, e o Fargate executa os contêineres sem que você precise provisionar ou gerenciar a infraestrutura de servidores EC2 subjacente."
  },
  {
    "id": "aws-co-019",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa analisar o tráfego de rede que entra e sai de suas instâncias EC2 para diagnosticar regras de firewall muito restritivas ou abertas. A análise deve capturar IPs de origem, destino e se o tráfego foi permitido ou negado.",
    "solution": ["vpc flow logs", "s3", "athena"],
    "availableServices": ["vpc flow logs", "s3", "athena", "cloudwatch", "cloudtrail"],
    "explanation": "Os VPC Flow Logs capturam informações sobre o tráfego IP que vai de e para as interfaces de rede na sua VPC. Você pode publicar esses logs no S3 e, em seguida, usar o Amazon Athena para executar consultas SQL nos logs, permitindo análises detalhadas do tráfego de rede."
  },
  {
    "id": "aws-co-020",
    "category": "cloud-operations",
    "difficulty": 6,
    "question": "Para otimizar custos, você precisa parar automaticamente todas as instâncias EC2 de 'desenvolvimento' fora do horário comercial (às 19h) e iniciá-las novamente no início do dia (às 8h).",
    "solution": ["ec2", "eventbridge", "lambda"],
    "availableServices": ["ec2", "eventbridge", "lambda", "systems manager", "auto scaling"],
    "explanation": "O Amazon EventBridge (Scheduler) é ideal para criar regras baseadas em tempo (cron jobs). Você pode ter duas regras: uma às 19h e outra às 8h. Ambas acionam uma função Lambda. A função Lambda contém o código (usando o SDK da AWS) para listar as instâncias com a tag 'ambiente=desenvolvimento' e executar as ações de 'stop' ou 'start'."
  },
  {
    "id": "aws-co-021",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Um novo desenvolvedor precisa de acesso programático à AWS CLI. Qual é a maneira mais segura de configurar as credenciais na sua máquina local?",
    "solution": ["iam", "aws cli"],
    "availableServices": ["iam", "aws cli", "ec2", "secrets-manager"],
    "explanation": "A melhor prática é criar um 'Usuário IAM' para o desenvolvedor, com as permissões mínimas necessárias. Em seguida, gerar 'chaves de acesso' (Access Key ID e Secret Access Key) para esse usuário. As chaves devem ser configuradas localmente usando o comando `aws configure`, que as armazena de forma segura no perfil do usuário."
  },
  {
    "id": "aws-co-022",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Você precisa de um painel centralizado que agregue descobertas de segurança de vários serviços da AWS, como GuardDuty, Inspector e Macie, para ter uma visão unificada da sua postura de segurança.",
    "solution": ["security hub"],
    "availableServices": ["security hub", "guardduty", "inspector", "macie", "cloudwatch"],
    "explanation": "O AWS Security Hub foi projetado exatamente para isso. Ele fornece uma visão abrangente do seu estado de segurança na AWS, centralizando e priorizando alertas e descobertas de segurança de vários serviços da AWS e de parceiros, em um único local."
  },
  {
    "id": "aws-co-023",
    "category": "cloud-operations",
    "difficulty": 9,
    "question": "Projete uma arquitetura de recuperação de desastres (DR) 'Pilot Light' para uma aplicação web. A infraestrutura principal deve ser provisionada, mas em uma escala mínima na região de DR, pronta para ser escalada rapidamente em caso de desastre.",
    "solution": ["route 53", "cloudformation", "rds", "ec2", "auto scaling group"],
    "availableServices": ["route 53", "cloudformation", "rds", "ec2", "auto scaling group", "dms"],
    "explanation": "Na região de DR, o CloudFormation define a infraestrutura. O RDS é provisionado como uma réplica de leitura cross-region. O Auto Scaling Group tem uma contagem mínima de instâncias (ex: 1). Os dados (ex: S3) são replicados. Em um desastre, o Route 53 direciona o tráfego, a réplica do RDS é promovida e o Auto Scaling Group é escalado para a capacidade total."
  },
  {
    "id": "aws-co-024",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Um volume EBS de uma instância EC2 crítica está ficando sem espaço. Você precisa aumentar seu tamanho sem tempo de inatividade para a aplicação.",
    "solution": ["ebs", "ec2"],
    "availableServices": ["ebs", "ec2", "s3", "storage gateway"],
    "explanation": "Os volumes EBS suportam 'modificações elásticas'. Você pode modificar o tamanho, o tipo e o IOPS de um volume anexado a uma instância EC2 sem precisar desanexá-lo. Após a AWS modificar o volume, você precisa estender o sistema de arquivos no sistema operacional para usar o novo espaço."
  },
  {
    "id": "aws-co-025",
    "category": "cloud-operations",
    "difficulty": 6,
    "question": "Você precisa distribuir globalmente o conteúdo de um site estático hospedado no S3, garantindo baixa latência para usuários em todo o mundo e proteção contra ataques DDoS na camada de rede.",
    "solution": ["s3", "cloudfront", "aws shield"],
    "availableServices": ["s3", "cloudfront", "aws shield", "route 53", "ec2"],
    "explanation": "O Amazon CloudFront é a CDN da AWS que armazena o conteúdo em cache globalmente. Além disso, todas as distribuições do CloudFront são protegidas por padrão pelo AWS Shield Standard, que oferece defesa contra os ataques DDoS mais comuns na camada de rede e transporte."
  },
  {
    "id": "aws-co-026",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Uma aplicação legada que não suporta escalonamento horizontal precisa de alta disponibilidade. Se a instância EC2 principal falhar, o tráfego precisa ser redirecionado para uma instância de standby em outra AZ.",
    "solution": ["ec2", "route 53", "cloudwatch"],
    "availableServices": ["ec2", "route 53", "cloudwatch", "elastic load balancer", "auto scaling group"],
    "explanation": "Um ELB ou ASG não funcionaria para uma aplicação stateful única. A solução é usar 'Verificações de Saúde' (Health Checks) do Route 53. Você cria uma verificação de saúde que monitora a instância principal. O registro DNS do Route 53 é configurado com uma política de 'Failover', apontando para a instância de standby se a verificação de saúde da principal falhar."
  },
  {
    "id": "aws-co-027",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa executar um comando shell em centenas de instâncias EC2 de uma só vez para coletar informações de diagnóstico, sem precisar fazer login via SSH em cada uma.",
    "solution": ["systems manager"],
    "availableServices": ["systems manager", "ec2", "lambda", "ssh"],
    "explanation": "O AWS Systems Manager Run Command permite que você execute comandos ou scripts em um grande número de instâncias gerenciadas de forma remota e segura. Você pode executar comandos ad-hoc, rastrear o status e coletar a saída de todas as instâncias em um único local."
  },
  {
    "id": "aws-co-028",
    "category": "cloud-operations",
    "difficulty": 5,
    "question": "Um desenvolvedor precisa de permissões para gerenciar instâncias EC2, mas não deve ter permissão para modificar configurações de IAM. Como você estrutura essa permissão?",
    "solution": ["iam"],
    "availableServices": ["iam", "ec2", "security group", "organizations"],
    "explanation": "No IAM, você cria uma 'Política' que concede permissões para ações da EC2 (ex: `ec2:StartInstances`, `ec2:StopInstances`) e explicitamente nega ou não inclui permissões para ações do IAM (ex: `iam:*`). Essa política é então anexada ao usuário ou grupo do desenvolvedor, seguindo o princípio do menor privilégio."
  },
  {
    "id": "aws-co-029",
    "category": "cloud-operations",
    "difficulty": 9,
    "question": "Sua organização tem várias contas AWS para diferentes departamentos (dev, prod, finanças). Você precisa aplicar uma política de segurança (SCP) que impeça qualquer usuário em qualquer conta de desativar o CloudTrail, centralizar a cobrança e gerenciar todas as contas de forma unificada.",
    "solution": ["aws organizations"],
    "availableServices": ["aws organizations", "iam", "cloudtrail", "aws budgets"],
    "explanation": "O AWS Organizations permite gerenciar centralmente várias contas AWS. Você pode usar o 'Faturamento Consolidado' para a cobrança. E o mais importante, você pode aplicar 'Políticas de Controle de Serviço' (SCPs) na raiz da organização ou em Unidades Organizacionais (OUs) para impor barreiras de permissão, como proibir a desativação de serviços críticos como o CloudTrail, mesmo para o administrador da conta filha."
  },
  {
    "id": "aws-co-030",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Uma aplicação conteinerizada no ECS precisa de permissão para ler de uma fila SQS. Como você concede essa permissão ao contêiner de forma segura?",
    "solution": ["ecs", "sqs", "iam"],
    "availableServices": ["ecs", "sqs", "iam", "ecr", "secrets-manager"],
    "explanation": "A melhor prática é usar 'IAM Roles for ECS Tasks'. Você cria um 'Task Role' do IAM com uma política que permite as ações necessárias na fila SQS. Em seguida, você associa esse perfil à 'Definição da Tarefa' do ECS. Os contêineres dessa tarefa herdarão automaticamente as permissões por meio de credenciais temporárias."
  },
  {
    "id": "aws-co-031",
    "category": "cloud-operations",
    "difficulty": 6,
    "question": "Você precisa criar um endereço IP público estático para uma instância EC2, que não mude mesmo se a instância for parada e iniciada.",
    "solution": ["elastic ip"],
    "availableServices": ["elastic ip", "ec2", "route 53", "vpc"],
    "explanation": "Um 'Elastic IP' (EIP) é um endereço IPv4 público estático projetado para computação em nuvem dinâmica. Você aloca um EIP na sua conta e o associa à sua instância EC2. O endereço permanece com sua conta até que você o libere, permitindo reassociá-lo a outra instância se necessário."
  },
  {
    "id": "aws-co-032",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Um desenvolvedor acidentalmente provisionou uma instância EC2 `m5.24xlarge` muito cara. Como você pode prevenir que isso aconteça no futuro, permitindo que apenas tipos de instância específicos sejam lançados?",
    "solution": ["iam"],
    "availableServices": ["iam", "aws config", "service catalog", "organizations"],
    "explanation": "Você pode usar 'chaves de condição' nas políticas do IAM. Uma política pode permitir a ação `ec2:RunInstances` mas com uma condição que restringe o atributo `ec2:InstanceType` a uma lista aprovada (ex: `t3.micro`, `t3.small`). Qualquer tentativa de lançar um tipo de instância fora dessa lista será negada."
  },
  {
    "id": "aws-co-033",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Uma aplicação precisa se conectar a um banco de dados RDS a partir de uma instância EC2 dentro da mesma VPC de forma privada e segura. Qual configuração de rede garante que o tráfego não passe pela internet pública?",
    "solution": ["ec2", "rds", "vpc", "security group"],
    "availableServices": ["ec2", "rds", "vpc", "security group", "internet gateway", "nat gateway"],
    "explanation": "Ambos os recursos devem estar em sub-redes privadas dentro da VPC. A conectividade é controlada por 'Security Groups'. O Security Group do RDS deve ter uma regra de entrada que permite o tráfego na porta do banco de dados (ex: 3306 para MySQL) originado do Security Group da instância EC2. Isso cria uma regra de firewall específica sem expor o banco de dados."
  },
  {
    "id": "aws-co-034",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa encontrar rapidamente todas as instâncias EC2 em sua conta que não possuem a tag 'Projeto' para fins de alocação de custos.",
    "solution": ["resource groups & tag editor"],
    "availableServices": ["resource groups & tag editor", "ec2", "cloudwatch", "systems manager"],
    "explanation": "O AWS Resource Groups & Tag Editor é a ferramenta central para gerenciar tags. Usando o 'Tag Editor', você pode pesquisar por todos os recursos de um tipo específico (como EC2) e filtrar por tags, incluindo a busca por recursos onde uma tag específica 'não está presente'."
  },
  {
    "id": "aws-co-035",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Você precisa de uma conexão de rede privada e dedicada entre seu data center on-premises e sua VPC na AWS, com largura de banda consistente e baixa latência.",
    "solution": ["direct connect"],
    "availableServices": ["direct connect", "vpn", "vpc", "internet gateway"],
    "explanation": "O AWS Direct Connect estabelece uma conexão de rede privada e dedicada entre seu ambiente on-premises e a AWS. Diferente de uma VPN que opera sobre a internet pública, o Direct Connect oferece uma experiência de rede mais consistente e com maior largura de banda."
  },
  {
    "id": "aws-co-036",
    "category": "cloud-operations",
    "difficulty": 9,
    "question": "Um serviço crítico precisa de um objetivo de tempo de recuperação (RTO) de 15 minutos e um objetivo de ponto de recuperação (RPO) de 1 minuto em caso de desastre regional. Qual estratégia de DR atende a esses requisitos rigorosos?",
    "solution": ["rds", "s3", "route 53", "auto scaling group"],
    "availableServices": ["rds", "s3", "route 53", "auto scaling group", "aws backup"],
    "explanation": "Isso exige uma estratégia de 'Warm Standby' ou 'Hot Standby'. RPO de 1 minuto sugere replicação contínua de dados, como réplicas de leitura cross-region para RDS Aurora ou replicação cross-region (CRR) para S3. RTO de 15 minutos exige que a infraestrutura esteja pré-provisionada (Warm Standby) ou totalmente ativa (Hot Standby), com failover de DNS automatizado via Route 53."
  },
  {
    "id": "aws-co-037",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você quer padronizar a criação de produtos de TI (ex: um servidor de desenvolvimento com EC2 e RDS) para que os desenvolvedores possam provisioná-los através de um portal de autoatendimento, sem acessar diretamente o CloudFormation.",
    "solution": ["service catalog"],
    "availableServices": ["service catalog", "cloudformation", "lambda", "organizations"],
    "explanation": "O AWS Service Catalog permite que as organizações criem e gerenciem catálogos de serviços de TI aprovados para uso na AWS. Você, como administrador, define os produtos usando templates do CloudFormation e os usuários podem implantar esses produtos padronizados com um clique, sem ver ou modificar o código subjacente."
  },
  {
    "id": "aws-co-038",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Você precisa expor vários microsserviços, cada um executado em seu próprio cluster ECS, através de um único endpoint de API. A solução deve lidar com roteamento, limitação de taxa (throttling) e autenticação.",
    "solution": ["api gateway", "ecs"],
    "availableServices": ["api gateway", "ecs", "elastic load balancer", "lambda"],
    "explanation": "O Amazon API Gateway atua como uma 'porta da frente' unificada para suas aplicações. Você pode configurar rotas (ex: /users, /orders) que direcionam para diferentes serviços de backend, como os serviços ECS. O API Gateway também fornece recursos integrados para throttling, autenticação (ex: chaves de API, IAM, Cognito) e cache."
  },
  {
    "id": "aws-co-039",
    "category": "cloud-operations",
    "difficulty": 6,
    "question": "Um bucket S3 contém dados sensíveis. Você precisa garantir que todos os novos objetos carregados no bucket sejam criptografados automaticamente, sem que o cliente precise especificar cabeçalhos de criptografia.",
    "solution": ["s3", "kms"],
    "availableServices": ["s3", "kms", "iam", "macie"],
    "explanation": "Você pode habilitar a 'Criptografia Padrão' (Default Encryption) nas propriedades do bucket S3. Ao configurar isso para usar SSE-S3 (chaves gerenciadas pela AWS) ou SSE-KMS (chaves gerenciadas no KMS), qualquer objeto enviado para o bucket sem informações de criptografia será criptografado automaticamente."
  },
  {
    "id": "aws-co-040",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Após uma implantação, a latência de uma função Lambda aumentou. A função não mudou, mas uma de suas dependências (uma biblioteca Python) foi atualizada. Como você pode implantar a versão anterior da função Lambda rapidamente?",
    "solution": ["lambda"],
    "availableServices": ["lambda", "codedeploy", "cloudformation", "s3"],
    "explanation": "O AWS Lambda suporta 'Versionamento e Aliases'. Cada vez que você publica uma função, uma nova versão imutável é criada. Você pode usar um 'alias' (ex: 'PROD') que aponta para a versão estável. Para reverter, basta reconfigurar o alias 'PROD' para apontar para a versão funcional anterior, o que é uma operação quase instantânea."
  },
  {
    "id": "aws-co-041",
    "category": "cloud-operations",
    "difficulty": 4,
    "question": "Você precisa de um local centralizado para armazenar parâmetros de configuração, como URLs de banco de dados ou chaves de recursos, para serem usados por suas aplicações EC2 e funções Lambda.",
    "solution": ["systems manager parameter store"],
    "availableServices": ["systems manager parameter store", "secrets-manager", "s3", "dynamodb"],
    "explanation": "O AWS Systems Manager Parameter Store oferece armazenamento seguro e hierárquico para gerenciamento de dados de configuração. É ideal para armazenar dados não secretos. Para dados sensíveis como senhas, o Secrets Manager é mais apropriado."
  },
  {
    "id": "aws-co-042",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Uma aplicação precisa de um sistema de arquivos compartilhado e de alta performance, acessível por múltiplas instâncias EC2 Linux simultaneamente.",
    "solution": ["efs"],
    "availableServices": ["efs", "ebs", "s3", "fsx"],
    "explanation": "O Amazon EFS (Elastic File System) fornece um sistema de arquivos de rede (NFS) simples, escalável e elástico para ser usado com instâncias EC2. Ele é projetado para ser montado e acessado por muitas instâncias ao mesmo tempo, ideal para armazenamento compartilhado."
  },
  {
    "id": "aws-co-043",
    "category": "cloud-operations",
    "difficulty": 9,
    "question": "Um processo de ingestão de vídeo precisa ser orquestrado: quando um vídeo é carregado no S3, uma função Lambda deve extrair metadados. Em seguida, duas tarefas de transcodificação (para 1080p e 480p) devem ocorrer em paralelo. Quando ambas terminarem, uma notificação de sucesso deve ser enviada.",
    "solution": ["s3", "lambda", "step-functions", "sns"],
    "availableServices": ["s3", "lambda", "step-functions", "sns", "sqs", "eventbridge"],
    "explanation": "Este é um caso de uso perfeito para o AWS Step Functions. Um gatilho do S3 inicia a máquina de estados. O primeiro estado invoca a Lambda. Um estado 'Parallel' executa as duas tarefas de transcodificação (que poderiam ser outras Lambdas ou tarefas do Fargate). O fluxo converge após o paralelismo para enviar a notificação via SNS."
  },
  {
    "id": "aws-co-044",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa analisar suas faturas da AWS para identificar qual recurso específico (ex: uma instância EC2 com um ID particular) está gerando mais custos.",
    "solution": ["cost explorer", "tags"],
    "availableServices": ["cost explorer", "tags", "aws budgets", "cloudwatch"],
    "explanation": "A chave para a análise de custos granulares é o 'tagging'. Ao aplicar tags (ex: 'Projeto:Alfa', 'CentroCusto:123') aos seus recursos, você pode ativar essas tags no AWS Cost Explorer. Isso permite filtrar e agrupar os custos por tag, identificando exatamente quais recursos ou projetos são responsáveis pelos gastos."
  },
  {
    "id": "aws-co-045",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Uma aplicação em uma instância EC2 em uma sub-rede privada precisa acessar serviços da AWS (como S3 e SQS) sem que o tráfego passe pela internet. A solução não deve usar um NAT Gateway.",
    "solution": ["vpc", "ec2", "s3", "vpc endpoint"],
    "availableServices": ["vpc", "ec2", "s3", "vpc endpoint", "nat gateway", "internet gateway"],
    "explanation": "Os 'VPC Endpoints' fornecem conectividade privada da sua VPC para serviços da AWS suportados. Um 'Gateway Endpoint' para S3 e DynamoDB ou um 'Interface Endpoint' para outros serviços (como SQS) permite que o tráfego flua pela rede privada da AWS, melhorando a segurança e a performance."
  },
  {
    "id": "aws-co-046",
    "category": "cloud-operations",
    "difficulty": 6,
    "question": "Um volume EBS foi acidentalmente excluído. Qual é o pré-requisito fundamental para que você possa restaurar os dados desse volume?",
    "solution": ["ebs snapshots"],
    "availableServices": ["ebs snapshots", "aws backup", "s3", "glacier"],
    "explanation": "Os dados de um volume EBS só podem ser recuperados se houver um 'snapshot' dele. Snapshots são backups de point-in-time dos volumes EBS, armazenados no S3. Sem um snapshot pré-existente (criado manualmente ou por uma política do AWS Backup), os dados de um volume excluído são irrecuperáveis."
  },
  {
    "id": "aws-co-047",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você está executando uma aplicação em contêineres no EKS. Como você pode escalar automaticamente o número de pods com base na utilização da CPU?",
    "solution": ["eks", "horizontal pod autoscaler"],
    "availableServices": ["eks", "horizontal pod autoscaler", "cluster autoscaler", "ec2 auto scaling"],
    "explanation": "No Kubernetes, o 'Horizontal Pod Autoscaler' (HPA) é o recurso nativo para escalar o número de réplicas de um pod com base em métricas observadas, como a utilização da CPU. O HPA ajusta dinamicamente o número de pods para atender à demanda."
  },
  {
    "id": "aws-co-048",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "No seu cluster EKS, os pods não conseguem ser agendados devido à falta de capacidade de nós (instâncias EC2). Como você pode escalar automaticamente o número de nós no cluster?",
    "solution": ["eks", "cluster autoscaler"],
    "availableServices": ["eks", "cluster autoscaler", "horizontal pod autoscaler", "ec2 auto scaling"],
    "explanation": "Enquanto o HPA escala os pods, o 'Cluster Autoscaler' é o componente que escala os nós (a infraestrutura). Ele monitora pods que estão no estado 'Pending' por falta de recursos e adiciona automaticamente novos nós (instâncias EC2) ao cluster para acomodá-los."
  },
  {
    "id": "aws-co-049",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa de um painel de controle operacional que mostre métricas de várias fontes (ex: CPU da EC2, invocações da Lambda, tamanho da fila SQS) e logs de aplicações em uma única visualização consolidada.",
    "solution": ["cloudwatch dashboards"],
    "availableServices": ["cloudwatch dashboards", "quicksight", "opensearch", "grafana"],
    "explanation": "Os 'CloudWatch Dashboards' são a solução nativa para criar painéis operacionais customizáveis. Você pode adicionar widgets que exibem métricas do CloudWatch, resultados de consultas do CloudWatch Logs Insights e alarmes, tudo em uma única tela para monitoramento consolidado."
  },
  {
    "id": "aws-co-050",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Implante uma atualização em um conjunto de instâncias EC2 de forma gradual. A nova versão deve ser implantada primeiro em um pequeno número de instâncias e, se os alarmes do CloudWatch permanecerem OK, a implantação deve continuar para o restante do parque.",
    "solution": ["codedeploy", "ec2", "cloudwatch"],
    "availableServices": ["codedeploy", "ec2", "cloudwatch", "cloudformation", "codebuild"],
    "explanation": "O AWS CodeDeploy suporta estratégias de implantação avançadas, como 'Canary' ou 'Linear'. Ele pode ser configurado para monitorar alarmes do CloudWatch durante o processo. Se um alarme for acionado após a implantação no primeiro lote, o CodeDeploy reverterá automaticamente a alteração, prevenindo uma falha em larga escala."
  },
  {
    "id": "aws-co-051",
    "category": "cloud-operations",
    "difficulty": 6,
    "question": "Como você pode garantir que uma função Lambda, dentro de uma VPC, possa acessar a internet pública para chamar uma API de terceiros?",
    "solution": ["lambda", "vpc", "nat gateway"],
    "availableServices": ["lambda", "vpc", "nat gateway", "internet gateway", "vpc endpoint"],
    "explanation": "Uma Lambda em uma sub-rede privada não tem acesso direto à internet. Para permitir o acesso de saída, a tabela de rotas da sub-rede privada deve apontar o tráfego de internet (0.0.0.0/0) para um 'NAT Gateway', que por sua vez reside em uma sub-rede pública e tem acesso à internet."
  },
  {
    "id": "aws-co-052",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa analisar as dependências das bibliotecas em seu código e verificar se há vulnerabilidades de segurança conhecidas durante o processo de build no seu pipeline de CI/CD.",
    "solution": ["codebuild", "inspector"],
    "availableServices": ["codebuild", "inspector", "guardduty", "codeguru"],
    "explanation": "O Amazon Inspector pode realizar a 'análise de composição de software' (SCA), que escaneia as dependências do seu código em busca de vulnerabilidades. Isso pode ser integrado como uma etapa no AWS CodeBuild para falhar o build caso vulnerabilidades críticas sejam encontradas."
  },
  {
    "id": "aws-co-053",
    "category": "cloud-operations",
    "difficulty": 9,
    "question": "Uma aplicação crítica falhou. Você precisa montar uma 'war room' virtual, notificando as equipes de desenvolvimento e operações via chat e e-mail, e registrar todos os eventos e ações tomadas para a análise post-mortem.",
    "solution": ["incident manager"],
    "availableServices": ["incident manager", "systems manager", "sns", "cloudwatch", "chatbot"],
    "explanation": "O 'Incident Manager', um recurso do AWS Systems Manager, foi projetado para isso. Ele permite criar planos de resposta que, quando um incidente é detectado (via CloudWatch Alarms, por exemplo), automaticamente engajam as equipes certas (via SMS, e-mail, AWS Chatbot), criam um canal de chat e registram o cronograma do incidente."
  },
  {
    "id": "aws-co-054",
    "category": "cloud-operations",
    "difficulty": 6,
    "question": "Um time de desenvolvimento precisa de um ambiente de banco de dados para testes que pode ser criado e destruído rapidamente. O banco não precisa de alta disponibilidade. Qual serviço de banco de dados relacional é mais adequado?",
    "solution": ["rds"],
    "availableServices": ["rds", "aurora", "dynamodb", "redshift"],
    "explanation": "O Amazon RDS (com um mecanismo como PostgreSQL ou MySQL) é perfeito para isso. Você pode provisionar uma instância 'Single-AZ' (sem alta disponibilidade) para reduzir custos e usar scripts de IaC (CloudFormation) para criá-la e destruí-la sob demanda."
  },
  {
    "id": "aws-co-055",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa conectar sua VPC a outra VPC em uma região diferente da AWS para permitir que recursos em ambas as VPCs se comuniquem usando IPs privados.",
    "solution": ["vpc peering", "transit gateway"],
    "availableServices": ["vpc peering", "transit gateway", "direct connect", "vpn"],
    "explanation": "Tanto o 'VPC Peering' quanto o 'Transit Gateway' podem resolver isso. O VPC Peering cria uma conexão 1-para-1. O Transit Gateway atua como um hub central para interconectar muitas VPCs (e conexões on-premises), o que é mais escalável. Para conectar entre regiões, ambos os serviços suportam 'inter-region peering'."
  },
  {
    "id": "aws-co-056",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Você está migrando uma aplicação on-premises que usa um sistema de arquivos Windows para a AWS. Você precisa de um armazenamento de arquivos totalmente gerenciado e compatível com o protocolo SMB.",
    "solution": ["fsx for windows file server"],
    "availableServices": ["fsx for windows file server", "efs", "s3", "ebs"],
    "explanation": "O Amazon FSx for Windows File Server fornece um sistema de arquivos totalmente gerenciado e nativo do Windows, construído sobre o Windows Server e acessível via protocolo SMB. É a solução ideal para migrar cargas de trabalho que dependem de compartilhamento de arquivos do Windows."
  },
  {
    "id": "aws-co-057",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você quer executar comandos da AWS CLI a partir de um canal do Slack para realizar ações operacionais rápidas, como verificar o status de uma instância.",
    "solution": ["aws chatbot", "slack"],
    "availableServices": ["aws chatbot", "slack", "lambda", "sns", "systems manager"],
    "explanation": "O AWS Chatbot simplifica a integração de operações de chat (ChatOps) com a AWS. Ele permite que você receba alertas e execute comandos da AWS CLI diretamente do Slack ou Amazon Chime, com as permissões controladas por um perfil do IAM."
  },
  {
    "id": "aws-co-058",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Um conjunto de instâncias EC2 precisa ser iniciado em proximidade física dentro de uma Zona de Disponibilidade para minimizar a latência de rede entre elas, para uma carga de trabalho de computação de alta performance (HPC).",
    "solution": ["placement groups"],
    "availableServices": ["placement groups", "ec2", "auto scaling group", "vpc"],
    "explanation": "Os 'Placement Groups' (Grupos de Posicionamento) com a estratégia 'Cluster' permitem que você agrupe instâncias em um único rack dentro de uma AZ. Isso fornece a menor latência e a maior largura de banda de rede entre as instâncias, ideal para aplicações HPC."
  },
  {
    "id": "aws-co-059",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa obter um certificado SSL/TLS público para seu domínio e gerenciá-lo (incluindo a renovação automática) para uso em um Application Load Balancer.",
    "solution": ["certificate manager", "elastic load balancer"],
    "availableServices": ["certificate manager", "elastic load balancer", "route 53", "iam"],
    "explanation": "O AWS Certificate Manager (ACM) permite provisionar, gerenciar e implantar certificados SSL/TLS públicos e privados. O ACM se integra perfeitamente com serviços como ELB e CloudFront, e o mais importante, gerencia a renovação automática dos certificados públicos que ele provisiona."
  },
  {
    "id": "aws-co-060",
    "category": "cloud-operations",
    "difficulty": 9,
    "question": "Você precisa de um serviço de DNS que possa rotear os usuários para diferentes endpoints com base em sua localização geográfica (geolocalização), para otimizar a latência e fornecer conteúdo localizado.",
    "solution": ["route 53"],
    "availableServices": ["route 53", "cloudfront", "elastic load balancer", "api gateway"],
    "explanation": "O Amazon Route 53 oferece várias 'Políticas de Roteamento'. A política de 'Geolocalização' permite que você escolha os recursos que atenderão ao tráfego com base na localização geográfica de seus usuários (continente, país ou estado nos EUA), direcionando-os para o endpoint mais próximo ou mais apropriado."
  },
  {
    "id": "aws-co-061",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa criar uma imagem de máquina (AMI) customizada a partir de uma instância EC2 configurada, para poder lançar novas instâncias com o mesmo software e configurações.",
    "solution": ["ec2", "ami"],
    "availableServices": ["ec2", "ami", "lambda", "cloudformation", "packer"],
    "explanation": "O processo padrão na AWS para isso é configurar uma instância EC2 base e, em seguida, usar a ação 'Create Image' no console da EC2 ou na CLI. Isso cria uma Amazon Machine Image (AMI) que é um modelo para suas instâncias, contendo o sistema operacional e o software que você instalou."
  },
  {
    "id": "aws-co-062",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Automatize a criação de snapshots de volumes EBS em uma programação diária, garantindo que os snapshots mais antigos que 30 dias sejam excluídos automaticamente.",
    "solution": ["amazon data lifecycle manager"],
    "availableServices": ["amazon data lifecycle manager", "ebs", "lambda", "eventbridge", "aws backup"],
    "explanation": "Embora o AWS Backup possa fazer isso, o Amazon Data Lifecycle Manager (DLM) é um serviço mais específico e simples para automatizar a criação, cópia e exclusão de snapshots de EBS. Você cria uma política no DLM que define a programação e a retenção, e o serviço cuida do resto."
  },
  {
    "id": "aws-co-063",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Sua aplicação em um Auto Scaling Group está sofrendo com tempos de inicialização lentos porque cada nova instância precisa baixar e instalar várias dependências. Como você pode acelerar o tempo de inicialização?",
    "solution": ["ec2", "ami", "auto scaling group"],
    "availableServices": ["ec2", "ami", "auto scaling group", "lambda", "user data"],
    "explanation": "A melhor prática é criar uma 'Golden AMI'. Em vez de instalar o software em tempo de inicialização (via 'user data'), você pré-instala e pré-configura todo o software necessário em uma AMI customizada. O Auto Scaling Group então lança instâncias a partir desta AMI, o que é significativamente mais rápido."
  },
  {
    "id": "aws-co-064",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Você precisa fornecer acesso a aplicações desktop (provisionadas na AWS) para seus usuários através de um navegador web, sem que eles precisem de um cliente de desktop remoto.",
    "solution": ["appstream 2.0"],
    "availableServices": ["appstream 2.0", "workspaces", "ec2", "client vpn"],
    "explanation": "O Amazon AppStream 2.0 é um serviço de streaming de aplicações totalmente gerenciado. Você pode instalar suas aplicações desktop no AppStream 2.0 e seus usuários podem acessá-las instantaneamente em seus navegadores, com a aplicação sendo executada na AWS."
  },
  {
    "id": "aws-co-065",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa garantir que sua aplicação web seja protegida contra vulnerabilidades comuns como injeção de SQL e Cross-Site Scripting (XSS).",
    "solution": ["waf", "cloudfront", "elastic load balancer"],
    "availableServices": ["waf", "cloudfront", "elastic load balancer", "security group", "aws shield"],
    "explanation": "O AWS WAF (Web Application Firewall) ajuda a proteger suas aplicações web contra exploits comuns. Você pode implantar o WAF no CloudFront ou em um Application Load Balancer e usar regras gerenciadas (como as da OWASP Top 10) para filtrar o tráfego malicioso."
  },
  {
    "id": "aws-co-066",
    "category": "cloud-operations",
    "difficulty": 9,
    "question": "Um grande número de objetos em um bucket S3 precisa ser processado. Iniciar uma função Lambda para cada objeto é ineficiente. Como você pode processar todos os objetos em lote de forma gerenciada?",
    "solution": ["s3 batch operations"],
    "availableServices": ["s3 batch operations", "lambda", "glue", "emr", "step-functions"],
    "explanation": "O S3 Batch Operations é um recurso do S3 projetado para executar operações em larga escala em bilhões de objetos. Você pode fornecer uma lista de objetos e instruir o S3 Batch Operations a invocar uma função Lambda, copiar objetos ou executar outras ações em cada um, com gerenciamento de retentativas, rastreamento e notificações."
  },
  {
    "id": "aws-co-067",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Você precisa de uma maneira de se conectar de forma segura à sua VPC para gerenciar recursos, a partir da sua máquina local, como se estivesse dentro da rede privada.",
    "solution": ["client vpn"],
    "availableServices": ["client vpn", "direct connect", "systems manager session manager", "bastion host"],
    "explanation": "O AWS Client VPN é um serviço de VPN de acesso remoto totalmente gerenciado. Seus usuários remotos podem usar um cliente de software VPN para estabelecer uma conexão segura com a sua VPC, permitindo o acesso a recursos como se estivessem conectados localmente."
  },
  {
    "id": "aws-co-068",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa de uma maneira de se conectar a uma instância EC2 em uma sub-rede privada para fins de shell, sem expor a porta 22 (SSH) e sem a necessidade de um 'bastion host' (servidor de pulo).",
    "solution": ["systems manager session manager"],
    "availableServices": ["systems manager session manager", "ec2", "ssh", "client vpn"],
    "explanation": "O Session Manager, um recurso do AWS Systems Manager, permite que você gerencie suas instâncias EC2 através de um shell interativo baseado em navegador ou da AWS CLI. Ele não requer a abertura de portas de entrada e usa perfis do IAM para controle de acesso, tornando-o mais seguro do que o SSH."
  },
  {
    "id": "aws-co-069",
    "category": "cloud-operations",
    "difficulty": 6,
    "question": "Um Auto Scaling Group deve aumentar o número de instâncias quando a utilização média de CPU do grupo ultrapassar 60%. Qual tipo de política de escalonamento é a mais adequada para isso?",
    "solution": ["auto scaling group", "cloudwatch"],
    "availableServices": ["auto scaling group", "cloudwatch", "lambda", "systems manager"],
    "explanation": "Uma 'Política de Escalonamento de Rastreamento de Alvo' (Target Tracking Scaling Policy) é a mais simples e eficaz para isso. Você define uma métrica (CPUUtilization) e um valor alvo (60%). O Auto Scaling Group então adiciona ou remove instâncias automaticamente para manter a métrica no valor alvo ou próximo a ele."
  },
  {
    "id": "aws-co-070",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Você precisa garantir que os dados em uma tabela do DynamoDB sejam replicados para outra região da AWS para fins de recuperação de desastres e acesso de baixa latência para usuários globais.",
    "solution": ["dynamodb global tables"],
    "availableServices": ["dynamodb global tables", "dms", "lambda", "s3"],
    "explanation": "As 'Tabelas Globais' do DynamoDB são a solução nativa para isso. Elas fornecem um banco de dados totalmente replicado e multiativo em várias regiões da AWS. As escritas em uma região são replicadas automaticamente para as outras regiões, facilitando a criação de aplicações globais e resilientes."
  },
  {
    "id": "aws-co-071",
    "category": "cloud-operations",
    "difficulty": 5,
    "question": "Você precisa encontrar rapidamente a documentação oficial da AWS, tutoriais e artigos da base de conhecimento sobre um serviço específico da AWS.",
    "solution": ["aws documentation"],
    "availableServices": ["aws documentation", "google", "stack overflow", "aws console"],
    "explanation": "A fonte primária e mais confiável para informações sobre os serviços da AWS é a documentação oficial da AWS. Ela fornece guias do usuário, referências de API, tutoriais e melhores práticas detalhadas para cada serviço."
  },
  {
    "id": "aws-co-072",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Uma aplicação precisa enviar notificações por push para dispositivos móveis (iOS e Android). Qual serviço da AWS pode atuar como um único ponto para enviar essas notificações?",
    "solution": ["sns"],
    "availableServices": ["sns", "sqs", "kinesis", "pinpoint"],
    "explanation": "O Amazon SNS (Simple Notification Service) suporta o envio de notificações push para endpoints móveis. Você pode registrar os tokens dos dispositivos no SNS e, em seguida, publicar uma única mensagem no SNS, que a entregará para as plataformas apropriadas (APNS para iOS, FCM para Android)."
  },
  {
    "id": "aws-co-073",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Você quer mover um grande repositório de arquivos de um servidor de arquivos on-premises para a AWS, mantendo-o acessível localmente com baixa latência, como se ainda estivesse na rede local.",
    "solution": ["storage gateway"],
    "availableServices": ["storage gateway", "s3", "direct connect", "dms"],
    "explanation": "O AWS Storage Gateway, no modo 'File Gateway', fornece uma interface de sistema de arquivos (NFS ou SMB) para o S3. Ele armazena os arquivos no S3, mas mantém um cache local dos dados acessados com mais frequência, proporcionando acesso de baixa latência para os usuários e aplicações on-premises."
  },
  {
    "id": "aws-co-074",
    "category": "cloud-operations",
    "difficulty": 9,
    "question": "Você precisa criar um 'data perimeter' para sua organização na AWS, garantindo que os dados não possam sair da sua rede de VPCs e que seus recursos só possam interagir com endpoints e serviços confiáveis, prevenindo a exfiltração de dados.",
    "solution": ["vpc", "vpc endpoint", "iam", "organizations"],
    "availableServices": ["vpc", "vpc endpoint", "iam", "organizations", "aws shield", "guardduty"],
    "explanation": "Um perímetro de dados é criado combinando vários controles. As políticas do AWS Organizations (SCPs) definem limites. Os VPC Endpoints e as políticas de endpoint restringem o acesso a serviços para dentro da VPC. As políticas do IAM usam condições (como `aws:SourceVpc`) para garantir que as solicitações se originem de locais de rede confiáveis."
  },
  {
    "id": "aws-co-075",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa de um serviço que forneça recomendações para otimizar seus recursos da AWS em cinco pilares: custo, performance, segurança, tolerância a falhas e limites de serviço.",
    "solution": ["trusted advisor"],
    "availableServices": ["trusted advisor", "cost explorer", "inspector", "aws config"],
    "explanation": "O AWS Trusted Advisor é um serviço que atua como seu consultor de nuvem personalizado. Ele analisa seu ambiente AWS e fornece recomendações em tempo real para ajudá-lo a seguir as melhores práticas da AWS, otimizando os recursos nos pilares mencionados."
  },
  {
    "id": "aws-co-076",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Uma aplicação crítica requer um banco de dados relacional com um RPO (Recovery Point Objective) de zero, o que significa que nenhuma perda de dados é aceitável em caso de falha.",
    "solution": ["aurora"],
    "availableServices": ["aurora", "rds", "dynamodb", "redshift"],
    "explanation": "O Amazon Aurora com a configuração de cluster Multi-AZ foi projetado para alta disponibilidade e durabilidade. Ele replica os dados de forma síncrona em 3 Zonas de Disponibilidade, o que significa que, no momento em que uma escrita é confirmada, ela já está em múltiplos locais, resultando em um RPO de zero (ou muito próximo de zero)."
  },
  {
    "id": "aws-co-077",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa de uma maneira de descobrir e visualizar as configurações e relacionamentos dos seus recursos AWS, além de rastrear o histórico de alterações de configuração de um recurso específico.",
    "solution": ["aws config"],
    "availableServices": ["aws config", "cloudtrail", "cloudwatch", "resource groups"],
    "explanation": "O AWS Config descobre continuamente seus recursos AWS e mantém um inventário detalhado de suas configurações. A 'Linha do Tempo de Configuração' (Configuration Timeline) de um recurso mostra um histórico completo de como sua configuração mudou ao longo do tempo."
  },
  {
    "id": "aws-co-078",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Uma aplicação precisa de um cache em memória distribuído para armazenar o estado da sessão. O cache deve ser altamente disponível e tolerante a falhas de nós.",
    "solution": ["elasticache for redis"],
    "availableServices": ["elasticache for redis", "elasticache for memcached", "dynamodb", "s3"],
    "explanation": "O ElastiCache for Redis, quando configurado no modo 'Cluster Mode Enabled', distribui os dados entre vários shards. Cada shard pode ter réplicas em diferentes AZs. Isso fornece alta disponibilidade, pois se um nó primário falhar, uma réplica pode ser promovida, garantindo a continuidade do serviço."
  },
  {
    "id": "aws-co-079",
    "category": "cloud-operations",
    "difficulty": 6,
    "question": "Você precisa implantar uma alteração de configuração em um grupo de instâncias do Auto Scaling, substituindo todas as instâncias antigas por novas instâncias com a nova configuração, de forma gradual para minimizar o impacto.",
    "solution": ["auto scaling group"],
    "availableServices": ["auto scaling group", "codedeploy", "cloudformation", "systems manager"],
    "explanation": "Os Auto Scaling Groups suportam 'Instance Refresh'. Esse recurso permite que você execute uma atualização contínua (rolling update) para substituir as instâncias no grupo. Você pode configurar pausas entre as substituições e verificações de saúde para garantir que a atualização ocorra de forma segura e controlada."
  },
  {
    "id": "aws-co-080",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa de um local para armazenar artefatos de build (como arquivos JAR ou pacotes NPM) que são produzidos pelo seu pipeline de CI/CD.",
    "solution": ["codeartifact", "s3"],
    "availableServices": ["codeartifact", "s3", "ecr", "codecommit"],
    "explanation": "O AWS CodeArtifact é um serviço de repositório de artefatos totalmente gerenciado. Ele é projetado para armazenar pacotes de software e dependências. O S3 também pode ser usado como um repositório de artefatos genérico e de baixo custo, sendo uma alternativa comum."
  },
  {
    "id": "aws-co-081",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Você precisa garantir que sua aplicação web possa lidar com picos de tráfego repentinos e massivos (ex: um flash sale). A arquitetura deve ser capaz de escalar de quase zero para milhares de solicitações por segundo em minutos.",
    "solution": ["api gateway", "lambda", "dynamodb"],
    "availableServices": ["api gateway", "lambda", "dynamodb", "ec2", "auto scaling", "rds"],
    "explanation": "Uma arquitetura serverless é ideal para picos de tráfego extremos. O API Gateway, a Lambda e o DynamoDB são todos serviços gerenciados que escalam automaticamente para lidar com a carga. Eles não exigem pré-aquecimento (warm-up) da mesma forma que uma frota de EC2, proporcionando escalabilidade massiva sob demanda."
  },
  {
    "id": "aws-co-082",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa analisar o código-fonte de sua aplicação em busca de bugs, vulnerabilidades de segurança e desvios das melhores práticas de codificação, de forma automatizada.",
    "solution": ["codeguru"],
    "availableServices": ["codeguru", "inspector", "codebuild", "lambda"],
    "explanation": "O Amazon CodeGuru é um serviço que usa machine learning para fornecer recomendações inteligentes para melhorar a qualidade do código e identificar os problemas mais caros de uma aplicação. Ele pode ser integrado ao seu processo de revisão de código para análise estática (CodeGuru Reviewer)."
  },
  {
    "id": "aws-co-083",
    "category": "cloud-operations",
    "difficulty": 9,
    "question": "Você precisa migrar uma máquina virtual VMware on-premises para uma instância EC2 na AWS com o mínimo de modificações e tempo de inatividade possível.",
    "solution": ["aws application migration service (mgn)"],
    "availableServices": ["aws application migration service (mgn)", "dms", "vm import/export", "cloudendure"],
    "explanation": "O AWS Application Migration Service (MGN) é o serviço recomendado para migrações 'lift-and-shift' para a AWS. Ele replica continuamente as máquinas de origem (on-premises ou outra nuvem) para uma área de preparação de baixo custo na sua conta AWS. Quando você está pronto para a transição, ele converte e lança as máquinas como instâncias EC2, minimizando o tempo de inatividade."
  },
  {
    "id": "aws-co-084",
    "category": "cloud-operations",
    "difficulty": 6,
    "question": "Você precisa criar um 'health check' personalizado para uma aplicação que vai além de uma simples verificação de porta. O health check deve chamar um endpoint `/health` e esperar uma resposta HTTP 200 OK.",
    "solution": ["elastic load balancer", "route 53"],
    "availableServices": ["elastic load balancer", "route 53", "cloudwatch", "lambda"],
    "explanation": "Tanto o Elastic Load Balancer quanto o Route 53 permitem configurar 'health checks' personalizados. Em vez de apenas verificar a conectividade TCP, você pode configurá-los para fazer solicitações HTTP/HTTPS para um caminho específico (ex: /health) e considerar a instância saudável apenas se receber um código de status 200."
  },
  {
    "id": "aws-co-085",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Você precisa de uma maneira de implantar e gerenciar pilhas do CloudFormation em múltiplas contas e regiões da AWS a partir de uma conta de administrador centralizada.",
    "solution": ["cloudformation stacksets"],
    "availableServices": ["cloudformation stacksets", "codepipeline", "systems manager", "organizations"],
    "explanation": "O AWS CloudFormation StackSets estende a funcionalidade do CloudFormation, permitindo que você crie, atualize ou exclua pilhas em várias contas e regiões com uma única operação. A partir de uma conta de administrador, você pode implantar uma infraestrutura base comum (ex: perfis do IAM, regras do Config) em toda a sua organização."
  },
  {
    "id": "aws-co-086",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Como você pode restringir o acesso a um bucket S3 para que o conteúdo só possa ser acessado através de uma distribuição específica do CloudFront, e não diretamente pela URL do S3?",
    "solution": ["s3", "cloudfront", "origin access identity"],
    "availableServices": ["s3", "cloudfront", "origin access identity", "iam", "waf"],
    "explanation": "A solução é usar uma 'Origin Access Identity' (OAI) ou 'Origin Access Control' (OAC). Você cria uma identidade especial no CloudFront e concede a ela permissão para ler o bucket S3. Em seguida, a política do bucket S3 é modificada para permitir o acesso apenas a essa identidade, bloqueando efetivamente todo o acesso direto."
  },
  {
    "id": "aws-co-087",
    "category": "cloud-operations",
    "difficulty": 9,
    "question": "Um serviço de processamento de dados precisa lidar com uma fila de mensagens. Se uma mensagem falhar no processamento várias vezes, ela deve ser movida para outra fila para análise manual, para evitar o bloqueio do processamento de outras mensagens.",
    "solution": ["sqs", "lambda"],
    "availableServices": ["sqs", "lambda", "sns", "dynamodb"],
    "explanation": "Esta é a função de uma 'Dead-Letter Queue' (DLQ). Na configuração da sua fila SQS principal, você pode definir uma política de 'redrive' e especificar outra fila SQS como a DLQ. Se uma mensagem for recebida de volta pela fila um número máximo de vezes (indicando falha no processamento), o SQS a moverá automaticamente para a DLQ."
  },
  {
    "id": "aws-co-088",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa de uma maneira de controlar o tráfego de saída de suas instâncias EC2, especificando quais domínios (ex: `api.github.com`) elas podem acessar na internet.",
    "solution": ["network firewall"],
    "availableServices": ["network firewall", "security group", "nacl", "nat gateway"],
    "explanation": "Enquanto Security Groups e NACLs operam nas camadas 3 e 4 (IP e porta), o AWS Network Firewall é um serviço de firewall gerenciado que permite a filtragem na camada 7. Você pode criar regras que inspecionam o tráfego e permitem ou negam com base no nome de domínio (FQDN), e não apenas no endereço IP."
  },
  {
    "id": "aws-co-089",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Sua aplicação requer um número muito grande de IOPS (operações de I/O por segundo) para seu banco de dados. Qual é o tipo de volume EBS de maior performance disponível?",
    "solution": ["ebs io2 block express"],
    "availableServices": ["ebs io2 block express", "ebs gp3", "instance store", "efs"],
    "explanation": "Os volumes EBS `io2 Block Express` são a última geração de armazenamento de alta performance, oferecendo a maior performance e a menor latência dos volumes EBS. Eles são projetados para as cargas de trabalho mais exigentes, como grandes bancos de dados relacionais e NoSQL."
  },
  {
    "id": "aws-co-090",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa de um serviço que possa detectar ameaças de segurança monitorando continuamente seus logs de CloudTrail, logs de VPC Flow e logs de DNS em busca de atividades maliciosas ou não autorizadas.",
    "solution": ["guardduty"],
    "availableServices": ["guardduty", "inspector", "macie", "aws config", "cloudwatch"],
    "explanation": "O Amazon GuardDuty é um serviço de detecção de ameaças que usa inteligência de ameaças e machine learning para monitorar continuamente atividades maliciosas. Ele analisa várias fontes de dados da AWS sem a necessidade de instalar agentes, identificando ameaças como instâncias comprometidas, reconhecimento de rede ou exfiltração de dados."
  },
  {
    "id": "aws-co-091",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Você precisa garantir que os dados de um banco de dados Aurora sejam copiados para outra região da AWS para fins de recuperação de desastres, com um RPO (Recovery Point Objective) de segundos.",
    "solution": ["aurora global database"],
    "availableServices": ["aurora global database", "dms", "rds snapshots", "aws backup"],
    "explanation": "O Amazon Aurora Global Database é projetado para aplicações globalmente distribuídas e recuperação de desastres. Ele consiste em um cluster primário e até cinco clusters secundários somente leitura em outras regiões. A replicação entre as regiões é feita na camada de armazenamento, com latência típica de menos de um segundo, proporcionando um RPO muito baixo."
  },
  {
    "id": "aws-co-092",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa de uma maneira de executar uma função Lambda em uma programação fixa, por exemplo, a cada 15 minutos.",
    "solution": ["eventbridge", "lambda"],
    "availableServices": ["eventbridge", "lambda", "sqs", "step-functions"],
    "explanation": "O Amazon EventBridge é a solução padrão para acionar eventos com base em uma programação. Você pode criar uma 'regra de agendamento' (schedule rule) no EventBridge com uma expressão de taxa (`rate(15 minutes)`) ou uma expressão cron, e definir a função Lambda como o alvo da regra."
  },
  {
    "id": "aws-co-093",
    "category": "cloud-operations",
    "difficulty": 9,
    "question": "Um ataque de negação de serviço (DDoS) na camada de aplicação (HTTP flood) está sobrecarregando seu Application Load Balancer. Como você pode mitigar esse ataque automaticamente?",
    "solution": ["waf", "aws shield advanced", "elastic load balancer"],
    "availableServices": ["waf", "aws shield advanced", "elastic load balancer", "security group", "nacl"],
    "explanation": "O AWS Shield Advanced oferece proteção aprimorada contra ataques DDoS, incluindo detecção e mitigação na camada de aplicação. Ele se integra ao AWS WAF, permitindo a criação de regras baseadas em taxa (rate-based rules) que bloqueiam automaticamente os endereços IP de origem que fazem um número excessivo de solicitações, mitigando o HTTP flood."
  },
  {
    "id": "aws-co-094",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Você precisa de um painel que mostre a saúde geral de todos os seus serviços AWS em todas as regiões, incluindo informações sobre interrupções de serviço e eventos operacionais.",
    "solution": ["aws health dashboard"],
    "availableServices": ["aws health dashboard", "cloudwatch", "trusted advisor", "service catalog"],
    "explanation": "O AWS Health Dashboard fornece uma visão personalizada da saúde dos serviços da AWS. Ele exibe informações sobre eventos em andamento que podem afetar sua infraestrutura (Personal Health Dashboard) e o status geral de todos os serviços (Service Health Dashboard)."
  },
  {
    "id": "aws-co-095",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Como você pode garantir que uma instância EC2 sempre se recupere automaticamente se falhar em uma verificação de saúde do sistema (ex: perda de conectividade de rede, falha de hardware)?",
    "solution": ["ec2", "cloudwatch"],
    "availableServices": ["ec2", "cloudwatch", "auto scaling group", "lambda"],
    "explanation": "Você pode criar um Alarme do CloudWatch que monitora a métrica 'StatusCheckFailed_System'. A ação desse alarme pode ser definida como 'Recover this instance'. Quando o alarme é acionado, a EC2 tenta recuperar a instância automaticamente, migrando-a para um novo hardware saudável enquanto mantém o ID da instância, o IP e os volumes."
  },
  {
    "id": "aws-co-096",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Uma aplicação precisa de acesso de baixa latência a um conjunto de dados de referência que é armazenado no S3. Ler do S3 a cada vez é muito lento. A solução deve ser um cache gerenciado na instância EC2.",
    "solution": ["s3", "ec2", "file cache"],
    "availableServices": ["s3", "ec2", "file cache", "efs", "elasticache"],
    "explanation": "O AWS File Cache é um cache de alta velocidade na AWS que facilita o processamento de arquivos armazenados em locais diferentes, incluindo on-premises e o Amazon S3. Ele fornece uma visão unificada e acesso rápido aos dados para suas aplicações de computação, agindo como um cache de leitura de baixa latência."
  },
  {
    "id": "aws-co-097",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa criar um registro DNS, como `api.suaempresa.com`, que aponte para um Application Load Balancer.",
    "solution": ["route 53", "elastic load balancer"],
    "availableServices": ["route 53", "elastic load balancer", "ec2", "cloudfront"],
    "explanation": "No Amazon Route 53, você cria um conjunto de registros (record set) na sua zona hospedada. Em vez de um registro 'A' com um IP, você usa um registro 'Alias'. Os registros Alias são um recurso do Route 53 que permite mapear seu domínio para recursos da AWS, como um ELB, de forma nativa e eficiente."
  },
  {
    "id": "aws-co-098",
    "category": "cloud-operations",
    "difficulty": 10,
    "question": "Você precisa implantar uma aplicação 'canary' para uma função Lambda. 10% do tráfego de produção deve ser direcionado para a nova versão da função por uma hora. Se a taxa de erros permanecer baixa, todo o tráfego deve ser transferido para a nova versão.",
    "solution": ["lambda", "codedeploy", "cloudwatch"],
    "availableServices": ["lambda", "codedeploy", "cloudwatch", "api gateway", "step-functions"],
    "explanation": "Esta é uma implantação 'Canary Linear'. Você usa 'Aliases' da Lambda. O AWS CodeDeploy pode gerenciar o processo de implantação, deslocando gradualmente o tráfego do alias da versão antiga para a nova. O CodeDeploy pode ser configurado com 'hooks' de validação e monitorar alarmes do CloudWatch, revertendo automaticamente a implantação se a nova versão gerar erros."
  },
  {
    "id": "aws-co-099",
    "category": "cloud-operations",
    "difficulty": 8,
    "question": "Você precisa transferir arquivos de um servidor SFTP externo para um bucket S3 em uma programação regular, de forma totalmente gerenciada, sem provisionar servidores.",
    "solution": ["aws transfer family"],
    "availableServices": ["aws transfer family", "s3", "lambda", "ec2", "dataSync"],
    "explanation": "O AWS Transfer Family é um serviço totalmente gerenciado que suporta transferências de arquivos via SFTP, FTPS e FTP diretamente para o Amazon S3. Você pode usá-lo para criar um endpoint SFTP e, em seguida, usar fluxos de trabalho gerenciados para automatizar a busca de arquivos de um servidor SFTP remoto e salvá-los no S3."
  },
  {
    "id": "aws-co-100",
    "category": "cloud-operations",
    "difficulty": 7,
    "question": "Você precisa de uma visão geral de sua conformidade com frameworks como CIS Benchmarks ou PCI DSS, com verificações automáticas e pontuação de segurança.",
    "solution": ["security hub"],
    "availableServices": ["security hub", "aws config", "inspector", "trusted advisor", "guardduty"],
    "explanation": "O AWS Security Hub executa verificações de segurança contínuas e automáticas com base nas melhores práticas da AWS e em padrões da indústria. Ele fornece uma pontuação de segurança e visualiza sua conformidade com padrões como CIS AWS Foundations Benchmark e PCI DSS."
  }


            ],
            Azure: [],
            GCP: []
        };


        // --- STATE ---
        let currentPlatform = null;
        let currentObjective = null;
        let selectedDifficulty = null;
        let currentScenario = null;
        let draggedServiceId = null;
        
        let currentQuiz = {
            questions: [],
            currentIndex: 0,
            totalQuestions: 5,
            results: []
        };

        // --- DOM ELEMENTS ---
        const platformSelectionScreen = document.getElementById('platform-selection-screen');
        const objectiveSelectionScreen = document.getElementById('objective-selection-screen');
        const difficultySelectionScreen = document.getElementById('difficulty-selection-screen');
        const mainSimulationScreen = document.getElementById('main-simulation-screen');
        const platformName = document.getElementById('platform-name');
        const scenarioQuestion = document.getElementById('scenario-question');
        const servicesPalette = document.getElementById('services-palette');
        const pipelineCanvas = document.getElementById('pipeline-canvas');
        const feedbackModal = document.getElementById('feedback-modal');
        const feedbackTitle = document.getElementById('feedback-title');
        const feedbackMessage = document.getElementById('feedback-message');
        const feedbackButton = document.getElementById('feedback-button');
        const pixModal = document.getElementById('pix-modal');
        const confirmExitModal = document.getElementById('confirm-exit-modal');
        const quizSummaryModal = document.getElementById('quiz-summary-modal');
        const summaryContent = document.getElementById('summary-content');
        const quizProgress = document.getElementById('quiz-progress');

        function selectPlatform(platform) {
            currentPlatform = platform;
            platformSelectionScreen.classList.add('hidden');
            objectiveSelectionScreen.classList.remove('hidden');
        }

        function selectObjective(objective) {
            currentObjective = objective;
            objectiveSelectionScreen.classList.add('hidden');
            difficultySelectionScreen.classList.remove('hidden');
        }

        function selectDifficulty(level) {
            selectedDifficulty = level;
            if(generateQuiz()){
                showPixModal('start');
            }
        }

        function generateQuiz() {
            currentQuiz.totalQuestions = 5; 
            let availableScenarios = scenarios[currentPlatform].filter(s => s.category === currentObjective && s.difficulty === selectedDifficulty);
            
            availableScenarios.sort(() => 0.5 - Math.random());
            currentQuiz.questions = availableScenarios.slice(0, 2); 
            currentQuiz.totalQuestions = currentQuiz.questions.length;
            currentQuiz.currentIndex = 0;
            currentQuiz.results = [];

            if (currentQuiz.questions.length === 0) {
               alert(`Nenhuma questão encontrada para a plataforma, objetivo e nível selecionados. Por favor, tente outra combinação.`);
               return false;
            }
            
            return true;
        }
        
        function showPixModal(context) {
            const primaryBtn = document.getElementById('pix-primary-button');
            const secondaryBtn = document.getElementById('pix-secondary-button');

            if (context === 'start') {
                primaryBtn.textContent = 'Iniciar Simulado';
                primaryBtn.onclick = () => {
                    pixModal.classList.add('hidden');
                    difficultySelectionScreen.classList.add('hidden');
                    mainSimulationScreen.classList.remove('hidden');
                    platformName.textContent = currentPlatform;
                    startChallenge(); 
                };
                secondaryBtn.textContent = 'Fechar';
                 secondaryBtn.onclick = () => pixModal.classList.add('hidden');

            } else if (context === 'end') {
                primaryBtn.textContent = 'Jogar Novamente';
                primaryBtn.onclick = () => {
                    pixModal.classList.add('hidden');
                    confirmExit(); 
                };
                secondaryBtn.textContent = 'Fechar';
                 secondaryBtn.onclick = () => pixModal.classList.add('hidden');
            }
            pixModal.classList.remove('hidden');
        }


        function startChallenge() {
            if (currentQuiz.questions.length === 0) return;

            currentScenario = currentQuiz.questions[currentQuiz.currentIndex];
            quizProgress.textContent = `Questão ${currentQuiz.currentIndex + 1} de ${currentQuiz.totalQuestions}`;
            
            scenarioQuestion.textContent = currentScenario.question;
            populateServices();
            createDropZones();
        }

        function nextQuestion() {
            feedbackModal.classList.add('hidden');
            currentQuiz.currentIndex++;
            if (currentQuiz.currentIndex < currentQuiz.totalQuestions) {
                startChallenge();
            } else {
                showQuizSummary();
            }
        }
        
        function goBack(event) {
            if(event) event.preventDefault();
            const isPlaying = currentPlatform !== null && !mainSimulationScreen.classList.contains('hidden');
            if (isPlaying) {
                confirmExitModal.classList.remove('hidden');
            } else {
                confirmExit();
            }
        }

        function confirmExit() {
            confirmExitModal.classList.add('hidden');
            quizSummaryModal.classList.add('hidden');
            mainSimulationScreen.classList.add('hidden');
            difficultySelectionScreen.classList.add('hidden');
            objectiveSelectionScreen.classList.add('hidden');
            platformSelectionScreen.classList.remove('hidden');

            currentPlatform = null;
            currentObjective = null;
            selectedDifficulty = null;
            currentQuiz.results = [];
            currentQuiz.totalQuestions = 5;
        }
        
        function populateServices() {
            servicesPalette.innerHTML = '';
            const platformServices = services[currentPlatform];
            
            currentScenario.availableServices.forEach(serviceId => {
                const service = platformServices[serviceId];
                if (!service) return;
                const serviceEl = document.createElement('div');
                serviceEl.id = serviceId;
                serviceEl.dataset.originalId = serviceId;
                serviceEl.draggable = true;
                serviceEl.className = 'service-icon flex flex-col items-center justify-center p-3 bg-slate-200 dark:bg-slate-700 rounded-lg shadow-sm hover:bg-slate-300 dark:hover:bg-slate-600';
                
                const invertClass = service.invertInDark ? 'dark:brightness-0 dark:invert' : '';

                const iconHtml = `
                    <div class="h-1/2 flex items-center justify-center">
                        <img src="${service.icon}" class="max-h-full max-w-full object-contain pointer-events-none filter ${invertClass}" alt="${service.name} icon" onerror="this.onerror=null;this.src='https://placehold.co/40x40/E2E8F0/475569?text=?';this.classList.remove('dark:invert');">
                    </div>
                `;

                serviceEl.innerHTML = `
                    ${iconHtml}
                    <div class="font-semibold text-xs sm:text-sm mt-1 text-center text-slate-800 dark:text-slate-200 pointer-events-none">${service.name}</div>
                `;
                serviceEl.addEventListener('dragstart', handleDragStart);
                servicesPalette.appendChild(serviceEl);
            });
        }
        
        function createDropZones() {
            pipelineCanvas.innerHTML = '';
            renderPipelineSegment(pipelineCanvas, currentScenario.solution);
        }

        function renderPipelineSegment(parentElement, solutionSegment) {
            solutionSegment.forEach((step, index) => {
                const stepContainer = document.createElement('div');
                stepContainer.className = 'pipeline-step flex items-center justify-center flex-1 min-w-0 h-full';

                if (typeof step === 'object' && !Array.isArray(step) && step.orchestrator) {
                    stepContainer.classList.add('self-stretch');
                    const orchestratorWrapper = document.createElement('div');
                    orchestratorWrapper.className = 'orchestrator-container w-full h-full flex flex-col border-2 border-dashed border-indigo-400 dark:border-indigo-600 rounded-xl p-4 bg-indigo-50 dark:bg-indigo-900/30';
                    const header = document.createElement('div');
                    header.className = 'flex items-center gap-2 mb-4 pb-4 border-b border-indigo-200 dark:border-indigo-800';
                    
                    const orchestratorDropZone = createSingleDropZone();
                    orchestratorDropZone.classList.add('orchestrator-target');
                    
                    header.appendChild(orchestratorDropZone);
                    
                    const innerCanvas = document.createElement('div');
                    innerCanvas.className = 'inner-canvas flex flex-nowrap items-center justify-start w-full flex-grow bg-white/50 dark:bg-slate-800/50 p-2 rounded-lg gap-2';
                    
                    orchestratorWrapper.appendChild(header);
                    orchestratorWrapper.appendChild(innerCanvas);
                    renderPipelineSegment(innerCanvas, step.flow);
                    stepContainer.appendChild(orchestratorWrapper);
                } else if (Array.isArray(step)) {
                    stepContainer.classList.add('flex-col', 'gap-2', 'self-stretch', 'py-2', 'justify-center');
                    step.forEach(branch => {
                        const branchContainer = document.createElement('div');
                        branchContainer.className = 'branch-container flex flex-nowrap items-center w-full gap-2';
                        branch.forEach((serviceId, serviceIndex) => {
                            const wrapper = document.createElement('div');
                            wrapper.className = 'flex-1 min-w-0';
                            const dropZone = createSingleDropZone();
                            wrapper.appendChild(dropZone);
                            branchContainer.appendChild(wrapper);

                            if (serviceIndex < branch.length - 1) {
                                branchContainer.appendChild(createArrow());
                            }
                        });
                        stepContainer.appendChild(branchContainer);
                    });
                } else {
                    const dropZone = createSingleDropZone();
                    stepContainer.appendChild(dropZone);
                }
                
                parentElement.appendChild(stepContainer);

                if (index < solutionSegment.length - 1) {
                    parentElement.appendChild(createArrow());
                }
            });
        }

        function createSingleDropZone() {
            const dropZone = document.createElement('div');
            dropZone.className = `drop-zone flex-shrink-0 flex items-center justify-center rounded-lg p-2 bg-white dark:bg-slate-800/50 border-slate-300 dark:border-slate-600 w-full max-w-[6rem] mx-auto`;
            dropZone.addEventListener('dragover', handleDragOver);
            dropZone.addEventListener('dragleave', handleDragLeave);
            dropZone.addEventListener('drop', handleDrop);
            return dropZone;
        }

        function createArrow() {
            const arrow = document.createElement('div');
            arrow.className = 'arrow mx-2 flex-shrink-0 text-slate-400 dark:text-slate-500';
            arrow.innerHTML = '&#10140;';
            return arrow;
        }
        
        function handleDragStart(e) {
            const serviceIcon = e.target.closest('.service-icon');
            if (serviceIcon) {
                draggedServiceId = serviceIcon.id;
                 e.dataTransfer.setData('text/plain', serviceIcon.id);
                 e.dataTransfer.effectAllowed = 'move';
            }
        }

        function handleDragOver(e) {
            e.preventDefault();
            const dropZone = e.target.closest('.drop-zone');
            if(dropZone) dropZone.classList.add('drag-over');
        }
        
        function handleDragLeave(e) {
            const dropZone = e.target.closest('.drop-zone');
            if(dropZone) dropZone.classList.remove('drag-over');
        }

        function handleDrop(e) {
            e.preventDefault();
            const dropZone = e.target.closest('.drop-zone');
            if (!dropZone) return;
            dropZone.classList.remove('drag-over');

            const draggedElId = e.dataTransfer.getData('text/plain');
            const draggedEl = document.getElementById(draggedElId);

            if (!draggedEl) return;

            const sourceContainer = draggedEl.parentElement;

            if (sourceContainer.id === 'services-palette') {
                if (dropZone.children.length > 0) return;
                const originalId = draggedEl.dataset.originalId;
                const clone = draggedEl.cloneNode(true);
                clone.id = `clone-${originalId}-${Date.now()}`;
                clone.dataset.originalId = originalId;
                clone.className = 'service-icon relative flex flex-col items-center justify-center p-2 bg-slate-200 dark:bg-slate-700 rounded-lg shadow-sm w-full h-full';
                
                const removeBtn = document.createElement('button');
                removeBtn.innerHTML = '&times;';
                removeBtn.className = 'absolute top-1 right-1 bg-red-500 text-white rounded-full h-5 w-5 flex items-center justify-center text-xs hover:bg-red-700 transition-colors z-10';
                removeBtn.onclick = (event) => event.target.parentElement.remove();
                clone.appendChild(removeBtn);

                clone.addEventListener('dragstart', handleDragStart);
                dropZone.appendChild(clone);
            } 
            else if (sourceContainer.classList.contains('drop-zone')) {
                if (dropZone.children.length > 0) {
                    const existingEl = dropZone.children[0];
                    sourceContainer.appendChild(existingEl);
                    dropZone.appendChild(draggedEl);
                } else {
                    dropZone.appendChild(draggedEl);
                }
            }
        }
        
        function resetPipeline() {
            createDropZones();
        }

        function evaluateSolution() {
            function parseCanvas(canvasElement) {
                const solutionSegment = [];
                const children = Array.from(canvasElement.children).filter(el => el.classList.contains('pipeline-step'));
                
                children.forEach(container => {
                    const orchestratorWrapper = container.querySelector(':scope > .orchestrator-container');
                    if (orchestratorWrapper) {
                        const innerCanvas = orchestratorWrapper.querySelector('.inner-canvas');
                        const orchestratorDropZone = orchestratorWrapper.querySelector('.orchestrator-target .service-icon');
                        const orchestratorId = orchestratorDropZone ? orchestratorDropZone.dataset.originalId : null;
                        solutionSegment.push({
                            orchestrator: orchestratorId,
                            flow: parseCanvas(innerCanvas)
                        });
                    } else if (container.querySelectorAll(':scope > .branch-container').length > 0) {
                        const branches = [];
                        container.querySelectorAll(':scope > .branch-container').forEach(branch => {
                             const servicesInBranch = Array.from(branch.querySelectorAll('.drop-zone')).map(zone => {
                                const serviceEl = zone.querySelector('.service-icon');
                                return serviceEl ? serviceEl.dataset.originalId : null;
                            });
                            branches.push(servicesInBranch);
                        });
                        branches.sort((a,b) => a.join(',').localeCompare(b.join(',')));
                        solutionSegment.push(branches);
                    } else {
                        const serviceEl = container.querySelector('.drop-zone .service-icon');
                        solutionSegment.push(serviceEl ? serviceEl.dataset.originalId : null);
                    }
                });
                return solutionSegment;
            }

            const userSolution = parseCanvas(pipelineCanvas);
            const correctSolution = JSON.parse(JSON.stringify(currentScenario.solution));
            
            function sortSolution(solutionArray) {
                if (!solutionArray) return;
                solutionArray.forEach(step => {
                    if (Array.isArray(step)) {
                        step.sort((a, b) => a.join(',').localeCompare(b.join(',')));
                    } else if (typeof step === 'object' && step.flow) {
                        sortSolution(step.flow);
                    }
                });
            }

            sortSolution(correctSolution);
            
            const isCorrect = JSON.stringify(userSolution) === JSON.stringify(correctSolution);
            
            currentQuiz.results.push({
                question: currentScenario.question,
                solution: currentScenario.solution,
                userSolution: userSolution,
                isCorrect: isCorrect
            });

            showFeedback(isCorrect, userSolution, currentScenario.solution);
        }

       function createSolutionFlowHtml(solutionArray) {
            const platformServices = services[currentPlatform];
            const flowContainer = document.createElement('div');
            flowContainer.className = 'flex flex-nowrap items-center justify-start w-full p-2 bg-slate-100 dark:bg-slate-900/50 rounded-lg overflow-x-auto gap-2';

            function renderSegmentTo(parent, segment) {
                segment.forEach((step, index) => {
                    const stepContainer = document.createElement('div');
                    stepContainer.className = 'flex items-center justify-center flex-1 min-w-max';

                    if (typeof step === 'object' && !Array.isArray(step) && step.orchestrator) {
                        stepContainer.className += ' flex flex-col border border-indigo-400 p-2 rounded-md bg-slate-50 dark:bg-slate-700/50 gap-1 mx-2 self-stretch';
                        const header = document.createElement('div');
                        header.className = 'flex items-center gap-2 font-semibold text-indigo-800 dark:text-indigo-200 text-sm';
                        header.textContent = 'Orquestrado por:';
                        header.appendChild(createServiceElement(step.orchestrator, true));
                        stepContainer.appendChild(header);
                        
                        const innerFlowContainer = document.createElement('div');
                        innerFlowContainer.className = 'flex flex-nowrap items-center justify-start w-full mt-2 border-t border-indigo-200 dark:border-indigo-800 pt-2 gap-2';
                        stepContainer.appendChild(innerFlowContainer);
                        
                        renderSegmentTo(innerFlowContainer, step.flow);
                    } else if (Array.isArray(step)) {
                        stepContainer.className += ' flex flex-col gap-2 p-2 justify-center w-full';
                        step.forEach(branch => {
                            const branchContainer = document.createElement('div');
                            branchContainer.className = 'flex flex-nowrap items-center w-full gap-2';
                            branch.forEach((serviceId, serviceIndex) => {
                                const wrapper = document.createElement('div');
                                wrapper.className = 'flex-1 min-w-0';
                                const serviceEl = createServiceElement(serviceId);
                                wrapper.appendChild(serviceEl);
                                branchContainer.appendChild(wrapper);

                                if (serviceIndex < branch.length - 1) {
                                    branchContainer.appendChild(createArrowElement());
                                }
                            });
                            stepContainer.appendChild(branchContainer);
                        });
                    } else {
                        stepContainer.className += ' flex items-center justify-center';
                        stepContainer.appendChild(createServiceElement(step));
                    }
                    parent.appendChild(stepContainer);

                    if (index < segment.length - 1) {
                        parent.appendChild(createArrowElement());
                    }
                });
            }
            
            function createServiceElement(serviceId, isSmall = false) {
                const service = platformServices[serviceId];
                const serviceEl = document.createElement('div');
                const sizeClass = isSmall ? 'w-16 h-16 text-xs' : 'w-full max-w-[5rem] mx-auto text-xs';
        
                if(serviceId && service) {
                    serviceEl.className = `flex flex-col items-center justify-center bg-white dark:bg-slate-700 p-1 rounded shadow-sm text-slate-800 dark:text-slate-200 aspect-square ${sizeClass}`;
                    const invertClass = service.invertInDark ? 'dark:brightness-0 dark:invert' : '';
                    serviceEl.innerHTML = `
                        <img src="${service.icon}" class="h-1/2 object-contain filter ${invertClass}" alt="${service.name}" onerror="this.onerror=null;this.src='https://placehold.co/32x32/E2E8F0/475569?text=?';this.classList.remove('dark:invert');">
                        <span class="text-center mt-1">${service.name}</span>
                    `;
                } else {
                     serviceEl.className = `flex flex-col items-center justify-center bg-slate-200 dark:bg-slate-600 p-1 rounded shadow-sm aspect-square ${sizeClass}`;
                     serviceEl.innerHTML = `<span class="font-bold">[Vazio]</span>`;
                }
                return serviceEl;
            }
        
            function createArrowElement() {
                 const arrow = document.createElement('div');
                 arrow.className = 'arrow text-2xl mx-2 flex-shrink-0 text-slate-400 dark:text-slate-500';
                 arrow.innerHTML = '&#10140;';
                 return arrow;
            }
        
            renderSegmentTo(flowContainer, solutionArray);
            return flowContainer;
        }


        function showFeedback(isCorrect, userSolution, correctSolution) {
            feedbackModal.classList.remove('hidden');
            
            const userSolutionHtml = createSolutionFlowHtml(userSolution).outerHTML;
            const correctSolutionHtml = createSolutionFlowHtml(correctSolution).outerHTML;
            const defaultExplanation = 'Esta sequência garante um fluxo de dados lógico e eficiente para o problema proposto, onde cada etapa prepara a informação para a seguinte.';
            
            const isLastQuestion = currentQuiz.currentIndex + 1 >= currentQuiz.totalQuestions;

            if (isCorrect) {
                feedbackTitle.textContent = "Parabéns!";
                feedbackTitle.className = "text-3xl font-bold mb-4 text-center text-green-500";
                
                feedbackMessage.innerHTML = `
                    <div class="text-left space-y-4">
                        <p>Você construiu o pipeline corretamente!</p>
                        <div>
                            <p class="font-semibold text-slate-800 dark:text-white">Sua solução:</p>
                            <div class="mt-1 bg-green-100 dark:bg-green-900/50 p-3 rounded-lg text-green-800 dark:text-green-300 text-sm">${correctSolutionHtml}</div>
                        </div>
                        <div>
                            <p class="font-semibold text-slate-800 dark:text-white">Por que essa é a solução correta?</p>
                            <p class="mt-1 text-slate-600 dark:text-slate-300 text-sm">${currentScenario.explanation || defaultExplanation}</p>
                        </div>
                    </div>`;

                feedbackButton.textContent = isLastQuestion ? "Ver Resumo" : "Próximo Desafio";
                feedbackButton.onclick = nextQuestion;
                feedbackButton.className = "bg-green-600 hover:bg-green-700 text-white font-bold py-3 px-8 rounded-lg transition-colors w-full mt-6";
            } else {
                feedbackTitle.textContent = "Análise da Solução";
                feedbackTitle.className = "text-3xl font-bold mb-4 text-center text-orange-500";
                
                feedbackMessage.innerHTML = `
                    <div class="text-left space-y-4">
                         <p>Sua solução não está totalmente correta. A resposta certa foi apresentada para seu aprendizado.</p>
                         <div>
                            <p class="font-semibold text-slate-800 dark:text-white">Sua Resposta:</p>
                            <div class="mt-1 bg-red-100 dark:bg-red-900/50 p-3 rounded-lg text-red-800 dark:text-red-300 text-sm">${userSolutionHtml}</div>
                        </div>
                        <div>
                            <p class="font-semibold text-slate-800 dark:text-white">A Resposta Correta é:</p>
                            <div class="mt-1 bg-green-100 dark:bg-green-900/50 p-3 rounded-lg text-green-800 dark:text-green-300 text-sm">${correctSolutionHtml}</div>
                        </div>
                        <div>
                            <p class="font-semibold text-slate-800 dark:text-white">Por quê?</p>
                            <p class="mt-1 text-slate-600 dark:text-slate-300 text-sm">${currentScenario.explanation || defaultExplanation}</p>
                        </div>
                    </div>`;
                
                feedbackButton.textContent = isLastQuestion ? "Ver Resumo" : "Próxima Questão";
                feedbackButton.onclick = nextQuestion;
                feedbackButton.className = "bg-indigo-600 hover:bg-indigo-700 dark:bg-indigo-500 dark:hover:bg-indigo-600 text-white font-bold py-3 px-8 rounded-lg transition-colors w-full mt-6";
            }
        }

        function showQuizSummary() {
            mainSimulationScreen.classList.add('hidden');
            quizSummaryModal.classList.remove('hidden');
            summaryContent.innerHTML = ''; 

            currentQuiz.results.forEach((result, index) => {
                const resultCard = document.createElement('div');
                resultCard.className = 'p-4 border border-slate-200 dark:border-slate-700 rounded-lg';
                
                const questionTitle = document.createElement('h3');
                questionTitle.className = 'font-semibold text-lg mb-2 text-slate-800 dark:text-white';
                questionTitle.textContent = `Questão ${index + 1}: ${result.question}`;

                const statusIcon = document.createElement('span');
                statusIcon.className = `ml-2 font-bold ${result.isCorrect ? 'text-green-500' : 'text-red-500'}`;
                statusIcon.textContent = result.isCorrect ? '✓ Correto' : '✗ Incorreto';
                questionTitle.appendChild(statusIcon);
                
                const solutionTitle = document.createElement('p');
                solutionTitle.className = 'font-semibold mt-4 mb-2 text-slate-800 dark:text-white';
                solutionTitle.textContent = 'Fluxo correto da arquitetura:';

                const solutionFlow = createSolutionFlowHtml(result.solution);

                resultCard.appendChild(questionTitle);
                resultCard.appendChild(solutionTitle);
                resultCard.appendChild(solutionFlow);
                summaryContent.appendChild(resultCard);
            });
        }

    </script>

</body>
</html>

